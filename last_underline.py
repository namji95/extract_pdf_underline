"""
í†µí•© ë¡œì§: ';'ê³¼ '.' ë˜ëŠ” ','ì™€ '.' ê¸°ì¤€ìœ¼ë¡œ ë¶„ê¸° ì²˜ë¦¬
- ';'ì´ ìˆìœ¼ë©´ ';'ê³¼ '.' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
- ';'ì´ ì—†ê³  ','ë§Œ ìˆìœ¼ë©´ ','ì™€ '.' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
"""

import re
import fitz
import sys
from pathlib import Path


def extract_trademark_sections(pdf_path):
    """
    PDFì—ì„œ 'Information concerning the earlier mark' ì„¹ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ
    ê° ìƒí‘œ(Earlier Mark)ì˜ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """

    doc = fitz.open(pdf_path)
    sections = []
    all_blocks = []

    for page_num, page in enumerate(doc):
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            if "lines" not in block:
                continue

            block_text = ""
            for line in block["lines"]:
                for span in line["spans"]:
                    block_text += span["text"] + " "

            block_text = block_text.strip()

            block_info = {
                "page": page_num + 1,
                "y0": block["bbox"][1],
                "y1": block["bbox"][3],
                "text": block_text
            }

            all_blocks.append(block_info)

    # 'Information concerning the earlier mark' ì‹œì‘ì  ì°¾ê¸°
    section_starts = []

    for idx, block in enumerate(all_blocks):
        text = block["text"]
        text_cleaned = text.replace("â–¡", "").replace("â˜", "").strip()

        # íŒ¨í„´ 1: ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš° (1), (2) ...
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*\((\d+)\)",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            mark_number = int(match.group(1))
            section_starts.append({
                "index": idx,
                "mark_number": mark_number,
                "page": block["page"],
                "y": block["y0"]
            })
            continue

        # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ëŠ” ê²½ìš° (ë‹¨ì¼ ìƒí‘œ ë¬¸ì„œ)
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*$",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            section_starts.append({
                "index": idx,
                "mark_number": 1,
                "page": block["page"],
                "y": block["y0"]
            })

    # ì„¹ì…˜ ì‹œì‘ì ì´ ì—†ëŠ” PDF ì²˜ë¦¬
    if not section_starts:
        full_text = " ".join([block["text"] for block in all_blocks])

        filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+(?:Registration|registration)[/\s]+"
            r"Subsequent\s+Designation\s+No[.\s]*:?\s*(\d+)",
            full_text
        )
        international_registration = ir_match.group(1) if ir_match else None

        doc.close()

        return [{
            "mark_number": 1,
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": 1,
            "page_end": all_blocks[-1]["page"] if all_blocks else 1,
            "y_start": 0,
            "y_end": float('inf')
        }]

    # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê³„ì‚° + ì •ë³´ ì¶”ì¶œ
    for i, start in enumerate(section_starts):
        if i + 1 < len(section_starts):
            end_idx = section_starts[i + 1]["index"]
            end_page = section_starts[i + 1]["page"]
            end_y = section_starts[i + 1]["y"]
        else:
            end_idx = len(all_blocks)
            end_page = all_blocks[-1]["page"]
            end_y = all_blocks[-1]["y1"]

        section_text = " ".join(
            all_blocks[j]["text"] for j in range(start["index"], end_idx)
        )

        filing_match = re.search(r"Filing\s+number\s*:\s*(\d+)", section_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+registration\s+number\s*:\s*(\d+)",
            section_text,
            re.IGNORECASE
        )
        international_registration = ir_match.group(1) if ir_match else None

        sections.append({
            "mark_number": start["mark_number"],
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": start["page"],
            "page_end": end_page,
            "y_start": start["y"],
            "y_end": end_y
        })

    doc.close()
    return sections


def extract_underlines_only(pdf_path):
    """
    PDFì—ì„œ ë°‘ì¤„(ìˆ˜í‰ì„ )ë§Œ ì¶”ì¶œ (ì¢Œí‘œ ì •ë³´ë§Œ)
    """
    doc = fitz.open(pdf_path)
    underlines = []

    for page_num, page in enumerate(doc):
        drawings = page.get_drawings()

        for d in drawings:
            for item in d.get("items", []):
                if item[0] == "l":
                    p1, p2 = item[1], item[2]

                    # ìˆ˜í‰ì„  íŒë³„
                    if abs(p1.y - p2.y) < 2:
                        length = abs(p2.x - p1.x)

                        # underline í›„ë³´ ê¸¸ì´ ì œí•œ
                        if 10 < length < 500:
                            underlines.append({
                                "page": page_num + 1,
                                "y": p1.y,
                                "x0": min(p1.x, p2.x),
                                "x1": max(p1.x, p2.x),
                            })

    doc.close()
    return underlines


def detect_delimiter_type(pdf_path):
    """
    PDFì—ì„œ Goods/Services ì˜ì—­ì˜ êµ¬ë¶„ì íƒ€ì… ê°ì§€
    - ';'ì´ ìˆìœ¼ë©´ 'semicolon' ë°˜í™˜ (;ê³¼ .ë¡œ ë¶„ë¦¬)
    - ';'ì´ ì—†ìœ¼ë©´ 'dot_only' ë°˜í™˜ (.ë¡œë§Œ ë¶„ë¦¬, ì „ì²´ê°€ í•˜ë‚˜ì˜ ìƒí’ˆ)

    Note: ','ëŠ” ìƒí’ˆ ì„¤ëª… ë‚´ì˜ êµ¬ë¶„ì´ë¯€ë¡œ ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ
    """
    doc = fitz.open(pdf_path)

    anchor_pattern = re.compile(
        r"Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground",
        re.IGNORECASE
    )

    goods_text = ""
    after_anchor = False

    for page in doc:
        text_dict = page.get_text("dict")

        for block in text_dict["blocks"]:
            if "lines" not in block:
                continue

            for line_obj in block["lines"]:
                for span in line_obj["spans"]:
                    txt = span["text"]

                    if anchor_pattern.search(txt):
                        after_anchor = True
                        colon_idx = txt.find(":")
                        if colon_idx != -1:
                            goods_text += txt[colon_idx + 1:]
                        continue

                    if after_anchor:
                        goods_text += txt
                        if '.' in txt:
                            # ì²« ë²ˆì§¸ ìƒí’ˆ ëª©ë¡ë§Œ í™•ì¸
                            break

            if after_anchor and '.' in goods_text:
                break
        if after_anchor and '.' in goods_text:
            break

    doc.close()

    # êµ¬ë¶„ì íƒ€ì… ê²°ì •: ';'ì´ ìˆìœ¼ë©´ semicolon, ì—†ìœ¼ë©´ dot_only
    if ';' in goods_text:
        return 'semicolon'
    else:
        return 'dot_only'  # .ë¡œë§Œ ë¶„ë¦¬ (ì „ì²´ê°€ í•˜ë‚˜ì˜ ìƒí’ˆ)


def extract_goods_with_spans(pdf_path, underlines, delimiter_type='semicolon'):
    """
    ì•µì»¤ íŒ¨í„´ ì´í›„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ë°‘ì¤„ ë¶€ë¶„ì—ë§Œ <u> íƒœê·¸ ì ìš©

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        underlines: extract_underlines_only() ê²°ê³¼
        delimiter_type: 'semicolon' (;ê³¼ . ê¸°ì¤€) ë˜ëŠ” 'comma' (,ì™€ . ê¸°ì¤€)
    """
    doc = fitz.open(pdf_path)
    results = []

    anchor_pattern = re.compile(
        r"Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground",
        re.IGNORECASE
    )

    page_num_pattern = re.compile(r'^\s*-\s*\d+\s*-\s*$')

    # êµ¬ë¶„ì ì„¤ì •
    if delimiter_type == 'semicolon':
        delimiter_regex = r'([;.])'
        delimiters = [';', '.']
    else:  # dot_only - .ë¡œë§Œ ë¶„ë¦¬ (ì „ì²´ê°€ í•˜ë‚˜ì˜ ìƒí’ˆ)
        delimiter_regex = r'([.])'
        delimiters = ['.']

    def get_underlined_texts_for_page(page, page_num):
        """í˜ì´ì§€ì—ì„œ ë°‘ì¤„ ë°”ë¡œ ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        underlined_texts = []
        page_underlines = [ul for ul in underlines if ul["page"] == page_num]

        for ul in page_underlines:
            clip_rect = fitz.Rect(
                ul["x0"] - 1,
                ul["y"] - 12,
                ul["x1"] + 1,
                ul["y"] + 1
            )
            text = page.get_text("text", clip=clip_rect).strip()
            text = " ".join(text.split())

            if text:
                underlined_texts.append({
                    "text": text,
                    "y": ul["y"],
                    "x0": ul["x0"],
                    "x1": ul["x1"]
                })

        return underlined_texts

    def apply_underline_tags(full_text, underlined_texts):
        """ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì—ë§Œ <u> íƒœê·¸ ì ìš©"""
        if not underlined_texts:
            return full_text

        tagged_text = full_text

        # ë°‘ì¤„ í…ìŠ¤íŠ¸ë“¤ì„ ê¸¸ì´ìˆœ ì •ë ¬ (ê¸´ ê²ƒ ë¨¼ì €)
        sorted_ul_texts = sorted(underlined_texts, key=lambda x: len(x["text"]), reverse=True)

        for ul in sorted_ul_texts:
            ul_text = ul["text"]
            if not ul_text:
                continue

            if f"<u>{ul_text}</u>" in tagged_text:
                continue

            if ul_text in tagged_text:
                pattern = re.compile(re.escape(ul_text))
                matches = list(pattern.finditer(tagged_text))

                for match in reversed(matches):
                    start, end = match.start(), match.end()

                    before = tagged_text[:start]
                    if before.count("<u>") > before.count("</u>"):
                        continue

                    tagged_text = tagged_text[:start] + f"<u>{ul_text}</u>" + tagged_text[end:]
                    break

        return tagged_text

    # ë²„í¼
    buffer_texts = []
    buffer_page = None
    buffer_y0 = float('inf')
    buffer_y1 = 0
    buffer_underlined_texts = []

    def flush_buffer():
        nonlocal buffer_texts, buffer_page, buffer_y0, buffer_y1, buffer_underlined_texts

        if not buffer_texts:
            return

        full_text = " ".join(buffer_texts)
        full_text = re.sub(r'\s+', ' ', full_text).strip()

        if full_text:
            tagged_text = apply_underline_tags(full_text, buffer_underlined_texts)

            results.append({
                "page": buffer_page,
                "text": full_text,
                "tagged_text": tagged_text,
                "y0": buffer_y0,
                "y1": buffer_y1,
            })

        buffer_texts = []
        buffer_y0 = float('inf')
        buffer_y1 = 0
        buffer_underlined_texts = []

    def add_to_buffer(text, y0, y1, page, page_underlined_texts):
        nonlocal buffer_page, buffer_y0, buffer_y1, buffer_underlined_texts

        buffer_texts.append(text)
        buffer_page = page
        buffer_y0 = min(buffer_y0, y0)
        buffer_y1 = max(buffer_y1, y1)

        for ul in page_underlined_texts:
            if y0 - 5 <= ul["y"] <= y1 + 5:
                if ul not in buffer_underlined_texts:
                    buffer_underlined_texts.append(ul)

    after_anchor = False

    for page_num, page in enumerate(doc):
        text_dict = page.get_text("dict")
        page_underlined_texts = get_underlined_texts_for_page(page, page_num + 1)

        for block in text_dict["blocks"]:
            if "lines" not in block:
                continue

            for line_obj in block["lines"]:
                for span in line_obj["spans"]:
                    txt = span["text"]
                    bbox = span["bbox"]

                    if not txt.strip():
                        continue

                    if page_num_pattern.match(txt.strip()):
                        continue

                    if anchor_pattern.search(txt):
                        after_anchor = True
                        colon_idx = txt.find(":")
                        if colon_idx != -1 and colon_idx < len(txt) - 1:
                            after_colon = txt[colon_idx + 1:].strip()
                            if after_colon:
                                parts = re.split(delimiter_regex, after_colon)
                                for part in parts:
                                    if not part:
                                        continue
                                    if part in delimiters:
                                        flush_buffer()
                                        if part == '.':
                                            after_anchor = False
                                    else:
                                        add_to_buffer(part, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                        continue

                    if not after_anchor:
                        continue

                    # ì•µì»¤ ì´í›„ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                    has_delimiter = any(d in txt for d in delimiters)
                    if has_delimiter:
                        parts = re.split(delimiter_regex, txt)
                        for part in parts:
                            if not part:
                                continue
                            if part in delimiters:
                                flush_buffer()
                                if part == '.':
                                    after_anchor = False
                            else:
                                add_to_buffer(part, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                    else:
                        add_to_buffer(txt, bbox[1], bbox[3], page_num + 1, page_underlined_texts)

    flush_buffer()
    doc.close()
    return results


def find_all_matching_tagged(sec, tagged_list, used_indices):
    """ì„¹ì…˜ ë²”ìœ„ ë‚´ì— ìˆëŠ” ëª¨ë“  tagged_result ì°¾ê¸°"""
    page_start = sec["page_start"]
    page_end = sec["page_end"]
    y_start = sec["y_start"]
    y_end = sec["y_end"]

    matched = []

    for idx, tr in enumerate(tagged_list):
        # ì¸ë±ìŠ¤ë¡œ ì¤‘ë³µ ì²´í¬ (ê°™ì€ y0ë¥¼ ê°€ì§„ ì—¬ëŸ¬ ìƒí’ˆ êµ¬ë¶„)
        if idx in used_indices:
            continue

        tr_page = tr["page"]
        tr_y0 = tr["y0"]

        if tr_page < page_start or tr_page > page_end:
            continue

        is_in_range = False

        if page_start == page_end:
            if y_start <= tr_y0 <= y_end:
                is_in_range = True
        elif tr_page == page_start:
            if tr_y0 >= y_start:
                is_in_range = True
        elif tr_page == page_end:
            if tr_y0 <= y_end:
                is_in_range = True
        else:
            # ì¤‘ê°„ í˜ì´ì§€
            is_in_range = True

        if is_in_range:
            matched.append(tr)
            used_indices.add(idx)

    return matched


def clean_tagged_text(tagged_text):
    """íƒœê·¸ëœ í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not tagged_text:
        return tagged_text

    # [Class XX] ì œê±°
    tagged_text = re.sub(
        r"\s*\[\s*Class\s*\d+\s*\]\s*",
        "",
        tagged_text,
        flags=re.IGNORECASE
    )

    # ê³µë°± ì •ë¦¬
    tagged_text = re.sub(r'<u>\s+', '<u>', tagged_text)
    tagged_text = re.sub(r'\s+</u>', '</u>', tagged_text)
    tagged_text = re.sub(r'\s{2,}', ' ', tagged_text)

    return tagged_text.strip()


def process_pdf(pdf_path):
    """
    PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
    - êµ¬ë¶„ì íƒ€ì… ìë™ ê°ì§€
    - ë°‘ì¤„ ì¶”ì¶œ
    - ì„¹ì…˜ ë§¤ì¹­
    """
    # 1. êµ¬ë¶„ì íƒ€ì… ê°ì§€
    delimiter_type = detect_delimiter_type(pdf_path)
    print(f"ê°ì§€ëœ êµ¬ë¶„ì íƒ€ì…: {delimiter_type}")

    # 2. ë°‘ì¤„ ì¢Œí‘œ ì¶”ì¶œ
    underlines = extract_underlines_only(pdf_path)

    # 3. ì„¹ì…˜ ì •ë³´ ì¶”ì¶œ
    sections = extract_trademark_sections(pdf_path)

    # 4. Goods ì¶”ì¶œ + ë°‘ì¤„ íƒœê·¸
    tagged_results = extract_goods_with_spans(pdf_path, underlines, delimiter_type)

    # 5. ì„¹ì…˜ì— ë§¤ì¹­
    final_results = []
    used_tagged = set()

    for section in sections:
        matched_list = find_all_matching_tagged(section, tagged_results, used_tagged)

        # íƒœê·¸ëœ í…ìŠ¤íŠ¸ ì •ë¦¬
        for matched in matched_list:
            matched["tagged_text"] = clean_tagged_text(matched["tagged_text"])

        final_results.append({
            "mark_number": section.get("mark_number"),
            "filing_number": section["filing_number"],
            "international_registration": section["international_registration"],
            "tagged_goods": matched_list
        })

    return {
        "delimiter_type": delimiter_type,
        "sections": sections,
        "tagged_results": tagged_results,
        "final_results": final_results
    }


def print_results(data):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"êµ¬ë¶„ì íƒ€ì…: {data['delimiter_type']}")
    print("=" * 80 + "\n")

    print("ğŸ“ ë°‘ì¤„ ë§¤ì¹­ ê²°ê³¼ (<u> íƒœê·¸ ì ìš©):")
    for idx, item in enumerate(data['tagged_results'], 1):
        has_underline = "<u>" in item["tagged_text"]
        mark = "âœ…" if has_underline else "  "
        print(f"  {idx}. {mark} page={item['page']}")
        print(f"      ì›ë³¸: {item['text'][:100]}..." if len(item['text']) > 100 else f"      ì›ë³¸: {item['text']}")
        print(f"      íƒœê·¸: {item['tagged_text'][:100]}..." if len(item['tagged_text']) > 100 else f"      íƒœê·¸: {item['tagged_text']}")
    print()

    print("=" * 80)
    print("ğŸ”¥ ìµœì¢… ê²°ê³¼ (ì „ì²´ í…ìŠ¤íŠ¸ + ë°‘ì¤„ íƒœê·¸)")
    print("=" * 80 + "\n")

    for idx, r in enumerate(data['final_results'], 1):
        print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")

        if r['filing_number']:
            print(f"    Filing Number: {r['filing_number']}")
        if r['international_registration']:
            print(f"    International Registration: {r['international_registration']}")

        if r['tagged_goods']:
            print(f"\n    ìƒí’ˆ ëª©ë¡ (ë°‘ì¤„ ë¶€ë¶„ì— <u> íƒœê·¸):")
            for i, goods_item in enumerate(r['tagged_goods'], 1):
                print(f"      {i}. {goods_item['tagged_text']}")
        else:
            print(f"    (ìƒí’ˆ ì—†ìŒ)")

        print()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/ë¬¸ì œ/552025075457917-01-ë³µì‚¬.pdf"

    if not Path(pdf_path).exists():
        print(f"íŒŒì¼ ì—†ìŒ: {pdf_path}")
        sys.exit(1)

    print("=" * 80)
    print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}\n")

    data = process_pdf(pdf_path)
    print_results(data)
