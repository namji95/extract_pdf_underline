"""
í†µí•© ë¡œì§:
- ';'ì´ ìˆìœ¼ë©´: ';'ê³¼ '.' ê¸°ì¤€ìœ¼ë¡œ ê°œë³„ ìƒí’ˆ ë¶„ë¦¬, ë°‘ì¤„ ìˆëŠ” ìƒí’ˆë§Œ ì¶”ì¶œ
- ';'ì´ ì—†ìœ¼ë©´: ','ì™€ '.'ë¡œ êµ¬ë¶„ëœ ì „ì²´ ë¬¸ìì—´ ìœ ì§€, ë°‘ì¤„ ë¶€ë¶„ë§Œ <u> íƒœê·¸ ì ìš©
PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
"""

import re
import fitz
import sys
from pathlib import Path


def extract_trademark_sections(pdf_path):
    """
    PDFì—ì„œ 'Information concerning the earlier mark' ì„¹ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ
    ê° ìƒí‘œ(Earlier Mark)ì˜ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """

    doc = fitz.open(pdf_path)
    sections = []
    all_blocks = []

    for page_num, page in enumerate(doc):
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            if "lines" not in block:
                continue

            block_text = ""
            for line in block["lines"]:
                for span in line["spans"]:
                    block_text += span["text"] + " "

            block_text = block_text.strip()

            block_info = {
                "page": page_num + 1,
                "y0": block["bbox"][1],
                "y1": block["bbox"][3],
                "text": block_text
            }

            all_blocks.append(block_info)

    section_starts = []

    for idx, block in enumerate(all_blocks):
        text = block["text"]
        text_cleaned = text.replace("â–¡", "").replace("â˜", "").strip()

        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*\((\d+)\)",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            mark_number = int(match.group(1))
            section_starts.append({
                "index": idx,
                "mark_number": mark_number,
                "page": block["page"],
                "y": block["y0"]
            })
            continue

        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*$",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            section_starts.append({
                "index": idx,
                "mark_number": 1,
                "page": block["page"],
                "y": block["y0"]
            })

    if not section_starts:
        full_text = " ".join([block["text"] for block in all_blocks])

        filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+(?:Registration|registration)[/\s]+"
            r"Subsequent\s+Designation\s+No[.\s]*:?\s*(\d+)",
            full_text
        )
        international_registration = ir_match.group(1) if ir_match else None

        doc.close()

        return [{
            "mark_number": 1,
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": 1,
            "page_end": all_blocks[-1]["page"] if all_blocks else 1,
            "y_start": 0,
            "y_end": float('inf')
        }]

    for i, start in enumerate(section_starts):
        if i + 1 < len(section_starts):
            end_idx = section_starts[i + 1]["index"]
            end_page = section_starts[i + 1]["page"]
            end_y = section_starts[i + 1]["y"]
        else:
            end_idx = len(all_blocks)
            end_page = all_blocks[-1]["page"]
            end_y = all_blocks[-1]["y1"]

        section_text = " ".join(
            all_blocks[j]["text"] for j in range(start["index"], end_idx)
        )

        filing_match = re.search(r"Filing\s+number\s*:\s*(\d+)", section_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+registration\s+number\s*:\s*(\d+)",
            section_text,
            re.IGNORECASE
        )
        international_registration = ir_match.group(1) if ir_match else None

        sections.append({
            "mark_number": start["mark_number"],
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": start["page"],
            "page_end": end_page,
            "y_start": start["y"],
            "y_end": end_y
        })

    doc.close()
    return sections


def extract_underlines_only(pdf_path):
    """PDFì—ì„œ ë°‘ì¤„(ìˆ˜í‰ì„ )ë§Œ ì¶”ì¶œ"""
    doc = fitz.open(pdf_path)
    underlines = []

    for page_num, page in enumerate(doc):
        drawings = page.get_drawings()

        for d in drawings:
            for item in d.get("items", []):
                if item[0] == "l":
                    p1, p2 = item[1], item[2]

                    if abs(p1.y - p2.y) < 2:
                        length = abs(p2.x - p1.x)

                        if 10 < length < 500:
                            underlines.append({
                                "page": page_num + 1,
                                "y": p1.y,
                                "x0": min(p1.x, p2.x),
                                "x1": max(p1.x, p2.x),
                            })

    doc.close()
    return underlines


def detect_delimiter_type(pdf_path):
    """
    PDFì—ì„œ Goods/Services ì˜ì—­ì˜ êµ¬ë¶„ì íƒ€ì… ê°ì§€
    - ';'ì´ ìˆìœ¼ë©´ 'semicolon' ë°˜í™˜
    - ';'ì´ ì—†ê³  ','ê°€ ìˆìœ¼ë©´ 'comma' ë°˜í™˜
    """
    doc = fitz.open(pdf_path)

    anchor_pattern = re.compile(
        r"Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground",
        re.IGNORECASE
    )

    goods_text = ""
    after_anchor = False

    for page in doc:
        text_dict = page.get_text("dict")

        for block in text_dict["blocks"]:
            if "lines" not in block:
                continue

            for line_obj in block["lines"]:
                for span in line_obj["spans"]:
                    txt = span["text"]

                    if anchor_pattern.search(txt):
                        after_anchor = True
                        colon_idx = txt.find(":")
                        if colon_idx != -1:
                            goods_text += txt[colon_idx + 1:]
                        continue

                    if after_anchor:
                        goods_text += txt
                        if '.' in txt:
                            break

            if after_anchor and '.' in goods_text:
                break
        if after_anchor and '.' in goods_text:
            break

    doc.close()

    if ';' in goods_text:
        return 'semicolon'
    else:
        return 'comma'


def should_exclude_underlined_text(text: str) -> bool:
    """ë°‘ì¤„ í…ìŠ¤íŠ¸ê°€ ìƒí’ˆ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš° ì œì™¸"""
    stripped = text.strip()

    if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
        return True

    if re.search(r"\b(Fax|Tel\.?|Telephone|E-mail|Email)\b", stripped, re.IGNORECASE):
        return True

    if "@" in stripped:
        return True

    if stripped in ["ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥", "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥"]:
        return True

    if stripped.startswith(('ì‹¬ì‚¬ê´€', 'íŒŒíŠ¸ì¥', 'íŒ€ì¥', 'êµ­ì¥')):
        return True

    if re.search(r"underlined goods", stripped, re.IGNORECASE):
        return True

    return False


def normalize_for_compare(text: str) -> str:
    """ìƒí’ˆ ë¹„êµìš© ì •ê·œí™”"""
    if not text:
        return ""

    text = re.sub(
        r"^\*?\s*Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground:\s*",
        "",
        text,
        flags=re.IGNORECASE
    )

    text = re.sub(r"\[\s*Class\s*\d+\s*\]", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\s{2,}", " ", text)

    return text.strip()


def clean_goods_text(goods: str) -> str:
    """ìµœì¢… ê²°ê³¼ìš© goods ë¬¸ìì—´ ì •ë¦¬"""
    if not goods:
        return goods

    goods = re.sub(
        r"^\*?\s*Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground:\s*",
        "",
        goods,
        flags=re.IGNORECASE
    )

    goods = re.sub(r"\s*\[\s*Class\s*\d+\s*\]\s*", "", goods, flags=re.IGNORECASE)
    goods = re.sub(r"<u>\s+", "<u>", goods)
    goods = re.sub(r"\s{2,}", " ", goods)

    return goods.strip()


# ============================================================
# SEMICOLON ë°©ì‹: ';'ê³¼ '.' ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„ë¦¬
# ============================================================

def extract_underlined_with_positions_semicolon(pdf_path):
    """
    ';' ê¸°ì¤€ PDFìš©: ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ê°œë³„ ìƒí’ˆìœ¼ë¡œ ì¶”ì¶œ
    """
    doc = fitz.open(pdf_path)
    results = []

    for page_num, page in enumerate(doc):
        drawings = page.get_drawings()
        lines = []

        for d in drawings:
            for item in d.get("items", []):
                if item[0] == "l":
                    p1, p2 = item[1], item[2]

                    if abs(p1.y - p2.y) < 2:
                        length = abs(p2.x - p1.x)

                        if 10 < length < 500:
                            lines.append({
                                "y": p1.y,
                                "x0": min(p1.x, p2.x),
                                "x1": max(p1.x, p2.x),
                            })

        for line in lines:
            anchor_rect = fitz.Rect(
                line["x0"] - 1,
                line["y"] - 12,
                line["x1"] + 1,
                line["y"] + 1,
            )

            raw_text = page.get_text("text", clip=anchor_rect)
            if raw_text.startswith(('ì‹¬ì‚¬ê´€', 'íŒŒíŠ¸ì¥', 'íŒ€ì¥', 'êµ­ì¥')):
                continue

            anchor_text = " ".join(raw_text.strip().split())

            if not anchor_text:
                continue

            full_rect = fitz.Rect(
                0,
                line["y"] - 12,
                page.rect.width,
                line["y"] + 1,
            )

            full_raw_text = page.get_text("text", clip=full_rect)
            full_text = " ".join(full_raw_text.strip().split())

            if not full_text:
                continue

            # Class ì •ë³´ ì¶”ì¶œ
            match = re.search(r'\[Class\s+(\d+)\]', full_text, re.IGNORECASE)
            class_num = match.group(1) if match else None

            # ì •ê·œí™”
            normalized_text = normalize_for_compare(anchor_text)

            if should_exclude_underlined_text(normalized_text):
                continue

            # delimiter ì œê±°
            underline_core = re.sub(r"[;.]\s*$", "", normalized_text).strip()
            compare_underline = normalize_for_compare(underline_core)

            # full_text â†’ ìƒí’ˆ ë‹¨ìœ„ ë¶„ë¦¬
            goods_parts = [
                p.strip()
                for p in re.split(r"[;.]", full_text)
                if p.strip()
            ]

            tagged_text = None

            for part in goods_parts:
                compare_part = normalize_for_compare(part)

                if compare_part == compare_underline:
                    tagged_text = f"<u>{compare_part}</u>"
                    break

            if not tagged_text:
                tagged_text = f"<u>{underline_core}</u>"

            result_item = {
                "page": page_num + 1,
                "y": line["y"],
                "text": normalized_text,
                "full_text": full_text,
                "tagged_text": tagged_text,
                "class": class_num,
            }

            results.append(result_item)

    doc.close()
    return results


def merge_multiline_underlines(underlines, y_gap=20):
    """ì¤„ë°”ê¿ˆëœ underlineì„ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ ë³‘í•©"""
    underlines = sorted(underlines, key=lambda x: (x["page"], x["y"]))
    merged = []

    buffer = None

    for u in underlines:
        if buffer is None:
            buffer = u.copy()
            continue

        same_page = buffer["page"] == u["page"]
        close_y = abs(u["y"] - buffer["y"]) < y_gap

        no_end = not buffer["text"].strip().endswith((';', '.'))

        if same_page and close_y and no_end:
            buffer["text"] = buffer["text"].rstrip(';') + " " + u["text"].lstrip()

            buffer["tagged_text"] = (
                buffer["tagged_text"].replace("</u>", "") +
                " " +
                u["tagged_text"].replace("<u>", "")
            )

            buffer["y"] = u["y"]
        else:
            merged.append(buffer)
            buffer = u.copy()

    if buffer:
        merged.append(buffer)

    return merged


def extract_goods_from_tagged_text(tagged_text: str) -> list:
    """<u>...</u> ë¸”ë¡ì—ì„œ ìƒí’ˆ ì¶”ì¶œ"""
    goods = []
    underline_blocks = re.findall(r"<u>(.*?)</u>", tagged_text)

    for block in underline_blocks:
        parts = [p.strip() for p in re.split(r"[;]", block) if p.strip()]

        for part in parts:
            goods.append(f"<u>{part}</u>")

    return goods


def match_underlines_to_sections_semicolon(sections, underlines):
    """ì„¹ì…˜ì— ë°‘ì¤„ ë§¤ì¹­ (semicolon ë°©ì‹)"""
    results = []

    for section in sections:
        goods_list = []

        section_underlines = []
        for u in underlines:
            if not (section["page_start"] <= u["page"] <= section["page_end"]):
                continue
            if u["page"] == section["page_start"] and u["y"] < section["y_start"]:
                continue
            if u["page"] == section["page_end"] and u["y"] >= section["y_end"]:
                continue

            section_underlines.append(u)

        section_underlines = merge_multiline_underlines(section_underlines)

        for u in section_underlines:
            ALL_DESIGNATED_PATTERN = re.compile(
                r'(?i)[\'\""\"]?\s*all\s*[\'\""\"]?\s+the\s+designated\s+(goods\s*/\s*services|goods|services)',
                re.VERBOSE
            )
            if ALL_DESIGNATED_PATTERN.search(u.get("full_text", "")):
                g = "<u>all the designated goods/services</u>"
                goods_list.append({
                    "class": u.get("class"),
                    "goods": g
                })
                continue

            goods = extract_goods_from_tagged_text(u["tagged_text"])
            full_goods_parts = [
                p.strip()
                for p in re.split(r"[;.]", u.get("full_text", ""))
                if p.strip()
            ]

            for g in goods:
                core = re.sub(r"</?u>", "", g).strip()

                extended = None
                standalone_exists = any(
                    p.strip().lower() == core.lower()
                    for p in full_goods_parts
                )

                for part in full_goods_parts:
                    if (
                            part.lower().startswith(core.lower() + " ")
                            and not standalone_exists
                    ):
                        extended = part
                        break

                if extended:
                    goods_list.append({
                        "class": u.get("class"),
                        "goods": extended.replace(
                            core,
                            f"<u>{core}</u>",
                            1
                        )
                    })
                else:
                    goods_list.append({
                        "class": u.get("class"),
                        "goods": g
                    })

        results.append({
            "mark_number": section.get("mark_number"),
            "filing_number": section["filing_number"],
            "international_registration": section["international_registration"],
            "underlined_goods": goods_list
        })

    for r in results:
        for item in r["underlined_goods"]:
            item["goods"] = clean_goods_text(item["goods"])

    return results


# ============================================================
# COMMA ë°©ì‹: ì „ì²´ ë¬¸ìì—´ ìœ ì§€, ë°‘ì¤„ ë¶€ë¶„ë§Œ <u> íƒœê·¸
# ============================================================

def extract_goods_with_spans_comma(pdf_path, underlines):
    """
    ',' ê¸°ì¤€ PDFìš©: ì „ì²´ ìƒí’ˆ ë¬¸ìì—´ì—ì„œ ë°‘ì¤„ ë¶€ë¶„ë§Œ <u> íƒœê·¸ ì ìš©
    '.'ìœ¼ë¡œë§Œ ë¶„ë¦¬ (','ëŠ” ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
    """
    doc = fitz.open(pdf_path)
    results = []

    ANCHOR_PATTERN = re.compile(
        r"Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground",
        re.IGNORECASE
    )

    PAGE_NUM_PATTERN = re.compile(r'^\s*-\s*\d+\s*-\s*$')

    def get_underlined_texts_for_page(page, page_num):
        """í˜ì´ì§€ì—ì„œ ë°‘ì¤„ ë°”ë¡œ ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        underlined_texts = []
        page_underlines = [ul for ul in underlines if ul["page"] == page_num]

        for ul in page_underlines:
            clip_rect = fitz.Rect(
                ul["x0"] - 1,
                ul["y"] - 12,
                ul["x1"] + 1,
                ul["y"] + 1
            )
            text = page.get_text("text", clip=clip_rect).strip()
            text = " ".join(text.split())

            if text:
                if should_exclude_underlined_text(text):
                    continue

                underlined_texts.append({
                    "text": text,
                    "y": ul["y"],
                    "x0": ul["x0"],
                    "x1": ul["x1"]
                })

        return underlined_texts

    def apply_underline_tags(full_text, underlined_texts):
        """ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì—ë§Œ <u> íƒœê·¸ ì ìš©"""
        if not underlined_texts:
            return full_text

        tagged_text = full_text

        sorted_ul_texts = sorted(underlined_texts, key=lambda x: len(x["text"]), reverse=True)

        for ul in sorted_ul_texts:
            ul_text = ul["text"]
            if not ul_text:
                continue

            if f"<u>{ul_text}</u>" in tagged_text:
                continue

            if ul_text in tagged_text:
                pattern = re.compile(re.escape(ul_text))
                matches = list(pattern.finditer(tagged_text))

                for match in reversed(matches):
                    start, end = match.start(), match.end()

                    before = tagged_text[:start]
                    if before.count("<u>") > before.count("</u>"):
                        continue

                    tagged_text = tagged_text[:start] + f"<u>{ul_text}</u>" + tagged_text[end:]
                    break

        return tagged_text

    buffer_texts = []
    buffer_page = None
    buffer_y0 = float('inf')
    buffer_y1 = 0
    buffer_underlined_texts = []
    buffer_class = None

    def flush_buffer():
        nonlocal buffer_texts, buffer_page, buffer_y0, buffer_y1, buffer_underlined_texts, buffer_class

        if not buffer_texts:
            return

        full_text = " ".join(buffer_texts)
        full_text = re.sub(r'\s+', ' ', full_text).strip()

        if full_text:
            tagged_text = apply_underline_tags(full_text, buffer_underlined_texts)

            # [Class XX] ì¶”ì¶œ
            class_match = re.search(r'\[Class\s+(\d+)\]', full_text, re.IGNORECASE)
            class_num = class_match.group(1) if class_match else buffer_class

            results.append({
                "page": buffer_page,
                "text": full_text,
                "tagged_text": tagged_text,
                "y0": buffer_y0,
                "y1": buffer_y1,
                "class": class_num,
            })

        buffer_texts = []
        buffer_y0 = float('inf')
        buffer_y1 = 0
        buffer_underlined_texts = []
        buffer_class = None

    def add_to_buffer(text, y0, y1, page, page_underlined_texts):
        nonlocal buffer_page, buffer_y0, buffer_y1, buffer_underlined_texts

        buffer_texts.append(text)
        buffer_page = page
        buffer_y0 = min(buffer_y0, y0)
        buffer_y1 = max(buffer_y1, y1)

        for ul in page_underlined_texts:
            if y0 - 5 <= ul["y"] <= y1 + 5:
                if ul not in buffer_underlined_texts:
                    buffer_underlined_texts.append(ul)

    after_anchor = False

    for page_num, page in enumerate(doc):
        text_dict = page.get_text("dict")
        page_underlined_texts = get_underlined_texts_for_page(page, page_num + 1)

        for block in text_dict["blocks"]:
            if "lines" not in block:
                continue

            for line_obj in block["lines"]:
                for span in line_obj["spans"]:
                    txt = span["text"]
                    bbox = span["bbox"]

                    if not txt.strip():
                        continue

                    if PAGE_NUM_PATTERN.match(txt.strip()):
                        continue

                    if ANCHOR_PATTERN.search(txt):
                        after_anchor = True
                        colon_idx = txt.find(":")
                        if colon_idx != -1 and colon_idx < len(txt) - 1:
                            after_colon = txt[colon_idx + 1:].strip()
                            if after_colon:
                                if '.' in after_colon:
                                    parts = re.split(r'([.])', after_colon)
                                    for part in parts:
                                        if not part:
                                            continue
                                        if part == '.':
                                            flush_buffer()
                                            after_anchor = False
                                        else:
                                            add_to_buffer(part, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                                else:
                                    add_to_buffer(after_colon, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                        continue

                    if not after_anchor:
                        continue

                    # '.'ìœ¼ë¡œë§Œ ë¶„ë¦¬ (','ëŠ” ë¶„ë¦¬ ì•ˆí•¨)
                    if '.' in txt:
                        parts = re.split(r'([.])', txt)
                        for part in parts:
                            if not part:
                                continue
                            if part == '.':
                                flush_buffer()
                                after_anchor = False
                            else:
                                add_to_buffer(part, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                    else:
                        add_to_buffer(txt, bbox[1], bbox[3], page_num + 1, page_underlined_texts)

    flush_buffer()
    doc.close()
    return results


def match_goods_to_sections_comma(sections, tagged_results):
    """ì„¹ì…˜ì— ìƒí’ˆ ë§¤ì¹­ (comma ë°©ì‹)"""
    final_results = []
    used_tagged = set()

    for section in sections:
        page_start = section["page_start"]
        page_end = section["page_end"]
        y_start = section["y_start"]
        y_end = section["y_end"]

        matched_list = []

        for idx, tr in enumerate(tagged_results):
            if idx in used_tagged:
                continue

            tr_page = tr["page"]
            tr_y0 = tr["y0"]

            if tr_page < page_start or tr_page > page_end:
                continue

            is_in_range = False

            if page_start == page_end:
                if y_start <= tr_y0 <= y_end:
                    is_in_range = True
            elif tr_page == page_start:
                if tr_y0 >= y_start:
                    is_in_range = True
            elif tr_page == page_end:
                if tr_y0 <= y_end:
                    is_in_range = True
            else:
                is_in_range = True

            if is_in_range:
                matched_list.append(tr)
                used_tagged.add(idx)

        final_results.append({
            "mark_number": section.get("mark_number"),
            "filing_number": section["filing_number"],
            "international_registration": section["international_registration"],
            "tagged_goods": matched_list
        })

    return final_results


# ============================================================
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================

def process_pdf(pdf_path):
    """
    PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
    - êµ¬ë¶„ì íƒ€ì… ìë™ ê°ì§€ (semicolon vs comma)
    - semicolon: ê°œë³„ ìƒí’ˆ ë¶„ë¦¬, ë°‘ì¤„ ìˆëŠ” ê²ƒë§Œ ì¶”ì¶œ
    - comma: ì „ì²´ ë¬¸ìì—´ ìœ ì§€, ë°‘ì¤„ ë¶€ë¶„ë§Œ <u> íƒœê·¸
    """
    delimiter_type = detect_delimiter_type(pdf_path)
    print(f"ê°ì§€ëœ êµ¬ë¶„ì íƒ€ì…: {delimiter_type}")

    sections = extract_trademark_sections(pdf_path)

    if delimiter_type == 'semicolon':
        # ';' ê¸°ì¤€: ê°œë³„ ìƒí’ˆ ë¶„ë¦¬
        underlines = extract_underlined_with_positions_semicolon(pdf_path)
        final_results = match_underlines_to_sections_semicolon(sections, underlines)

        return {
            "delimiter_type": delimiter_type,
            "sections": sections,
            "final_results": final_results
        }
    else:
        # ',' ê¸°ì¤€: ì „ì²´ ë¬¸ìì—´ ìœ ì§€
        underlines = extract_underlines_only(pdf_path)
        tagged_results = extract_goods_with_spans_comma(pdf_path, underlines)
        final_results = match_goods_to_sections_comma(sections, tagged_results)

        return {
            "delimiter_type": delimiter_type,
            "sections": sections,
            "tagged_results": tagged_results,
            "final_results": final_results
        }


def print_results(data):
    """ê²°ê³¼ ì¶œë ¥"""
    delimiter_type = data.get('delimiter_type', 'unknown')

    print("\n" + "=" * 80)
    print(f"êµ¬ë¶„ì íƒ€ì…: {delimiter_type}")
    print("=" * 80 + "\n")

    if delimiter_type == 'semicolon':
        # ';' ê¸°ì¤€: ê°œë³„ ìƒí’ˆ ëª©ë¡
        for idx, r in enumerate(data['final_results'], 1):
            print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")

            if r['filing_number']:
                print(f"    Filing Number: {r['filing_number']}")
            if r['international_registration']:
                print(f"    International Registration: {r['international_registration']}")

            goods_list = r.get('underlined_goods', [])
            print(f"    Underlined Goods: {len(goods_list)}ê°œ")

            if goods_list:
                print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
                for i, goods_item in enumerate(goods_list, 1):
                    print(f"      {i}. {goods_item['goods']}")
            else:
                print(f"    (ë°‘ì¤„ ì—†ìŒ)")

            print()
    else:
        # ',' ê¸°ì¤€: ì „ì²´ ë¬¸ìì—´
        print("=" * 80)
        print("ğŸ”¥ ìµœì¢… ê²°ê³¼ (ì „ì²´ í…ìŠ¤íŠ¸ + ë°‘ì¤„ íƒœê·¸)")
        print("=" * 80 + "\n")

        for idx, r in enumerate(data['final_results'], 1):
            print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")

            if r['filing_number']:
                print(f"    Filing Number: {r['filing_number']}")
            if r['international_registration']:
                print(f"    International Registration: {r['international_registration']}")

            tagged_goods = r.get('tagged_goods', [])
            if tagged_goods:
                print(f"\n    ìƒí’ˆ ëª©ë¡ (ë°‘ì¤„ ë¶€ë¶„ì— <u> íƒœê·¸):")
                for i, goods_item in enumerate(tagged_goods, 1):
                    class_num = goods_item.get('class')
                    class_prefix = f"[Class {class_num}] " if class_num else ""
                    print(f"      {i}. {class_prefix}{goods_item['tagged_text']}")
            else:
                print(f"    (ìƒí’ˆ ì—†ìŒ)")

            print()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = r"c:\Users\mark\Downloads\ê°€ê±°ì ˆ í†µì§€ì„œ\ê°€ê±°ì ˆ í†µì§€ì„œ\ë¬¸ì œ\552025075453328-02-ë³µì‚¬.pdf"

    if not Path(pdf_path).exists():
        print(f"íŒŒì¼ ì—†ìŒ: {pdf_path}")
        sys.exit(1)

    print("=" * 80)
    print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}\n")

    data = process_pdf(pdf_path)
    print_results(data)
