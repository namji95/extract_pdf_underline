"""
í†µí•© ë¡œì§: ';'ê³¼ '.' ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ (','ëŠ” ë¶„ë¦¬ ê¸°ì¤€ ì•„ë‹˜)
- last_extract_underline.pyì˜ ';'ê³¼ '.' ë¶„ë¦¬ + ì¤„ë°”ê¿ˆ ë³‘í•© ë¡œì§
- test_extract_underline.pyì˜ ë¶€ë¶„ ë°‘ì¤„ ì²˜ë¦¬ + <u> íƒœê·¸ ì ìš© ë¡œì§
PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
"""

import re
import fitz
import sys
from pathlib import Path


def extract_trademark_sections(pdf_path): 
    """
    PDFì—ì„œ 'Information concerning the earlier mark' ì„¹ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ
    ê° ìƒí‘œ(Earlier Mark)ì˜ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """

    doc = fitz.open(pdf_path)
    sections = []
    all_blocks = []

    for page_num, page in enumerate(doc):
        blocks = page.get_text("dict")["blocks"]

        for block in blocks:
            if "lines" not in block:
                continue

            block_text = ""
            for line in block["lines"]:
                for span in line["spans"]:
                    block_text += span["text"] + " "

            block_text = block_text.strip()

            block_info = {
                "page": page_num + 1,
                "y0": block["bbox"][1],
                "y1": block["bbox"][3],
                "text": block_text
            }

            all_blocks.append(block_info)

    # 'Information concerning the earlier mark' ì‹œì‘ì  ì°¾ê¸°
    section_starts = []

    for idx, block in enumerate(all_blocks):
        text = block["text"]
        text_cleaned = text.replace("â–¡", "").replace("â˜", "").strip()

        # íŒ¨í„´ 1: ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš° (1), (2) ...
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*\((\d+)\)",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            mark_number = int(match.group(1))
            section_starts.append({
                "index": idx,
                "mark_number": mark_number,
                "page": block["page"],
                "y": block["y0"]
            })
            continue

        # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ëŠ” ê²½ìš° (ë‹¨ì¼ ìƒí‘œ ë¬¸ì„œ)
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*$",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            section_starts.append({
                "index": idx,
                "mark_number": 1,
                "page": block["page"],
                "y": block["y0"]
            })

    # ì„¹ì…˜ ì‹œì‘ì ì´ ì—†ëŠ” PDF ì²˜ë¦¬
    if not section_starts:
        full_text = " ".join([block["text"] for block in all_blocks])

        filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+(?:Registration|registration)[/\s]+"
            r"Subsequent\s+Designation\s+No[.\s]*:?\s*(\d+)",
            full_text
        )
        international_registration = ir_match.group(1) if ir_match else None

        doc.close()

        return [{
            "mark_number": 1,
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": 1,
            "page_end": all_blocks[-1]["page"] if all_blocks else 1,
            "y_start": 0,
            "y_end": float('inf')
        }]

    # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê³„ì‚° + ì •ë³´ ì¶”ì¶œ
    for i, start in enumerate(section_starts):
        if i + 1 < len(section_starts):
            end_idx = section_starts[i + 1]["index"]
            end_page = section_starts[i + 1]["page"]
            end_y = section_starts[i + 1]["y"]
        else:
            end_idx = len(all_blocks)
            end_page = all_blocks[-1]["page"]
            end_y = all_blocks[-1]["y1"]

        section_text = " ".join(
            all_blocks[j]["text"] for j in range(start["index"], end_idx)
        )

        filing_match = re.search(r"Filing\s+number\s*:\s*(\d+)", section_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+registration\s+number\s*:\s*(\d+)",
            section_text,
            re.IGNORECASE
        )
        international_registration = ir_match.group(1) if ir_match else None

        sections.append({
            "mark_number": start["mark_number"],
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": start["page"],
            "page_end": end_page,
            "y_start": start["y"],
            "y_end": end_y
        })

    doc.close()
    return sections


def extract_underlines_only(pdf_path):
    """
    PDFì—ì„œ ë°‘ì¤„(ìˆ˜í‰ì„ )ë§Œ ì¶”ì¶œ (ì¢Œí‘œ ì •ë³´ë§Œ)
    """
    doc = fitz.open(pdf_path)
    underlines = []

    for page_num, page in enumerate(doc):
        drawings = page.get_drawings()

        for d in drawings:
            for item in d.get("items", []):
                if item[0] == "l":
                    p1, p2 = item[1], item[2]

                    # ìˆ˜í‰ì„  íŒë³„
                    if abs(p1.y - p2.y) < 2:
                        length = abs(p2.x - p1.x)

                        # underline í›„ë³´ ê¸¸ì´ ì œí•œ
                        if 10 < length < 500:
                            underlines.append({
                                "page": page_num + 1,
                                "y": p1.y,
                                "x0": min(p1.x, p2.x),
                                "x1": max(p1.x, p2.x),
                            })

    doc.close()
    return underlines


def extract_goods_with_spans(pdf_path, underlines):
    """
    ì•µì»¤ íŒ¨í„´ ì´í›„ í…ìŠ¤íŠ¸ë¥¼ ';'ê³¼ '.' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³ 
    ë°‘ì¤„ ë¶€ë¶„ì—ë§Œ <u> íƒœê·¸ ì ìš©
    (','ëŠ” ë¶„ë¦¬ ê¸°ì¤€ì´ ì•„ë‹˜ - í•˜ë‚˜ì˜ ìƒí’ˆ ë‚´ì—ì„œ ì‚¬ìš©ë¨)

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        underlines: extract_underlines_only() ê²°ê³¼
    """
    doc = fitz.open(pdf_path)
    results = []

    # ì•µì»¤ íŒ¨í„´ë“¤
    ANCHOR_PATTERNS = [
        re.compile(
            r"Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground",
            re.IGNORECASE
        ),
        re.compile(
            r"\(\s*underlined\s+goods(?:/services)?\s*\)",
            re.IGNORECASE
        ),
    ]

    # í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´ (ì˜ˆ: "- 5 -", "- 6 -")
    PAGE_NUM_PATTERN = re.compile(r'^\s*-\s*\d+\s*-\s*$')

    # êµ¬ë¶„ì: ';'ê³¼ '.'ë§Œ ì‚¬ìš© (','ëŠ” ë¶„ë¦¬ ê¸°ì¤€ ì•„ë‹˜)
    DELIMITER_REGEX = r'([;.])'
    DELIMITERS = [';', '.']

    def get_underlined_texts_for_page(page, page_num):
        """í˜ì´ì§€ì—ì„œ ë°‘ì¤„ ë°”ë¡œ ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        underlined_texts = []
        page_underlines = [ul for ul in underlines if ul["page"] == page_num]

        for ul in page_underlines:
            # ë°‘ì¤„ ë°”ë¡œ ìœ„ ì˜ì—­ (í…ìŠ¤íŠ¸ ë†’ì´ ì•½ 12pt)
            clip_rect = fitz.Rect(
                ul["x0"] - 1,
                ul["y"] - 12,
                ul["x1"] + 1,
                ul["y"] + 1
            )
            text = page.get_text("text", clip=clip_rect).strip()
            text = " ".join(text.split())  # ê³µë°± ì •ë¦¬

            if text:
                # ì œì™¸ ëŒ€ìƒ ì²´í¬
                if should_exclude_underlined_text(text):
                    continue

                underlined_texts.append({
                    "text": text,
                    "y": ul["y"],
                    "x0": ul["x0"],
                    "x1": ul["x1"]
                })

        return underlined_texts

    def apply_underline_tags(full_text, underlined_texts):
        """ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì—ë§Œ <u> íƒœê·¸ ì ìš©"""
        if not underlined_texts:
            return full_text

        tagged_text = full_text

        # ë°‘ì¤„ í…ìŠ¤íŠ¸ë“¤ì„ ê¸¸ì´ìˆœ ì •ë ¬ (ê¸´ ê²ƒ ë¨¼ì € - ë¶€ë¶„ ë§¤ì¹­ ë°©ì§€)
        sorted_ul_texts = sorted(underlined_texts, key=lambda x: len(x["text"]), reverse=True)

        for ul in sorted_ul_texts:
            ul_text = ul["text"]
            if not ul_text:
                continue

            # ì´ë¯¸ íƒœê·¸ëœ ë¶€ë¶„ ê±´ë„ˆë›°ê¸°
            if f"<u>{ul_text}</u>" in tagged_text:
                continue

            # ì •í™•í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­ í›„ íƒœê·¸ ì ìš©
            if ul_text in tagged_text:
                pattern = re.compile(re.escape(ul_text))
                matches = list(pattern.finditer(tagged_text))

                for match in reversed(matches):  # ë’¤ì—ì„œë¶€í„° ì²˜ë¦¬
                    start, end = match.start(), match.end()

                    # ì´ë¯¸ <u> íƒœê·¸ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                    before = tagged_text[:start]
                    if before.count("<u>") > before.count("</u>"):
                        continue  # ì´ë¯¸ íƒœê·¸ ì•ˆì— ìˆìŒ

                    tagged_text = tagged_text[:start] + f"<u>{ul_text}</u>" + tagged_text[end:]
                    break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ ì²˜ë¦¬

        return tagged_text

    # ë²„í¼: í…ìŠ¤íŠ¸ ëˆ„ì  (ì¤„ë°”ê¿ˆ ì²˜ë¦¬ìš©)
    buffer_texts = []
    buffer_page = None
    buffer_y0 = float('inf')
    buffer_y1 = 0
    buffer_underlined_texts = []

    def flush_buffer():
        """ë²„í¼ì— ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ resultsì— ì¶”ê°€"""
        nonlocal buffer_texts, buffer_page, buffer_y0, buffer_y1, buffer_underlined_texts

        if not buffer_texts:
            return

        # í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        full_text = " ".join(buffer_texts)
        full_text = re.sub(r'\s+', ' ', full_text).strip()

        if full_text:
            # ë°‘ì¤„ íƒœê·¸ ì ìš©
            tagged_text = apply_underline_tags(full_text, buffer_underlined_texts)

            results.append({
                "page": buffer_page,
                "text": full_text,
                "tagged_text": tagged_text,
                "y0": buffer_y0,
                "y1": buffer_y1,
            })

        # ì´ˆê¸°í™”
        buffer_texts = []
        buffer_y0 = float('inf')
        buffer_y1 = 0
        buffer_underlined_texts = []

    def add_to_buffer(text, y0, y1, page, page_underlined_texts):
        """í…ìŠ¤íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€"""
        nonlocal buffer_page, buffer_y0, buffer_y1, buffer_underlined_texts

        buffer_texts.append(text)
        buffer_page = page
        buffer_y0 = min(buffer_y0, y0)
        buffer_y1 = max(buffer_y1, y1)

        # í•´ë‹¹ y ë²”ìœ„ì— ìˆëŠ” ë°‘ì¤„ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        for ul in page_underlined_texts:
            if y0 - 5 <= ul["y"] <= y1 + 5:
                if ul not in buffer_underlined_texts:
                    buffer_underlined_texts.append(ul)

    after_anchor = False

    for page_num, page in enumerate(doc):
        text_dict = page.get_text("dict")
        page_underlined_texts = get_underlined_texts_for_page(page, page_num + 1)

        for block in text_dict["blocks"]:
            if "lines" not in block:
                continue

            for line_obj in block["lines"]:
                for span in line_obj["spans"]:
                    txt = span["text"]
                    bbox = span["bbox"]

                    if not txt.strip():
                        continue

                    # í˜ì´ì§€ ë²ˆí˜¸ ìŠ¤í‚µ
                    if PAGE_NUM_PATTERN.match(txt.strip()):
                        continue

                    # ì•µì»¤ íŒ¨í„´ ì°¾ê¸°
                    anchor_found = False
                    for pattern in ANCHOR_PATTERNS:
                        if pattern.search(txt):
                            anchor_found = True
                            break

                    if anchor_found:
                        after_anchor = True
                        # ":" ì´í›„ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                        colon_idx = txt.find(":")
                        if colon_idx != -1 and colon_idx < len(txt) - 1:
                            after_colon = txt[colon_idx + 1:].strip()
                            if after_colon:
                                # ';' ë˜ëŠ” '.'ë¡œ ë¶„ë¦¬
                                parts = re.split(DELIMITER_REGEX, after_colon)
                                for part in parts:
                                    if not part:
                                        continue
                                    if part in DELIMITERS:
                                        flush_buffer()
                                        if part == '.':
                                            after_anchor = False
                                    else:
                                        add_to_buffer(part, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                        continue

                    if not after_anchor:
                        continue

                    # ì•µì»¤ ì´í›„ í…ìŠ¤íŠ¸ ì²˜ë¦¬: ';'ê³¼ '.'ë¡œë§Œ ë¶„ë¦¬
                    if ';' in txt or '.' in txt:
                        parts = re.split(DELIMITER_REGEX, txt)
                        for part in parts:
                            if not part:
                                continue
                            if part in DELIMITERS:
                                flush_buffer()
                                if part == '.':
                                    after_anchor = False
                            else:
                                add_to_buffer(part, bbox[1], bbox[3], page_num + 1, page_underlined_texts)
                    else:
                        # ','ê°€ ìˆì–´ë„ ë¶„ë¦¬í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë²„í¼ì— ì¶”ê°€
                        add_to_buffer(txt, bbox[1], bbox[3], page_num + 1, page_underlined_texts)

    # ë§ˆì§€ë§‰ ë²„í¼ ì²˜ë¦¬
    flush_buffer()

    doc.close()
    return results


def should_exclude_underlined_text(text: str) -> bool:
    """
    ë°‘ì¤„ í…ìŠ¤íŠ¸ê°€ 'ìƒí’ˆ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš°' ì œì™¸í•˜ê¸° ìœ„í•œ íŒë‹¨ í•¨ìˆ˜
    """

    stripped = text.strip()

    # 1. << ... >> í˜•íƒœ (ë©”íƒ€/ì£¼ì„)
    if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
        return True

    # 2. ì—°ë½ì²˜ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    if re.search(r"\b(Fax|Tel\.?|Telephone|E-mail|Email)\b", stripped, re.IGNORECASE):
        return True

    # 3. ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨
    if "@" in stripped:
        return True

    # 4. ì‹¬ì‚¬ê´€ ì§ì±… ë‹¨ë… í…ìŠ¤íŠ¸
    if stripped in ["ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥", "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥"]:
        return True

    # 5. ì‹¬ì‚¬ê´€ ë“± ì§ì±…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” í…ìŠ¤íŠ¸
    if stripped.startswith(('ì‹¬ì‚¬ê´€', 'íŒŒíŠ¸ì¥', 'íŒ€ì¥', 'êµ­ì¥')):
        return True

    # 6. underlined goods ë©”íƒ€ í…ìŠ¤íŠ¸
    if re.search(r"underlined goods", stripped, re.IGNORECASE):
        return True

    return False


def find_all_matching_tagged(sec, tagged_list, used_indices):
    """ì„¹ì…˜ ë²”ìœ„ ë‚´ì— ìˆëŠ” ëª¨ë“  tagged_result ì°¾ê¸°"""
    page_start = sec["page_start"]
    page_end = sec["page_end"]
    y_start = sec["y_start"]
    y_end = sec["y_end"]

    matched = []

    for idx, tr in enumerate(tagged_list):
        if idx in used_indices:
            continue

        tr_page = tr["page"]
        tr_y0 = tr["y0"]

        if tr_page < page_start or tr_page > page_end:
            continue

        is_in_range = False

        if page_start == page_end:
            if y_start <= tr_y0 <= y_end:
                is_in_range = True
        elif tr_page == page_start:
            if tr_y0 >= y_start:
                is_in_range = True
        elif tr_page == page_end:
            if tr_y0 <= y_end:
                is_in_range = True
        else:
            is_in_range = True

        if is_in_range:
            matched.append(tr)
            used_indices.add(idx)

    return matched


def clean_tagged_text(tagged_text):
    """íƒœê·¸ëœ í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not tagged_text:
        return tagged_text

    # applied-for mark ì„¤ëª… ì œê±°
    tagged_text = re.sub(
        r"^\*?\s*Goods/Services\s+of\s+the\s+applied[- ]for\s+mark\s+in\s+relation\s+to\s+this\s+ground:\s*",
        "",
        tagged_text,
        flags=re.IGNORECASE
    )

    # (underlined goods) ì œê±°
    tagged_text = re.sub(r"^\(\s*underlined goods(?:/services)?\s*\)\s*", "", tagged_text, flags=re.IGNORECASE)

    # [Class XX] ì œê±°
    tagged_text = re.sub(
        r"\s*\[\s*Class\s*\d+\s*\]\s*",
        "",
        tagged_text,
        flags=re.IGNORECASE
    )

    # ê³µë°± ì •ë¦¬
    tagged_text = re.sub(r'<u>\s+', '<u>', tagged_text)
    tagged_text = re.sub(r'\s+</u>', '</u>', tagged_text)
    tagged_text = re.sub(r'\s{2,}', ' ', tagged_text)

    return tagged_text.strip()


def process_pdf(pdf_path):
    """
    PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
    - ';'ê³¼ '.' ê¸°ì¤€ìœ¼ë¡œ ìƒí’ˆ ë¶„ë¦¬ (','ëŠ” ë¶„ë¦¬ ê¸°ì¤€ ì•„ë‹˜)
    - ë°‘ì¤„ ì¶”ì¶œ ë° <u> íƒœê·¸ ì ìš©
    - ì„¹ì…˜ ë§¤ì¹­
    """
    # 1. ë°‘ì¤„ ì¢Œí‘œ ì¶”ì¶œ
    underlines = extract_underlines_only(pdf_path)

    # 2. ì„¹ì…˜ ì •ë³´ ì¶”ì¶œ
    sections = extract_trademark_sections(pdf_path)

    # 3. Goods ì¶”ì¶œ + ë°‘ì¤„ íƒœê·¸ (';'ê³¼ '.' ê¸°ì¤€ ë¶„ë¦¬)
    tagged_results = extract_goods_with_spans(pdf_path, underlines)

    # 4. ì„¹ì…˜ì— ë§¤ì¹­
    final_results = []
    used_tagged = set()

    for section in sections:
        matched_list = find_all_matching_tagged(section, tagged_results, used_tagged)

        # íƒœê·¸ëœ í…ìŠ¤íŠ¸ ì •ë¦¬
        for matched in matched_list:
            matched["tagged_text"] = clean_tagged_text(matched["tagged_text"])

        final_results.append({
            "mark_number": section.get("mark_number"),
            "filing_number": section["filing_number"],
            "international_registration": section["international_registration"],
            "tagged_goods": matched_list
        })

    return {
        "sections": sections,
        "tagged_results": tagged_results,
        "final_results": final_results
    }


def print_results(data):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("êµ¬ë¶„ì: ';'ê³¼ '.' ê¸°ì¤€ ë¶„ë¦¬ (','ëŠ” ë¶„ë¦¬ ì•ˆí•¨)")
    print("=" * 80 + "\n")

    print("ğŸ“ ë°‘ì¤„ ë§¤ì¹­ ê²°ê³¼ (<u> íƒœê·¸ ì ìš©):")
    for idx, item in enumerate(data['tagged_results'], 1):
        has_underline = "<u>" in item["tagged_text"]
        mark = "âœ…" if has_underline else "  "
        print(f"  {idx}. {mark} page={item['page']}")
        text_preview = item['text'][:100] + "..." if len(item['text']) > 100 else item['text']
        tagged_preview = item['tagged_text'][:100] + "..." if len(item['tagged_text']) > 100 else item['tagged_text']
        print(f"      ì›ë³¸: {text_preview}")
        print(f"      íƒœê·¸: {tagged_preview}")
    print()

    print("=" * 80)
    print("ğŸ”¥ ìµœì¢… ê²°ê³¼ (ì „ì²´ í…ìŠ¤íŠ¸ + ë°‘ì¤„ íƒœê·¸)")
    print("=" * 80 + "\n")

    for idx, r in enumerate(data['final_results'], 1):
        print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")

        if r['filing_number']:
            print(f"    Filing Number: {r['filing_number']}")
        if r['international_registration']:
            print(f"    International Registration: {r['international_registration']}")

        if r['tagged_goods']:
            print(f"\n    ìƒí’ˆ ëª©ë¡ (ë°‘ì¤„ ë¶€ë¶„ì— <u> íƒœê·¸):")
            for i, goods_item in enumerate(r['tagged_goods'], 1):
                print(f"      {i}. {goods_item['tagged_text']}")
        else:
            print(f"    (ìƒí’ˆ ì—†ìŒ)")

        print()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = r"c:\Users\mark\Downloads\ê°€ê±°ì ˆ í†µì§€ì„œ\ê°€ê±°ì ˆ í†µì§€ì„œ\ë¬¸ì œ\552025075453328-02-ë³µì‚¬.pdf"

    if not Path(pdf_path).exists():
        print(f"íŒŒì¼ ì—†ìŒ: {pdf_path}")
        sys.exit(1)

    print("=" * 80)
    print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}\n")

    data = process_pdf(pdf_path)
    print_results(data)
