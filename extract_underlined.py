# # ì•„ë˜ ë¡œì§ì€ ë°‘ì¤„ ë°ì´í„°ë§Œ ì¶”ì¶œ
# # """
# # PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
# #
# # í•µì‹¬ ì•„ì´ë””ì–´:
# # - PDFëŠ” 'ë°‘ì¤„'ì„ ìŠ¤íƒ€ì¼ ì •ë³´ë¡œ ì €ì¥í•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë§ë‹¤
# # - ëŒ€ì‹  'ìˆ˜í‰ì„ (line drawing)' ê°ì²´ë¡œ ì €ì¥ëœ ê²½ìš°ê°€ ë§ë‹¤
# # - ì´ ìˆ˜í‰ì„  ë°”ë¡œ ìœ„ì— ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼í•œë‹¤
# #
# # í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:
# # pip install pymupdf
# # """
# #
# # import re
# # import fitz           # PyMuPDF: PDF ë‚´ë¶€ êµ¬ì¡°(í…ìŠ¤íŠ¸, ë„í˜•, ì„  ë“±)ë¥¼ ë‹¤ë£° ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
# # import sys            # ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬ìš©
# # from pathlib import Path  # íŒŒì¼ ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš©
# #
# #
# # def extract_underlined(pdf_path):
# #     """
# #     PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì„  ê¸°ë°˜)
# #
# #     pdf_path: ë¶„ì„í•  PDF íŒŒì¼ ê²½ë¡œ
# #     return: [
# #         { "page": í˜ì´ì§€ë²ˆí˜¸, "text": ë°‘ì¤„ì¹œ í…ìŠ¤íŠ¸ },
# #         ...
# #     ]
# #     """
# #
# #     # PDF íŒŒì¼ ì—´ê¸° (ë¬¸ì„œ ê°ì²´ ìƒì„±)
# #     doc = fitz.open(pdf_path)
# #
# #     # ìµœì¢… ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
# #     results = []
# #
# #     # í˜ì´ì§€ ë‹¨ìœ„ë¡œ ìˆœíšŒ
# #     # page_num: 0ë¶€í„° ì‹œì‘í•˜ëŠ” í˜ì´ì§€ ì¸ë±ìŠ¤
# #     # page: ì‹¤ì œ í˜ì´ì§€ ê°ì²´
# #     for page_num, page in enumerate(doc):
# #
# #         # --------------------------------------------------
# #         # 1ï¸âƒ£ ì´ í˜ì´ì§€ì— ê·¸ë ¤ì§„ ëª¨ë“  ë„í˜•(drawing) ê°€ì ¸ì˜¤ê¸°
# #         # --------------------------------------------------
# #         # get_drawings():
# #         # - ì„ (line)
# #         # - ì‚¬ê°í˜•(rect)
# #         # - ê³¡ì„ (curve)
# #         # - ê¸°íƒ€ ê·¸ë˜í”½ ìš”ì†Œ
# #         # ë¥¼ ëª¨ë‘ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
# #         drawings = page.get_drawings()
# #
# #         # ì´ í˜ì´ì§€ì—ì„œ ë°œê²¬ëœ "ìˆ˜í‰ì„ "ë§Œ ëª¨ì•„ë‘˜ ë¦¬ìŠ¤íŠ¸
# #         lines = []
# #
# #         # ê° drawing ê°ì²´ ìˆœíšŒ
# #         for d in drawings:
# #             # drawing ë‚´ë¶€ì—ëŠ” ì‹¤ì œ ê·¸ë˜í”½ ëª…ë ¹ë“¤ì´ itemsë¡œ ë“¤ì–´ ìˆìŒ
# #             for item in d.get("items", []):
# #
# #                 # item êµ¬ì¡° ì˜ˆ:
# #                 # ("l", Point(x1,y1), Point(x2,y2)) â†’ ì„ (line)
# #                 # ì²« ë²ˆì§¸ ê°’ item[0] == "l" ì´ë©´ ì„ 
# #                 if item[0] == "l":
# #                     p1, p2 = item[1], item[2]  # ì„ ì˜ ì‹œì‘ì , ëì 
# #
# #                     # --------------------------------------------------
# #                     # ìˆ˜í‰ì„  íŒë³„
# #                     # --------------------------------------------------
# #                     # y ì¢Œí‘œ ì°¨ì´ê°€ ê±°ì˜ ì—†ìœ¼ë©´ ìˆ˜í‰ì„ ìœ¼ë¡œ ê°„ì£¼
# #                     # (PDF ì¢Œí‘œê³„ì—ì„œëŠ” ì†Œìˆ˜ì  ì˜¤ì°¨ê°€ ìˆìœ¼ë¯€ë¡œ < 2 ì •ë„ í—ˆìš©)
# #                     if abs(p1.y - p2.y) < 2:
# #
# #                         # ì„ ì˜ ê¸¸ì´ ê³„ì‚° (xì¶• ë°©í–¥)
# #                         length = abs(p2.x - p1.x)
# #
# #                         # --------------------------------------------------
# #                         # ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸´ ì„ ì€ ì œì™¸
# #                         # - 10px ë¯¸ë§Œ: ê¸€ì ë°‘ì¤„ì´ ì•„ë‹ ê°€ëŠ¥ì„±
# #                         # - 500px ì´ˆê³¼: í‘œ, êµ¬ë¶„ì„ ì¼ ê°€ëŠ¥ì„±
# #                         # --------------------------------------------------
# #                         if 10 < length < 500:
# #                             lines.append({
# #                                 # ì„ ì˜ y ì¢Œí‘œ (ë°‘ì¤„ ìœ„ì¹˜)
# #                                 "y": p1.y,
# #
# #                                 # ì„ ì˜ ì‹œì‘ x
# #                                 "x0": min(p1.x, p2.x),
# #
# #                                 # ì„ ì˜ ë x
# #                                 "x1": max(p1.x, p2.x)
# #                             })
# #
# #         # --------------------------------------------------
# #         # 2ï¸âƒ£ ê° ìˆ˜í‰ì„  ë°”ë¡œ ìœ„ì— ìˆëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #         # --------------------------------------------------
# #         for line in lines:
# #             # í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ì˜ì—­(Rect) ì •ì˜
# #             #
# #             # ì™œ ì´ë ‡ê²Œ ì¡ë‚˜?
# #             # - ë°‘ì¤„ì€ ë³´í†µ í…ìŠ¤íŠ¸ ë°”ë¡œ "ì•„ë˜"ì— ìˆìŒ
# #             # - ê·¸ë˜ì„œ ì„  ê¸°ì¤€ìœ¼ë¡œ ìœ„ìª½(y-12) ì˜ì—­ì„ ì˜ë¼ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ìŒ
# #             rect = fitz.Rect(
# #                 line["x0"] - 1,     # ì¢Œì¸¡ ì—¬ìœ 
# #                 line["y"] - 12,     # ì„  ìœ„ìª½ ì˜ì—­
# #                 line["x1"] + 1,     # ìš°ì¸¡ ì—¬ìœ 
# #                 line["y"] + 1       # ì„  ë°”ë¡œ ìœ„ê¹Œì§€
# #             )
# #
# #             # í•´ë‹¹ ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #             # "text" ì˜µì…˜ â†’ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
# #             text = page.get_text("text", clip=rect).strip()
# #
# #             # ì—¬ëŸ¬ ì¤„/ê³µë°±ì„ í•œ ì¤„ë¡œ ì •ë¦¬
# #             text = " ".join(text.split())
# #
# #             # â­ ì„¤ëª…ìš© prefix ì œê±°
# #             text = normalize_underlined_text(text)
# #
# #             # ì˜ë¯¸ ì—†ëŠ” ê°’ ì œì™¸
# #             # - ë¹ˆ ë¬¸ìì—´
# #             # - í•œ ê¸€ì ì´í•˜
# #             if text and len(text) > 1 and not should_exclude_underlined_text(text):
# #                 results.append({
# #                     "page": page_num + 1, # ì‚¬ëŒ ê¸°ì¤€ í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„°)
# #                     "text": text
# #                 })
# #
# #     # PDF ë‹«ê¸° (ë¦¬ì†ŒìŠ¤ í•´ì œ)
# #     doc.close()
# #
# #     return results
# #
# #
# # def normalize_underlined_text(text: str) -> str:
# #     """
# #     ë°‘ì¤„ í…ìŠ¤íŠ¸ì—ì„œ
# #     - ìƒí’ˆê³¼ ë¬´ê´€í•œ ì„¤ëª…ìš© prefix ì œê±°
# #     - goods/services ë¡œ ëë‚˜ëŠ” ìƒí’ˆì€ ì„¸ë¯¸ì½œë¡  ë³´ì •
# #     """
# #
# #     original = text
# #     text = text.strip()
# #
# #     # --------------------------------------------------
# #     # 1ï¸âƒ£ (underlined goods/services) prefix ì œê±°
# #     # --------------------------------------------------
# #     text = re.sub(
# #         r"^\(\s*underlined goods/services\s*\)\s*",
# #         "",
# #         text,
# #         flags=re.IGNORECASE
# #     )
# #
# #     # --------------------------------------------------
# #     # 2ï¸âƒ£ goods/services ë¡œ ëë‚˜ëŠ” ê²½ìš° ì„¸ë¯¸ì½œë¡  ë³´ì •
# #     # --------------------------------------------------
# #     # ì¡°ê±´:
# #     # - prefix ì œê±° í›„ ê²°ê³¼ì— ì ìš©
# #     # - ì´ë¯¸ ; ë˜ëŠ” . ìœ¼ë¡œ ëë‚˜ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
# #     # - ì •í™•íˆ goods/services ë¡œ "ëë‚˜ëŠ”" ê²½ìš°ë§Œ
# #     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
# #         if not text.rstrip().endswith((';', '.')):
# #             text = text.rstrip() + ";"
# #
# #     return text.strip()
# #
# #
# #
# # def should_exclude_underlined_text(text: str) -> bool:
# #     """
# #     ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¤‘ 'ë¬´ì¡°ê±´ ì œê±°í•´ì•¼ í•˜ëŠ” ê²ƒ'ë§Œ ê±¸ëŸ¬ë‚¸ë‹¤.
# #     ìƒí’ˆ ì—¬ë¶€ íŒë‹¨ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.
# #     """
# #
# #     stripped = text.strip()
# #
# #     # 1ï¸âƒ£ << ... >> í˜•íƒœì˜ ì„¹ì…˜/UI í—¤ë” ì œê±°
# #     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
# #         return True
# #
# #     # 2ï¸âƒ£ ì´ë©”ì¼ / ì—°ë½ì²˜ ë¼ì¸ ì œê±° (ë¼ì¸ ì‹œì‘ ê¸°ì¤€)
# #     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
# #         return True
# #
# #     # 3ï¸âƒ£ ì´ë©”ì¼ ì£¼ì†Œê°€ í¬í•¨ëœ ë‹¨ë… ë¼ì¸ ì œê±°
# #     if "@" in stripped:
# #         return True
# #
# #     # 4ï¸âƒ£ ì‹¬ì‚¬ê´€ ì§í•¨ ë¼ì¸ ì œê±° (ëª…ì‹œì  ë¬¸ìì—´ ë§¤ì¹­)
# #     # ğŸ‘‰ ì—¬ê¸°ì„œëŠ” 'íŒë‹¨'ì´ ì•„ë‹ˆë¼ 'ì§€ì • ì œê±°'
# #     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
# #         return True
# #
# #     return False
# #
# #
# # def merge_by_semicolon(results):
# #     """
# #     ë°‘ì¤„ ì¶”ì¶œ ê²°ê³¼(results)ë¥¼ ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.) ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•œë‹¤.
# #
# #     results ì…ë ¥ í˜•íƒœ:
# #     [
# #         {"page": 2, "text": "provision of"},
# #         {"page": 2, "text": "space on web sites for advertising goods and services;"},
# #         {"page": 3, "text": "jewellery;"},
# #         ...
# #     ]
# #
# #     ë°˜í™˜ í˜•íƒœ:
# #     [
# #         {"page": 2, "text": "provision of space on web sites for advertising goods and services"},
# #         {"page": 3, "text": "jewellery"},
# #         ...
# #     ]
# #
# #     í•µì‹¬ ê°œë…:
# #     - PDFì—ì„œëŠ” í•œ ìƒí’ˆëª…ì´ ì—¬ëŸ¬ ì¤„ë¡œ ëŠì–´ì ¸ ìˆì„ ìˆ˜ ìˆë‹¤
# #     - ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.)ëŠ” 'ìƒí’ˆ í•˜ë‚˜ì˜ ì¢…ë£Œ'ë¥¼ ì˜ë¯¸í•œë‹¤
# #     - ë”°ë¼ì„œ í•´ë‹¹ ê¸°í˜¸ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ í…ìŠ¤íŠ¸ë¥¼ ëˆ„ì í•œë‹¤
# #     """
# #
# #     # ìµœì¢… ë³‘í•© ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
# #     merged = []
# #
# #     # í˜„ì¬ ìƒí’ˆì„ êµ¬ì„± ì¤‘ì¸ ì„ì‹œ ë²„í¼
# #     # ì—¬ëŸ¬ ì¤„ì„ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ í•©ì¹  ë•Œ ì‚¬ìš©
# #     current_text = ""
# #
# #     # í˜„ì¬ ë²„í¼ì— ë‹´ê¸´ í…ìŠ¤íŠ¸ê°€ ì†í•œ í˜ì´ì§€ ë²ˆí˜¸
# #     # í˜ì´ì§€ ë³€ê²½ ì‹œ ë²„í¼ë¥¼ ê°•ì œë¡œ í™•ì •í•˜ê¸° ìœ„í•´ í•„ìš”
# #     current_page = None
# #
# #     # ì¶”ì¶œëœ ë°‘ì¤„ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆœíšŒ
# #     # resultsëŠ” PDF ìƒì—ì„œ ì½ì€ ìˆœì„œë¥¼ ìœ ì§€í•´ì•¼ í•¨
# #     for item in results:
# #
# #         # í˜„ì¬ ì¤„ì˜ í…ìŠ¤íŠ¸ (ë°‘ì¤„ë¡œ ì¶”ì¶œëœ ë‹¨ìœ„)
# #         text = item["text"]
# #
# #         # í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ ìœ„ì¹˜í•œ í˜ì´ì§€ ë²ˆí˜¸
# #         page = item["page"]
# #
# #         # --------------------------------------------------
# #         # 1ï¸âƒ£ í˜ì´ì§€ ë³€ê²½ ê°ì§€
# #         # --------------------------------------------------
# #         # ì´ì „ ì¤„ê³¼ í˜„ì¬ ì¤„ì˜ í˜ì´ì§€ê°€ ë‹¤ë¥´ë©´
# #         # â†’ ì´ì „ í˜ì´ì§€ì—ì„œ ëˆ„ì  ì¤‘ì´ë˜ ìƒí’ˆì„ ê°•ì œë¡œ í™•ì •
# #         if current_page is not None and page != current_page:
# #
# #             # ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ê²°ê³¼ë¡œ ì¶”ê°€
# #             if current_text:
# #                 merged.append({
# #                     "page": current_page,
# #                     # â­ ë§ˆì§€ë§‰ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
# #                     "text": current_text.rstrip(";.").strip()
# #                 })
# #
# #                 # ë²„í¼ ì´ˆê¸°í™”
# #                 current_text = ""
# #
# #         # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í˜ì´ì§€ ë²ˆí˜¸ ê°±ì‹ 
# #         current_page = page
# #
# #         # --------------------------------------------------
# #         # 2ï¸âƒ£ í…ìŠ¤íŠ¸ ëˆ„ì 
# #         # --------------------------------------------------
# #         # ì´ë¯¸ ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´
# #         # â†’ ê³µë°±ì„ í•˜ë‚˜ ë„£ê³  ì´ì–´ ë¶™ì„
# #         if current_text:
# #             current_text += " " + text
# #         else:
# #             # ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸ê°€ ì—†ë‹¤ë©´ ìƒˆë¡œ ì‹œì‘
# #             current_text = text
# #
# #         # --------------------------------------------------
# #         # 3ï¸âƒ£ ìƒí’ˆ ì¢…ë£Œ ì¡°ê±´ íŒë‹¨
# #         # --------------------------------------------------
# #         # ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.)ë¡œ ëë‚˜ë©´
# #         # â†’ í•˜ë‚˜ì˜ ìƒí’ˆì´ ì™„ì„±ë˜ì—ˆë‹¤ê³  íŒë‹¨
# #         if current_text.endswith(";") or current_text.endswith("."):
# #
# #             # ì™„ì„±ëœ ìƒí’ˆì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
# #             merged.append({
# #                 "page": current_page,
# #                 # â­ ë§ˆì§€ë§‰ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
# #                 "text": current_text.rstrip(";.").strip()
# #             })
# #
# #             # ë‹¤ìŒ ìƒí’ˆì„ ìœ„í•´ ë²„í¼ ì´ˆê¸°í™”
# #             current_text = ""
# #
# #     # --------------------------------------------------
# #     # 4ï¸âƒ£ ë£¨í”„ ì¢…ë£Œ í›„ ë‚¨ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
# #     # --------------------------------------------------
# #     # íŒŒì¼ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œëŠ”
# #     # ì„¸ë¯¸ì½œë¡  ì—†ì´ ëë‚˜ëŠ” ìƒí’ˆì´ ìˆì„ ìˆ˜ ìˆìŒ
# #     if current_text:
# #         merged.append({
# #             "page": current_page,
# #             # â­ ë§ˆì§€ë§‰ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
# #             "text": current_text.rstrip(";.").strip()
# #         })
# #
# #     # ë³‘í•©ëœ ìµœì¢… ê²°ê³¼ ë°˜í™˜
# #     return merged
# #
# #
# # def split_products(merged_results):
# #     """
# #     ë³‘í•©ëœ ìƒí’ˆ í…ìŠ¤íŠ¸ì—ì„œ ì„¸ë¯¸ì½œë¡ (;) ê¸°ì¤€ìœ¼ë¡œ
# #     ê°œë³„ ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ëŠ” í•¨ìˆ˜.
# #
# #     merged_results ì…ë ¥ í˜•íƒœ:
# #     [
# #         {"page": 11, "text": "Office furniture; desks; tea tables"},
# #         {"page": 11, "text": "book shelves rocking chairs"},
# #         ...
# #     ]
# #
# #     ë°˜í™˜ í˜•íƒœ:
# #     [
# #         {"page": 11, "text": "Office furniture"},
# #         {"page": 11, "text": "desks"},
# #         {"page": 11, "text": "tea tables"},
# #         {"page": 11, "text": "book shelves rocking chairs"},
# #         ...
# #     ]
# #
# #     í•µì‹¬ ê°œë…:
# #     - merge_by_semicolon ë‹¨ê³„ì—ì„œëŠ”
# #       "ì¤„ ê¹¨ì§(line break)"ë§Œ í•´ê²°í•œë‹¤.
# #     - í•˜ì§€ë§Œ í•œ ì¤„ ì•ˆì— ì—¬ëŸ¬ ìƒí’ˆì´ ë“¤ì–´ ìˆëŠ” ê²½ìš°ê°€ ë§ë‹¤.
# #     - ì´ í•¨ìˆ˜ëŠ” ì„¸ë¯¸ì½œë¡ (;)ì„
# #       "ìƒí’ˆê³¼ ìƒí’ˆì„ ë‚˜ëˆ„ëŠ” êµ¬ë¶„ì"ë¡œ ì‚¬ìš©í•˜ì—¬
# #       ìµœì¢… ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„í•´í•œë‹¤.
# #     """
# #
# #     # ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
# #     # ê° ìš”ì†ŒëŠ” {page, text} í˜•íƒœì˜ ë‹¨ì¼ ìƒí’ˆ
# #     final_results = []
# #
# #     # ë³‘í•©ëœ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆœíšŒ
# #     # ì´ ìˆœì„œëŠ” PDF ì›ë¬¸ì— ë‚˜íƒ€ë‚œ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•¨
# #     for item in merged_results:
# #
# #         # í•´ë‹¹ ìƒí’ˆì´ ë“±ì¥í•œ í˜ì´ì§€ ë²ˆí˜¸
# #         # (merge ë‹¨ê³„ì—ì„œ ì´ë¯¸ í™•ì •ëœ ê°’)
# #         page = item["page"]
# #
# #         # ë³‘í•©ëœ ìƒí’ˆ í…ìŠ¤íŠ¸
# #         # ì˜ˆ: "Office furniture; desks; tea tables"
# #         text = item["text"]
# #
# #         # --------------------------------------------------
# #         # 1ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë¶„í•´
# #         # --------------------------------------------------
# #         # split(";"):
# #         #   "Office furniture; desks; tea tables"
# #         # â†’ ["Office furniture", " desks", " tea tables"]
# #         #
# #         # strip():
# #         #   ê° ì¡°ê°ì˜ ì•ë’¤ ê³µë°± ì œê±°
# #         #
# #         # if p.strip():
# #         #   ë¹ˆ ë¬¸ìì—´ ì œê±°
# #         parts = [
# #             p.strip()
# #             for p in text.split(";")
# #             if p.strip()
# #         ]
# #
# #         # --------------------------------------------------
# #         # 2ï¸âƒ£ ê°œë³„ ìƒí’ˆ ë‹¨ìœ„ë¡œ ê²°ê³¼ ìƒì„±
# #         # --------------------------------------------------
# #         # í•˜ë‚˜ì˜ merged itemì—ì„œ
# #         # ì—¬ëŸ¬ ê°œì˜ ìµœì¢… ìƒí’ˆì´ ë§Œë“¤ì–´ì§ˆ ìˆ˜ ìˆìŒ
# #         for part in parts:
# #             final_results.append({
# #                 "page": page,  # ì›ë³¸ í˜ì´ì§€ ë²ˆí˜¸ ìœ ì§€
# #                 "text": part   # ìµœì¢… ìƒí’ˆëª… (ì„¸ë¯¸ì½œë¡  ì œê±°ë¨)
# #             })
# #
# #     # ì„¸ë¯¸ì½œë¡  ë¶„í•´ê°€ ì™„ë£Œëœ ìµœì¢… ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
# #     return final_results
# #
# #
# # def main(pdf_path):
# #     """
# #     ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ìš© ë©”ì¸ í•¨ìˆ˜
# #     """
# #
# #     print(f"íŒŒì¼: {pdf_path}")
# #     print("-" * 50)
# #
# #     # ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰
# #     results = extract_underlined(pdf_path)
# #     # 1ï¸âƒ£ ì¤„ ê¹¨ì§ ë³‘í•©
# #     merged_results = merge_by_semicolon(results)
# #     # 2ï¸âƒ£ í•œ ì¤„ ë‚´ ë‹¤ì¤‘ ìƒí’ˆ ë¶„í•´
# #     final_results = split_products(merged_results)
# #
# #
# #     # ê²°ê³¼ ì¶œë ¥
# #     if final_results:
# #         for r in final_results:
# #             print(f"[p{r['page']}] {r['text']}")
# #         print(f"\nì´ {len(results)}ê°œ ë°‘ì¤„ ë°œê²¬")
# #     else:
# #         print("ë°‘ì¤„ ì—†ìŒ")
# #
# #     return final_results
# #
# #
# # if __name__ == "__main__":
# #     # --------------------------------------------------
# #     # ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬
# #     # --------------------------------------------------
# #     # python extract.py sample.pdf
# #     if len(sys.argv) > 1:
# #         path = sys.argv[1]
# #     else:
# #         # ì¸ìê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
# #         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ë™ì¼ìœ ì‚¬_1ìƒí‘œ1ì¶œì›1.pdf"
# #
# #     # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
# #     if not Path(path).exists():
# #         print(f"íŒŒì¼ ì—†ìŒ: {path}")
# #         sys.exit(1)
# #
# #     # ì‹¤í–‰
# #     main(path)
#
#
#
# # ì•„ë˜ ë¡œì§ì€ ë°‘ì¤„ì´ í¬í•¨ëœ ë°ì´í„° ì¶”ì¶œ
# # """
# # PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# # í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# # """
# #
# # import re
# # import fitz
# # import sys
# # from pathlib import Path
# # from typing import List, Dict, Optional
# #
# #
# # def extract_trademark_sections(pdf_path):
# #     """
# #     PDFì—ì„œ ìƒí‘œ ì •ë³´ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ì—¬ ê° ì„¹ì…˜ì˜ ë²”ìœ„ë¥¼ íŒŒì•…
# #
# #     return: [
# #         {
# #             "mark_number": 1,
# #             "filing_number": "4120080005100",
# #             "international_registration": None,
# #             "page_start": 2,
# #             "page_end": 2,
# #             "y_start": 200.5,
# #             "y_end": 450.3,
# #             "owner": "Han Nam Hee"
# #         },
# #         ...
# #     ]
# #     """
# #     doc = fitz.open(pdf_path)
# #     sections = []
# #
# #     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
# #     all_blocks = []
# #     for page_num, page in enumerate(doc):
# #         blocks = page.get_text("dict")["blocks"]
# #         for block in blocks:
# #             if "lines" in block:
# #                 block_text = ""
# #                 for line in block["lines"]:
# #                     for span in line["spans"]:
# #                         block_text += span["text"] + " "
# #
# #                 all_blocks.append({
# #                     "page": page_num + 1,
# #                     "y0": block["bbox"][1],
# #                     "y1": block["bbox"][3],
# #                     "text": block_text.strip()
# #                 })
# #
# #     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
# #     section_starts = []
# #     for idx, block in enumerate(all_blocks):
# #         match = re.search(
# #             r"Information concerning the earlier mark \((\d+)\)",
# #             block["text"],
# #             re.IGNORECASE
# #         )
# #         if match:
# #             section_starts.append({
# #                 "index": idx,
# #                 "mark_number": int(match.group(1)),
# #                 "page": block["page"],
# #                 "y": block["y0"]
# #             })
# #
# #     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
# #     for i, start in enumerate(section_starts):
# #         # ì„¹ì…˜ ë ì§€ì  ê²°ì •
# #         if i + 1 < len(section_starts):
# #             end_idx = section_starts[i + 1]["index"]
# #             end_page = section_starts[i + 1]["page"]
# #             end_y = section_starts[i + 1]["y"]
# #         else:
# #             end_idx = len(all_blocks)
# #             end_page = all_blocks[-1]["page"]
# #             end_y = all_blocks[-1]["y1"]
# #
# #         # í•´ë‹¹ ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
# #         section_text = " ".join([
# #             all_blocks[j]["text"]
# #             for j in range(start["index"], end_idx)
# #         ])
# #
# #         # Filing number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
# #         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
# #         filing_number = filing_match.group(1) if filing_match else None
# #
# #         # International registration number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
# #         ir_match = re.search(
# #             r"International registration number\s*:\s*(\d+)",
# #             section_text
# #         )
# #         international_registration = ir_match.group(1) if ir_match else None
# #
# #         # Owner ì •ë³´ ì¶”ì¶œ
# #         owner_match = re.search(
# #             r"Name and address of the owner\s*:\s*([^\n]+)",
# #             section_text
# #         )
# #         owner = owner_match.group(1).strip() if owner_match else "Unknown"
# #
# #         sections.append({
# #             "mark_number": start["mark_number"],
# #             "filing_number": filing_number,
# #             "international_registration": international_registration,
# #             "page_start": start["page"],
# #             "page_end": end_page,
# #             "y_start": start["y"],
# #             "y_end": end_y,
# #             "owner": owner
# #         })
# #
# #     doc.close()
# #     return sections
# #
# #
# # def extract_underlined_with_positions(pdf_path):
# #     """
# #     PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ
# #
# #     return: [
# #         {"page": 2, "y": 350.5, "text": "Advertising"},
# #         {"page": 2, "y": 365.2, "text": "presentation of goods..."},
# #         ...
# #     ]
# #     """
# #     doc = fitz.open(pdf_path)
# #     results = []
# #
# #     for page_num, page in enumerate(doc):
# #         drawings = page.get_drawings()
# #         lines = []
# #
# #         # ìˆ˜í‰ì„  ì°¾ê¸°
# #         for d in drawings:
# #             for item in d.get("items", []):
# #                 if item[0] == "l":
# #                     p1, p2 = item[1], item[2]
# #                     if abs(p1.y - p2.y) < 2:
# #                         length = abs(p2.x - p1.x)
# #                         if 10 < length < 500:
# #                             lines.append({
# #                                 "y": p1.y,
# #                                 "x0": min(p1.x, p2.x),
# #                                 "x1": max(p1.x, p2.x)
# #                             })
# #
# #         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #         for line in lines:
# #             rect = fitz.Rect(
# #                 line["x0"] - 1,
# #                 line["y"] - 12,
# #                 line["x1"] + 1,
# #                 line["y"] + 1
# #             )
# #             text = page.get_text("text", clip=rect).strip()
# #             text = " ".join(text.split())
# #             text = normalize_underlined_text(text)
# #
# #             if text and len(text) > 1 and not should_exclude_underlined_text(text):
# #                 results.append({
# #                     "page": page_num + 1,
# #                     "y": line["y"],
# #                     "text": text
# #                 })
# #
# #     doc.close()
# #     return results
# #
# #
# # def normalize_underlined_text(text: str) -> str:
# #     """ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
# #     text = text.strip()
# #     text = re.sub(
# #         r"^\(\s*underlined goods/services\s*\)\s*",
# #         "",
# #         text,
# #         flags=re.IGNORECASE
# #     )
# #     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
# #         if not text.rstrip().endswith((';', '.')):
# #             text = text.rstrip() + ";"
# #     return text.strip()
# #
# #
# # def should_exclude_underlined_text(text: str) -> bool:
# #     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
# #     stripped = text.strip()
# #     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
# #         return True
# #     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
# #         return True
# #     if "@" in stripped:
# #         return True
# #     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
# #         return True
# #     return False
# #
# #
# # def match_underlines_to_sections(sections, underlines):
# #     """
# #     ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­
# #
# #     sections: extract_trademark_sections() ê²°ê³¼
# #     underlines: extract_underlined_with_positions() ê²°ê³¼
# #
# #     return: [
# #         {
# #             "mark_number": 1,
# #             "filing_number": "4120080005100",
# #             "international_registration": None,
# #             "owner": "Han Nam Hee",
# #             "underlined_goods": ["Advertising", "presentation of goods...", ...]
# #         },
# #         ...
# #     ]
# #     """
# #     results = []
# #
# #     for section in sections:
# #         # ì´ ì„¹ì…˜ì— ì†í•˜ëŠ” ë°‘ì¤„ ì°¾ê¸°
# #         section_underlines = []
# #
# #         for u in underlines:
# #             # í˜ì´ì§€ì™€ yì¢Œí‘œë¡œ ë²”ìœ„ íŒë‹¨
# #             in_page_range = (
# #                     section["page_start"] <= u["page"] <= section["page_end"]
# #             )
# #
# #             if in_page_range:
# #                 # ê°™ì€ í˜ì´ì§€ì¼ ê²½ìš° yì¢Œí‘œë„ í™•ì¸
# #                 if u["page"] == section["page_start"]:
# #                     if u["y"] < section["y_start"]:
# #                         continue
# #                 if u["page"] == section["page_end"]:
# #                     if u["y"] > section["y_end"]:
# #                         continue
# #
# #                 section_underlines.append(u)
# #
# #         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
# #         if section_underlines:
# #             merged = merge_by_semicolon(section_underlines)
# #             final_goods = split_products(merged)
# #             goods_list = [item["text"] for item in final_goods]
# #         else:
# #             goods_list = []
# #
# #         results.append({
# #             "mark_number": section["mark_number"],
# #             "filing_number": section["filing_number"],
# #             "international_registration": section["international_registration"],
# #             "owner": section["owner"],
# #             "page_range": f"{section['page_start']}-{section['page_end']}",
# #             "underlined_goods": goods_list
# #         })
# #
# #     return results
# #
# #
# # def merge_by_semicolon(results):
# #     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•©"""
# #     merged = []
# #     current_text = ""
# #     current_page = None
# #
# #     for item in results:
# #         text = item["text"]
# #         page = item["page"]
# #
# #         if current_page is not None and page != current_page:
# #             if current_text:
# #                 merged.append({
# #                     "page": current_page,
# #                     "text": current_text.rstrip(";.").strip()
# #                 })
# #                 current_text = ""
# #
# #         current_page = page
# #
# #         if current_text:
# #             current_text += " " + text
# #         else:
# #             current_text = text
# #
# #         if current_text.endswith(";") or current_text.endswith("."):
# #             merged.append({
# #                 "page": current_page,
# #                 "text": current_text.rstrip(";.").strip()
# #             })
# #             current_text = ""
# #
# #     if current_text:
# #         merged.append({
# #             "page": current_page,
# #             "text": current_text.rstrip(";.").strip()
# #         })
# #
# #     return merged
# #
# #
# # def split_products(merged_results):
# #     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´"""
# #     final_results = []
# #     for item in merged_results:
# #         page = item["page"]
# #         text = item["text"]
# #         parts = [p.strip() for p in text.split(";") if p.strip()]
# #         for part in parts:
# #             final_results.append({
# #                 "page": page,
# #                 "text": part
# #             })
# #     return final_results
# #
# #
# # def print_results(results):
# #     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
# #     print("\n" + "=" * 80)
# #     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
# #     print("=" * 80 + "\n")
# #
# #     for idx, r in enumerate(results, 1):
# #         print(f"[{idx}] ìƒí‘œ ì •ë³´")
# #         print(f"    Mark Number: {r['mark_number']}")
# #
# #         if r['filing_number']:
# #             print(f"    Filing Number: {r['filing_number']}")
# #         if r['international_registration']:
# #             print(f"    International Registration: {r['international_registration']}")
# #
# #         print(f"    Owner: {r['owner']}")
# #         print(f"    Page Range: {r['page_range']}")
# #         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
# #
# #         if r['underlined_goods']:
# #             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
# #             for i, goods in enumerate(r['underlined_goods'], 1):
# #                 print(f"      {i}. {goods}")
# #         else:
# #             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
# #
# #         print()
# #
# #
# # def main(pdf_path):
# #     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
# #     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
# #     print("=" * 80)
# #
# #     # 1ë‹¨ê³„: ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ
# #     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
# #     sections = extract_trademark_sections(pdf_path)
# #     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
# #
# #     # 2ë‹¨ê³„: ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
# #     underlines = extract_underlined_with_positions(pdf_path)
# #     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
# #
# #     # 3ë‹¨ê³„: ë§¤ì¹­
# #     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
# #     results = match_underlines_to_sections(sections, underlines)
# #     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
# #
# #     # ê²°ê³¼ ì¶œë ¥
# #     print_results(results)
# #
# #     return results
# #
# #
# # if __name__ == "__main__":
# #     if len(sys.argv) > 1:
# #         path = sys.argv[1]
# #     else:
# #         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ë™ì¼ìœ ì‚¬_1ìƒí‘œ1ì¶œì›1.pdf"
# #
# #     if not Path(path).exists():
# #         print(f"íŒŒì¼ ì—†ìŒ: {path}")
# #         sys.exit(1)
# #
# #     main(path)
#
# """
# PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# """
#
# import re
# import fitz
# import sys
# from pathlib import Path
# from typing import List, Dict, Optional
#
#
# def extract_trademark_sections(pdf_path):
#     """
#     PDFì—ì„œ ìƒí‘œ ì •ë³´ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ì—¬ ê° ì„¹ì…˜ì˜ ë²”ìœ„ë¥¼ íŒŒì•…
#
#     return: [
#         {
#             "filing_number": "4120080005100",
#             "international_registration": None,
#             "page_start": 2,
#             "page_end": 2,
#             "y_start": 200.5,
#             "y_end": 450.3
#         },
#         ...
#     ]
#     """
#     doc = fitz.open(pdf_path)
#     sections = []
#
#     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" in block:
#                 block_text = ""
#                 for line in block["lines"]:
#                     for span in line["spans"]:
#                         block_text += span["text"] + " "
#
#                 all_blocks.append({
#                     "page": page_num + 1,
#                     "y0": block["bbox"][1],
#                     "y1": block["bbox"][3],
#                     "text": block_text.strip()
#                 })
#
#     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
#     # ë‘ ê°€ì§€ íŒ¨í„´ ëª¨ë‘ ì§€ì›: ë²ˆí˜¸ ìˆìŒ/ì—†ìŒ
#     section_starts = []
#     for idx, block in enumerate(all_blocks):
#         # íŒ¨í„´ 1: ë²ˆí˜¸ ìˆìŒ (1), (2), (3)...
#         match = re.search(
#             r"Information concerning the earlier mark \((\d+)\)",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ìŒ
#         match = re.search(
#             r"Information concerning the earlier mark\s*$",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,  # ë²ˆí˜¸ ì—†ìœ¼ë©´ 1ë¡œ ì„¤ì •
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
#     for i, start in enumerate(section_starts):
#         # ì„¹ì…˜ ë ì§€ì  ê²°ì •
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         # í•´ë‹¹ ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
#         section_text = " ".join([
#             all_blocks[j]["text"]
#             for j in range(start["index"], end_idx)
#         ])
#
#         # Filing number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         # International registration number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
#         ir_match = re.search(
#             r"International registration number\s*:\s*(\d+)",
#             section_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         # Owner ì •ë³´ ì¶”ì¶œ
#         owner_match = re.search(
#             r"Name and address of the owner\s*:\s*([^\n]+)",
#             section_text
#         )
#         owner = owner_match.group(1).strip() if owner_match else "Unknown"
#
#         sections.append({
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
# def extract_underlined_with_positions(pdf_path):
#     """
#     PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ
#
#     return: [
#         {"page": 2, "y": 350.5, "text": "Advertising"},
#         {"page": 2, "y": 365.2, "text": "presentation of goods..."},
#         ...
#     ]
#     """
#     doc = fitz.open(pdf_path)
#     results = []
#
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         # ìˆ˜í‰ì„  ì°¾ê¸°
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#             text = page.get_text("text", clip=rect).strip()
#             text = " ".join(text.split())
#             text = normalize_underlined_text(text)
#
#             if text and len(text) > 1 and not should_exclude_underlined_text(text):
#                 results.append({
#                     "page": page_num + 1,
#                     "y": line["y"],
#                     "text": text
#                 })
#
#     doc.close()
#     return results
#
# def normalize_underlined_text(text: str) -> str:
#     """ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
#     text = text.strip()
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#     return text.strip()
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
#     stripped = text.strip()
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
#         return True
#     if "@" in stripped:
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
#         return True
#     return False
#
# def match_underlines_to_sections(sections, underlines):
#     """
#     ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­
#
#     sections: extract_trademark_sections() ê²°ê³¼
#     underlines: extract_underlined_with_positions() ê²°ê³¼
#
#     return: [
#         {
#             "filing_number": "4120080005100",
#             "international_registration": None,
#             "underlined_goods": ["Advertising", "presentation of goods...", ...]
#         },
#         ...
#     ]
#     """
#     results = []
#
#     for section in sections:
#         # ì´ ì„¹ì…˜ì— ì†í•˜ëŠ” ë°‘ì¤„ ì°¾ê¸°
#         section_underlines = []
#
#         for u in underlines:
#             # í˜ì´ì§€ì™€ yì¢Œí‘œë¡œ ë²”ìœ„ íŒë‹¨
#             in_page_range = (
#                 section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if in_page_range:
#                 # ê°™ì€ í˜ì´ì§€ì¼ ê²½ìš° yì¢Œí‘œë„ í™•ì¸
#                 if u["page"] == section["page_start"]:
#                     if u["y"] < section["y_start"]:
#                         continue
#                 if u["page"] == section["page_end"]:
#                     if u["y"] > section["y_end"]:
#                         continue
#
#                 section_underlines.append(u)
#
#         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#             final_goods = split_products(merged)
#             goods_list = [item["text"] for item in final_goods]
#         else:
#             goods_list = []
#
#         results.append({
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         })
#
#     return results
#
# def merge_by_semicolon(results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•©"""
#     merged = []
#     current_text = ""
#     current_page = None
#
#     for item in results:
#         text = item["text"]
#         page = item["page"]
#
#         if current_page is not None and page != current_page:
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.rstrip(";.").strip()
#                 })
#                 current_text = ""
#
#         current_page = page
#
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         if current_text.endswith(";") or current_text.endswith("."):
#             merged.append({
#                 "page": current_page,
#                 "text": current_text.rstrip(";.").strip()
#             })
#             current_text = ""
#
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.rstrip(";.").strip()
#         })
#
#     return merged
#
# def split_products(merged_results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´"""
#     final_results = []
#     for item in merged_results:
#         page = item["page"]
#         text = item["text"]
#         parts = [p.strip() for p in text.split(";") if p.strip()]
#         for part in parts:
#             final_results.append({
#                 "page": page,
#                 "text": part
#             })
#     return final_results
#
# def print_results(results):
#     print(results)
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods in enumerate(r['underlined_goods'], 1):
#                 print(f"      {i}. {goods}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
# def main(pdf_path):
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#     print("=" * 80)
#
#     # 1ë‹¨ê³„: ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ
#     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
#     sections = extract_trademark_sections(pdf_path)
#     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
#
#     # 2ë‹¨ê³„: ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
#     underlines = extract_underlined_with_positions(pdf_path)
#     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
#
#     # 3ë‹¨ê³„: ë§¤ì¹­
#     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
#     results = match_underlines_to_sections(sections, underlines)
#     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
#
#     # ê²°ê³¼ ì¶œë ¥
#     print_results(results)
#
#     return results
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ì‹ë³„ë ¥_1ìƒí‘œ1ì¶œì›.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)


# """
# PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# """
#
# import re
# import fitz
# import sys
# import asyncio
# from pathlib import Path
# from typing import List, Dict, Optional
# from concurrent.futures import ThreadPoolExecutor
#
#
# def extract_class_from_text(text: str) -> Optional[str]:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] íŒ¨í„´ ì¶”ì¶œ"""
#     match = re.search(r'\[Class\s+(\d+)\]', text, re.IGNORECASE)
#     return match.group(1) if match else None
#
# def remove_class_prefix(text: str) -> str:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] ë¶€ë¶„ ì œê±°"""
#     return re.sub(r'\[Class\s+\d+\]\s*', '', text, flags=re.IGNORECASE).strip()
#
# def normalize_underlined_text(text: str) -> str:
#     """ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
#     text = text.strip()
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#     return text.strip()
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
#     stripped = text.strip()
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
#         return True
#     if "@" in stripped:
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
#         return True
#     return False
#
# def extract_trademark_sections(pdf_path):
#     doc = fitz.open(pdf_path)
#     sections = []
#
#     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" in block:
#                 block_text = ""
#                 for line in block["lines"]:
#                     for span in line["spans"]:
#                         block_text += span["text"] + " "
#
#                 all_blocks.append({
#                     "page": page_num + 1,
#                     "y0": block["bbox"][1],
#                     "y1": block["bbox"][3],
#                     "text": block_text.strip()
#                 })
#
#     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
#     section_starts = []
#     for idx, block in enumerate(all_blocks):
#         # íŒ¨í„´ 1: ë²ˆí˜¸ ìˆìŒ
#         match = re.search(
#             r"Information concerning the earlier mark \((\d+)\)",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ìŒ
#         match = re.search(
#             r"Information concerning the earlier mark\s*$",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     # ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš°: ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬
#     if not section_starts:
#         full_text = " ".join([block["text"] for block in all_blocks])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International Registration/Subsequent Designation No[.\s]*.*?:\s*(\d+)",
#             full_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         doc.close()
#         return [{
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": 1,
#             "page_end": all_blocks[-1]["page"] if all_blocks else 1,
#             "y_start": 0,
#             "y_end": float('inf')
#         }]
#
#     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
#     for i, start in enumerate(section_starts):
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         section_text = " ".join([
#             all_blocks[j]["text"]
#             for j in range(start["index"], end_idx)
#         ])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International registration number\s*:\s*(\d+)",
#             section_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         sections.append({
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
# def extract_underlined_with_positions(pdf_path):
#     """PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ"""
#     doc = fitz.open(pdf_path)
#     results = []
#
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         # ìˆ˜í‰ì„  ì°¾ê¸°
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#             text = page.get_text("text", clip=rect).strip()
#             text = " ".join(text.split())
#
#             # Class ì •ë³´ ì¶”ì¶œ (ì •ê·œí™” ì „ì—)
#             class_num = extract_class_from_text(text)
#
#             # í…ìŠ¤íŠ¸ ì •ê·œí™”
#             text = normalize_underlined_text(text)
#
#             if text and len(text) > 1 and not should_exclude_underlined_text(text):
#                 results.append({
#                     "page": page_num + 1,
#                     "y": line["y"],
#                     "text": text,
#                     "class": class_num
#                 })
#
#     doc.close()
#     return results
#
# def match_underlines_to_sections(sections, underlines):
#     """ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­"""
#     results = []
#
#     for section in sections:
#         section_underlines = []
#
#         for u in underlines:
#             in_page_range = (
#                     section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if in_page_range:
#                 if u["page"] == section["page_start"]:
#                     if u["y"] < section["y_start"]:
#                         continue
#                 if u["page"] == section["page_end"]:
#                     if u["y"] > section["y_end"]:
#                         continue
#
#                 section_underlines.append(u)
#
#         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#             final_goods = split_products(merged)
#
#             # Class ì •ë³´ì™€ í•¨ê»˜ êµ¬ì¡°í™”
#             goods_list = []
#             for item in final_goods:
#                 goods_list.append({
#                     "class": item.get("class"),
#                     "goods": item["text"]
#                 })
#         else:
#             goods_list = []
#
#         results.append({
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         })
#
#     return results
#
# def merge_by_semicolon(results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•© (Class ì •ë³´ ìœ ì§€)"""
#     merged = []
#     current_text = ""
#     current_page = None
#     current_class = None
#
#     for item in results:
#         text = item["text"]
#         page = item["page"]
#         class_num = item.get("class")
#
#         if current_page is not None and page != current_page:
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.rstrip(";.").strip(),
#                     "class": current_class
#                 })
#                 current_text = ""
#                 current_class = None
#
#         current_page = page
#
#         if class_num and not current_class:
#             current_class = class_num
#
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         if current_text.endswith(";") or current_text.endswith("."):
#             merged.append({
#                 "page": current_page,
#                 "text": current_text.rstrip(";.").strip(),
#                 "class": current_class
#             })
#             current_text = ""
#             current_class = None
#
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.rstrip(";.").strip(),
#             "class": current_class
#         })
#
#     return merged
#
# def split_products(merged_results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´ (Class ì •ë³´ ìœ ì§€)"""
#     final_results = []
#     for item in merged_results:
#         page = item["page"]
#         text = item["text"]
#         class_num = item.get("class")
#
#         text_without_class = remove_class_prefix(text)
#         parts = [p.strip() for p in text_without_class.split(";") if p.strip()]
#
#         for part in parts:
#             final_results.append({
#                 "page": page,
#                 "text": part,
#                 "class": class_num
#             })
#     return final_results
#
# def extract_underlined_goods_sync(pdf_path):
#     """ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     sections = extract_trademark_sections(pdf_path)
#     underlines = extract_underlined_with_positions(pdf_path)
#     results = match_underlines_to_sections(sections, underlines)
#     return results
#
# async def extract_underlined_goods_async(pdf_path):
#     """ë¹„ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     loop = asyncio.get_event_loop()
#
#     with ThreadPoolExecutor() as executor:
#         results = await loop.run_in_executor(
#             executor,
#             extract_underlined_goods_sync,
#             pdf_path
#         )
#
#     return results
#
# async def extract_underline(file_path: str):
#     import logging
#     logger = logging.getLogger(__name__)
#
#     logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘.")
#
#     try:
#         if not Path(file_path).exists():
#             logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
#             return []
#
#         results = await extract_underlined_goods_async(file_path)
#
#         logger.info(f"PDF UNDERLINE ì¶”ì¶œ ì™„ë£Œ: {len(results)}ê°œ ìƒí‘œ ì²˜ë¦¬")
#         logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")
#
#         return results
#
#     except Exception as e:
#         logger.error(f"PDF UNDERLINE ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
#         return []
#
# def print_results(results):
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#     print("\nê²°ê³¼ ë°ì´í„°:")
#     print(results)
#
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods_item in enumerate(r['underlined_goods'], 1):
#                 class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
#                 print(f"      {i}. {class_info}{goods_item['goods']}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
# def main(pdf_path):
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#     print("=" * 80)
#
#     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
#     sections = extract_trademark_sections(pdf_path)
#     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
#
#     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
#     underlines = extract_underlined_with_positions(pdf_path)
#     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
#
#     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
#     results = match_underlines_to_sections(sections, underlines)
#     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
#
#     print_results(results)
#
#     return results
#
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ë™ì¼ìœ ì‚¬3.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)

# ìµœì¢…ìœ¼ë¡œ ì‚¬ìš©í•˜ë ¤ê³  í–ˆì§€ë§Œ ì¸ìš© ìƒí‘œ ì „ì²´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ëŠ” ìƒí™© ë°œìƒìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
# """
# PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# """
#
# import re
# import fitz
# import sys
# import asyncio
# from pathlib import Path
# from typing import List, Dict, Optional
# from concurrent.futures import ThreadPoolExecutor
#
#
# def extract_class_from_text(text: str) -> Optional[str]:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] íŒ¨í„´ ì¶”ì¶œ"""
#     match = re.search(r'\[Class\s+(\d+)\]', text, re.IGNORECASE)
#     return match.group(1) if match else None
#
#
# def remove_class_prefix(text: str) -> str:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] ë¶€ë¶„ ì œê±°"""
#     return re.sub(r'\[Class\s+\d+\]\s*', '', text, flags=re.IGNORECASE).strip()
#
#
# def normalize_underlined_text(text: str, remove_class: bool = False) -> str:
#     """
#     ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”
#
#     Args:
#         text: ì •ê·œí™”í•  í…ìŠ¤íŠ¸
#         remove_class: [Class XX] ë¶€ë¶„ë„ ì œê±°í• ì§€ ì—¬ë¶€
#     """
#     text = text.strip()
#
#     # (underlined goods/services) prefix ì œê±°
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#
#     # [Class XX] ì œê±° (ì˜µì…˜)
#     if remove_class:
#         text = remove_class_prefix(text)
#
#     # goods/servicesë¡œ ëë‚˜ëŠ” ê²½ìš° ì„¸ë¯¸ì½œë¡  ë³´ì •
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#
#     return text.strip()
#
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
#     stripped = text.strip()
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
#         return True
#     if "@" in stripped:
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥":
#         return True
#     return False
#
#
# def extract_trademark_sections(pdf_path):
#     """PDFì—ì„œ ìƒí‘œ ì •ë³´ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ì—¬ ê° ì„¹ì…˜ì˜ ë²”ìœ„ë¥¼ íŒŒì•…"""
#     doc = fitz.open(pdf_path)
#     sections = []
#
#     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" in block:
#                 block_text = ""
#                 for line in block["lines"]:
#                     for span in line["spans"]:
#                         block_text += span["text"] + " "
#
#                 all_blocks.append({
#                     "page": page_num + 1,
#                     "y0": block["bbox"][1],
#                     "y1": block["bbox"][3],
#                     "text": block_text.strip()
#                 })
#
#     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
#     section_starts = []
#     for idx, block in enumerate(all_blocks):
#         # íŒ¨í„´ 1: ë²ˆí˜¸ ìˆìŒ
#         match = re.search(
#             r"Information concerning the earlier mark \((\d+)\)",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ìŒ
#         match = re.search(
#             r"Information concerning the earlier mark\s*$",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     # ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš°: ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬
#     if not section_starts:
#         full_text = " ".join([block["text"] for block in all_blocks])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International Registration/Subsequent Designation No[.\s]*.*?:\s*(\d+)",
#             full_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         doc.close()
#         return [{
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": 1,
#             "page_end": all_blocks[-1]["page"] if all_blocks else 1,
#             "y_start": 0,
#             "y_end": float('inf')
#         }]
#
#     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
#     for i, start in enumerate(section_starts):
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         section_text = " ".join([
#             all_blocks[j]["text"]
#             for j in range(start["index"], end_idx)
#         ])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International registration number\s*:\s*(\d+)",
#             section_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         sections.append({
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
#
# def extract_underlined_with_positions(pdf_path):
#     """PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ"""
#     doc = fitz.open(pdf_path)
#     results = []
#
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         # ìˆ˜í‰ì„  ì°¾ê¸°
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#             text = page.get_text("text", clip=rect).strip()
#             text = " ".join(text.split())
#
#             # â­ ì¤‘ìš”: Class ì •ë³´ë¥¼ ë¨¼ì € ì¶”ì¶œ (ì •ê·œí™” ì „ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ)
#             original_text = text
#             class_num = extract_class_from_text(original_text)
#
#             # í…ìŠ¤íŠ¸ ì •ê·œí™” (ClassëŠ” ì•„ì§ ì œê±°í•˜ì§€ ì•ŠìŒ)
#             text = normalize_underlined_text(text, remove_class=False)
#
#             if text and len(text) > 1 and not should_exclude_underlined_text(text):
#                 results.append({
#                     "page": page_num + 1,
#                     "y": line["y"],
#                     "text": text,
#                     "class": class_num
#                 })
#
#     doc.close()
#     return results
#
#
# def match_underlines_to_sections(sections, underlines):
#     """ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­"""
#     results = []
#
#     for section in sections:
#         section_underlines = []
#
#         for u in underlines:
#             in_page_range = (
#                     section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if in_page_range:
#                 if u["page"] == section["page_start"]:
#                     if u["y"] < section["y_start"]:
#                         continue
#                 if u["page"] == section["page_end"]:
#                     if u["y"] > section["y_end"]:
#                         continue
#
#                 section_underlines.append(u)
#
#         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#             final_goods = split_products(merged)
#
#             # Class ì •ë³´ì™€ í•¨ê»˜ êµ¬ì¡°í™”
#             goods_list = []
#             for item in final_goods:
#                 goods_list.append({
#                     "class": item.get("class"),
#                     "goods": item["text"]
#                 })
#         else:
#             goods_list = []
#
#         results.append({
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         })
#
#     return results
#
#
# def merge_by_semicolon(results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•© (Class ì •ë³´ ìœ ì§€)"""
#     merged = []
#     current_text = ""
#     current_page = None
#     current_class = None
#
#     for item in results:
#         text = item["text"]
#         page = item["page"]
#         class_num = item.get("class")
#
#         if current_page is not None and page != current_page:
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.rstrip(";.").strip(),
#                     "class": current_class
#                 })
#                 current_text = ""
#                 current_class = None
#
#         current_page = page
#
#         if class_num and not current_class:
#             current_class = class_num
#
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         if current_text.endswith(";") or current_text.endswith("."):
#             merged.append({
#                 "page": current_page,
#                 "text": current_text.rstrip(";.").strip(),
#                 "class": current_class
#             })
#             current_text = ""
#             current_class = None
#
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.rstrip(";.").strip(),
#             "class": current_class
#         })
#
#     return merged
#
#
# def split_products(merged_results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´ (Class ì •ë³´ ìœ ì§€)"""
#     final_results = []
#     for item in merged_results:
#         page = item["page"]
#         text = item["text"]
#         class_num = item.get("class")
#
#         # [Class XX] ì œê±° í›„ ë¶„í•´
#         text_without_class = remove_class_prefix(text)
#
#         # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„í•´
#         parts = [p.strip() for p in text_without_class.split(";") if p.strip()]
#
#         for part in parts:
#             final_results.append({
#                 "page": page,
#                 "text": part,
#                 "class": class_num
#             })
#
#     return final_results
#
#
# def extract_underlined_goods_sync(pdf_path):
#     """ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     sections = extract_trademark_sections(pdf_path)
#     underlines = extract_underlined_with_positions(pdf_path)
#     results = match_underlines_to_sections(sections, underlines)
#     return results
#
#
# async def extract_underlined_goods_async(pdf_path):
#     """ë¹„ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     loop = asyncio.get_event_loop()
#
#     with ThreadPoolExecutor() as executor:
#         results = await loop.run_in_executor(
#             executor,
#             extract_underlined_goods_sync,
#             pdf_path
#         )
#
#     return results
#
#
# async def extract_underline(file_path: str):
#     """
#     PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆì„ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
#
#     Returns:
#         list: [
#             {
#                 'filing_number': '4120080005100',
#                 'international_registration': None,
#                 'underlined_goods': [
#                     {"class": "35", "goods": "Advertising"},
#                     ...
#                 ]
#             },
#             ...
#         ]
#     """
#     import logging
#     logger = logging.getLogger(__name__)
#
#     logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘.")
#
#     try:
#         if not Path(file_path).exists():
#             logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
#             return []
#
#         results = await extract_underlined_goods_async(file_path)
#
#         logger.info(f"PDF UNDERLINE ì¶”ì¶œ ì™„ë£Œ: {len(results)}ê°œ ìƒí‘œ ì²˜ë¦¬")
#         logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")
#
#         return results
#
#     except Exception as e:
#         logger.error(f"PDF UNDERLINE ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
#         return []
#
#
# def print_results(results):
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#     print("\nê²°ê³¼ ë°ì´í„°:")
#     print(results)
#
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods_item in enumerate(r['underlined_goods'], 1):
#                 class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
#                 print(f"      {i}. {class_info}{goods_item['goods']}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
#
# def main(pdf_path):
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#     print("=" * 80)
#
#     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
#     sections = extract_trademark_sections(pdf_path)
#     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
#
#     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
#     underlines = extract_underlined_with_positions(pdf_path)
#     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
#
#     # ë””ë²„ê¹…: ì¶”ì¶œëœ ë°‘ì¤„ í™•ì¸
#     print("\nì¶”ì¶œëœ ë°‘ì¤„ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
#     for i, u in enumerate(underlines[:3]):
#         print(f"  {i + 1}. Page={u['page']}, Class={u['class']}, Text={u['text'][:50]}...")
#
#     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
#     results = match_underlines_to_sections(sections, underlines)
#     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
#
#     print_results(results)
#
#     return results
#
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/552025075457917-01-ë³µì‚¬.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)

for i in range(1):
    print("*"*100)

"""
í˜„ì¬ ê°€ì¥ ì í•©í•œ ë¡œì§
2026.01.16 ; íŠ¹ìˆ˜ê¸°í˜¸ê°€ ì¡´ì¬í•  ê²½ìš° ; ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ | ,ê°€ ìˆëŠ” ê²½ìš° , ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ => ;ê°€ ìš°ì„ 
merge_by_semicolon, split_products
PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
"""

import re
import fitz
import sys
from pathlib import Path

def extract_trademark_sections(pdf_path):
    """
    PDFì—ì„œ 'Information concerning the earlier mark' ì„¹ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ
    ê° ìƒí‘œ(Earlier Mark)ì˜ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """

    # PDF ì—´ê¸°
    doc = fitz.open(pdf_path)

    # ìµœì¢… ì„¹ì…˜ ê²°ê³¼
    sections = []

    # ==================================================
    # 1ï¸âƒ£ ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜ì§‘
    # ==================================================
    all_blocks = []

    for page_num, page in enumerate(doc):

        # PyMuPDF dict í˜•íƒœë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        blocks = page.get_text("dict")["blocks"]

        for block_idx, block in enumerate(blocks):
            # í…ìŠ¤íŠ¸ ë¼ì¸ì´ ìˆëŠ” ë¸”ë¡ë§Œ ì‚¬ìš©
            if "lines" not in block:
                continue

            block_text = ""

            # í•œ ë¸”ë¡ ì•ˆì˜ ëª¨ë“  span í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
            for line in block["lines"]:
                for span in line["spans"]:
                    block_text += span["text"] + " "

            block_text = block_text.strip()

            block_info = {
                "page": page_num + 1,               # í˜ì´ì§€ ë²ˆí˜¸
                "y0": block["bbox"][1],             # ë¸”ë¡ ì‹œì‘ yì¢Œí‘œ
                "y1": block["bbox"][3],             # ë¸”ë¡ ë yì¢Œí‘œ
                "text": block_text                  # ë¸”ë¡ ì „ì²´ í…ìŠ¤íŠ¸
            }

            all_blocks.append(block_info)

    # ==================================================
    # 2ï¸âƒ£ 'Information concerning the earlier mark' ì‹œì‘ì  ì°¾ê¸°
    # ==================================================
    section_starts = []

    for idx, block in enumerate(all_blocks):
        text = block["text"]

        # PDF ì²´í¬ë°•ìŠ¤ ê¸°í˜¸ ì œê±°
        text_cleaned = text.replace("â–¡", "").replace("â˜", "").strip()

        # íŒ¨í„´ 1ï¸âƒ£ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°: (1), (2) ...
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*\((\d+)\)",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            mark_number = int(match.group(1))

            section_starts.append({
                "index": idx,
                "mark_number": mark_number,
                "page": block["page"],
                "y": block["y0"]
            })
            continue

        # íŒ¨í„´ 2ï¸âƒ£ ë²ˆí˜¸ ì—†ëŠ” ê²½ìš° (ë‹¨ì¼ ìƒí‘œ ë¬¸ì„œ)
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*$",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            section_starts.append({
                "index": idx,
                "mark_number": 1,
                "page": block["page"],
                "y": block["y0"]
            })

    # ==================================================
    # 3ï¸âƒ£ ì„¹ì…˜ ì‹œì‘ì ì´ ì•„ì˜ˆ ì—†ëŠ” PDF ì²˜ë¦¬
    # ==================================================
    if not section_starts:

        full_text = " ".join([block["text"] for block in all_blocks])

        filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+(?:Registration|registration)[/\s]+"
            r"Subsequent\s+Designation\s+No[.\s]*:?\s*(\d+)",
            full_text
        )
        international_registration = ir_match.group(1) if ir_match else None

        doc.close()

        return [{
            "mark_number": 1,
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": 1,
            "page_end": all_blocks[-1]["page"] if all_blocks else 1,
            "y_start": 0,
            "y_end": float('inf')
        }]

    # ==================================================
    # 4ï¸âƒ£ ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê³„ì‚° + ì •ë³´ ì¶”ì¶œ
    # ==================================================
    for i, start in enumerate(section_starts):

        # ë‹¤ìŒ ì„¹ì…˜ì´ ìˆìœ¼ë©´ ê±°ê¸° ì „ê¹Œì§€
        if i + 1 < len(section_starts):
            end_idx = section_starts[i + 1]["index"]
            end_page = section_starts[i + 1]["page"]
            end_y = section_starts[i + 1]["y"]
        else:
            end_idx = len(all_blocks)
            end_page = all_blocks[-1]["page"]
            end_y = all_blocks[-1]["y1"]

        # í•´ë‹¹ ì„¹ì…˜ í…ìŠ¤íŠ¸ ì „ì²´ í•©ì¹˜ê¸°
        section_text = " ".join(
            all_blocks[j]["text"] for j in range(start["index"], end_idx)
        )

        # Filing number ì¶”ì¶œ
        filing_match = re.search(r"Filing\s+number\s*:\s*(\d+)", section_text)
        filing_number = filing_match.group(1) if filing_match else None

        # International registration number ì¶”ì¶œ
        ir_match = re.search(
            r"International\s+registration\s+number\s*:\s*(\d+)",
            section_text,
            re.IGNORECASE
        )
        international_registration = ir_match.group(1) if ir_match else None

        sections.append({
            "mark_number": start["mark_number"],
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": start["page"],
            "page_end": end_page,
            "y_start": start["y"],
            "y_end": end_y
        })

    doc.close()

    return sections

def extract_underlined_with_positions(pdf_path):
    """
    PDFì—ì„œ 'ë°‘ì¤„(underline)'ì— í•´ë‹¹í•˜ëŠ” ìˆ˜í‰ì„ ì„ ì§ì ‘ íƒì§€í•˜ê³ ,
    í•´ë‹¹ ìˆ˜í‰ì„  ë°”ë¡œ ìœ„ì— ìœ„ì¹˜í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ ë’¤
    ê°™ì€ ì¤„ì˜ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë°‘ì¤„ ë¶€ë¶„ì„ <u> íƒœê·¸ë¡œ ê°ì‹¼ë‹¤.

    âœ” underline style ë¯¸ì‚¬ìš©
    âœ” ì‹¤ì œ drawëœ ìˆ˜í‰ì„ (line) ê¸°ì¤€
    âœ” underline = anchor
    âœ” <u>ëŠ” full line ê¸°ì¤€ ì ìš©
    """

    # ==================================================
    # 0ï¸âƒ£ PDF íŒŒì¼ ì˜¤í”ˆ
    # ==================================================
    doc = fitz.open(pdf_path)
    results = []

    # ==================================================
    # 1ï¸âƒ£ í˜ì´ì§€ ë‹¨ìœ„ ìˆœíšŒ
    # ==================================================
    for page_num, page in enumerate(doc):
        drawings = page.get_drawings()
        lines = []

        # ==================================================
        # 2ï¸âƒ£ ìˆ˜í‰ì„ (underline) íƒìƒ‰
        # ==================================================
        for d in drawings:
            for item in d.get("items", []):
                if item[0] == "l":
                    p1, p2 = item[1], item[2]

                    # ìˆ˜í‰ì„  íŒë³„
                    if abs(p1.y - p2.y) < 2:
                        length = abs(p2.x - p1.x)

                        # underline í›„ë³´ ê¸¸ì´ ì œí•œ
                        if 10 < length < 500:
                            lines.append({
                                "y": p1.y,
                                "x0": min(p1.x, p2.x),
                                "x1": max(p1.x, p2.x),
                            })

        # ==================================================
        # 3ï¸âƒ£ ê° ë°‘ì¤„ ê¸°ì¤€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        # ==================================================
        for idx, line in enumerate(lines):

            # ------------------------------------------
            # (1) ë°‘ì¤„ ë°”ë¡œ ìœ„ ì˜ì—­ (anchor text)
            # ------------------------------------------
            anchor_rect = fitz.Rect(
                line["x0"] - 1,
                line["y"] - 12,
                line["x1"] + 1,
                line["y"] + 1,
            )

            raw_text = page.get_text("text", clip=anchor_rect)
            if raw_text == 'ì‹¬ì‚¬ê´€\níŒŒíŠ¸ì¥\níŒ€ì¥\nêµ­ì¥\n':
                continue

            anchor_text = " ".join(raw_text.strip().split())

            if not anchor_text:
                continue

            # ------------------------------------------
            # (2) ê°™ì€ ì¤„ ì „ì²´ í…ìŠ¤íŠ¸ (page width)
            # ------------------------------------------
            full_rect = fitz.Rect(
                0,
                line["y"] - 12,
                page.rect.width,
                line["y"] + 1,
            )

            full_raw_text = page.get_text("text", clip=full_rect)
            full_text = " ".join(full_raw_text.strip().split())

            if not full_text:
                continue

            # ==================================================
            # 4ï¸âƒ£ Class ì •ë³´ ì¶”ì¶œ
            # ==================================================
            match = re.search(r'\[Class\s+(\d+)\]', full_text, re.IGNORECASE)
            class_num = match.group(1) if match else None

            # ==================================================
            # 5ï¸âƒ£ ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”
            # ==================================================
            normalized_text = normalize_underlined_text(
                anchor_text,
                remove_class=False
            )

            # ==================================================
            # 6ï¸âƒ£ ì œì™¸ ëŒ€ìƒ ê²€ì‚¬
            # ==================================================
            if should_exclude_underlined_text(normalized_text):
                continue

            # underline ëŒ€ìƒ í…ìŠ¤íŠ¸ì—ì„œ ë êµ¬ë¶„ì ì œê±°
            m = re.match(r"^(.*?)([;.]?)$", normalized_text)
            underline_core = m.group(1)
            delimiter = m.group(2)

            if underline_core and underline_core in full_text:
                tagged_text = full_text.replace(
                    underline_core + delimiter,
                    f"<u>{underline_core}</u>{delimiter}",
                    1
                )
            else:
                tagged_text = f"<u>{underline_core}</u>{delimiter}"

            # ==================================================
            # 8ï¸âƒ£ ê²°ê³¼ ì €ì¥
            # ==================================================
            result_item = {
                "page": page_num + 1,
                "y": line["y"],
                "text": normalized_text,   # underline text
                "full_text": full_text,    # ì „ì²´ ë¼ì¸
                "tagged_text": tagged_text,  # <u> ì ìš©
                "class": class_num,
            }

            results.append(result_item)

    # ==================================================
    # 9ï¸âƒ£ PDF ë‹«ê¸°
    # ==================================================
    doc.close()

    return results

def match_underlines_to_sections(sections, underlines):
    results = []

    for section in sections:
        seen = set()
        goods_list = []

        # 1ï¸âƒ£ ì„¹ì…˜ì— ì†í•˜ëŠ” underline ë¨¼ì € ìˆ˜ì§‘
        section_underlines = []
        for u in underlines:
            if not (section["page_start"] <= u["page"] <= section["page_end"]):
                continue
            if u["page"] == section["page_start"] and u["y"] < section["y_start"]:
                continue
            if u["page"] == section["page_end"] and u["y"] >= section["y_end"]:
                continue

            section_underlines.append(u)

        # 2ï¸âƒ£ ğŸ”¥ ì—¬ê¸°ì„œ underline ë³‘í•©
        section_underlines = merge_multiline_underlines(section_underlines)

        # 3ï¸âƒ£ ì´ì œ ì•ˆì „í•˜ê²Œ tagged_text íŒŒì‹±
        for u in section_underlines:
            goods = extract_goods_from_tagged_text(u["tagged_text"])
            for g in goods:
                if g not in seen:
                    seen.add(g)
                    goods_list.append({
                        "class": u.get("class"),
                        "goods": g
                    })

        results.append({
            "mark_number": section.get("mark_number"),
            "filing_number": section["filing_number"],
            "international_registration": section["international_registration"],
            "underlined_goods": goods_list
        })

    return results

def normalize_underlined_text(text: str, remove_class: bool = False) -> str:
    """
    ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    - ë¶ˆí•„ìš”í•œ prefix ì œê±°
    - goods/services í˜•íƒœ ë³´ì •
    - Class ì œê±° ì˜µì…˜ ì²˜ë¦¬
    """
    # 1ï¸âƒ£ ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()

    # 2ï¸âƒ£ 'all' ë˜ëŠ” 'All' ë‹¨ë…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.fullmatch(r"(all|All)", text):
        return text

    # 3ï¸âƒ£ '(underlined goods)' ì œê±°
    before = text
    text = re.sub(
        r"^\(\s*underlined goods\s*\)\s*",
        "",
        text,
        flags=re.IGNORECASE
    )

    # 4ï¸âƒ£ '(underlined goods/services)' ì œê±°
    before = text
    text = re.sub(
        r"^\(\s*underlined goods/services\s*\)\s*",
        "",
        text,
        flags=re.IGNORECASE
    )

    # 5ï¸âƒ£ Class ì œê±° ì˜µì…˜
    if remove_class:
        before = text
        text = remove_class_prefix(text)

    # 6ï¸âƒ£ goods/services ë¡œ ëë‚˜ëŠ” ê²½ìš° ; ë³´ì •
    if re.search(r"goods/services\s*$", text, re.IGNORECASE):
        if not text.rstrip().endswith((';', '.')):
            text = text.rstrip() + ";"

    # 7ï¸âƒ£ ìµœì¢… ì •ë¦¬
    text = text.strip()

    return text

def should_exclude_underlined_text(text: str) -> bool:
    """
    ë°‘ì¤„ í…ìŠ¤íŠ¸ê°€ 'ìƒí’ˆ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš°' ì œì™¸í•˜ê¸° ìœ„í•œ íŒë‹¨ í•¨ìˆ˜
    """

    stripped = text.strip()

    # 1ï¸âƒ£ << ... >> í˜•íƒœ (ë©”íƒ€/ì£¼ì„)
    if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
        return True

    # 2ï¸âƒ£ ì—°ë½ì²˜ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    if re.search(r"\b(Fax|Tel\.?|Telephone|E-mail|Email)\b", stripped, re.IGNORECASE):
        return True

    # 3ï¸âƒ£ ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨
    if "@" in stripped:
        return True

    # 4ï¸âƒ£ ì‹¬ì‚¬ê´€ ì§ì±… ë‹¨ë… í…ìŠ¤íŠ¸
    if stripped in ["ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥", "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥"]:
        return True

    return False

def merge_by_semicolon(results):
    """
    ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.) ê¸°ì¤€ìœ¼ë¡œ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜
    - ê²°ê³¼ë¬¼ì—ëŠ” ; / . ì„ ì œê±°í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€
    - í˜ì´ì§€ê°€ ë°”ë€Œë©´ ë¬´ì¡°ê±´ flush
    """

    merged = []            # ìµœì¢… ë³‘í•© ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    current_text = ""      # í˜„ì¬ ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸
    current_page = None    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í˜ì´ì§€
    current_class = None   # í˜„ì¬ ëˆ„ì  ì¤‘ì¸ class

    # 1ï¸âƒ£ underline ê²°ê³¼ í•˜ë‚˜ì”© ìˆœíšŒ
    for idx, item in enumerate(results, 1):
        text = item["text"]
        page = item["page"]
        class_num = item.get("class")

        # 2ï¸âƒ£ ì§í•¨/ì„œëª… ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
        if text in ['ì‹¬ì‚¬ê´€', 'íŒŒíŠ¸ì¥', 'íŒ€ì¥', 'êµ­ì¥', 'íŒ€ì¥ êµ­ì¥']:
            continue

        # 3ï¸âƒ£ í˜ì´ì§€ ë³€ê²½ ê°ì§€ â†’ ì´ì „ ëˆ„ì  ë°ì´í„° flush
        if current_page is not None and page != current_page:

            if current_text:
                merged.append({
                    "page": current_page,
                    "text": current_text.strip(),  # â— ë ë¬¸ì ì œê±° ì•ˆ í•¨
                    "class": current_class
                })

                current_text = ""
                current_class = None

        # í˜„ì¬ í˜ì´ì§€ ê°±ì‹ 
        current_page = page

        # 4ï¸âƒ£ class ì„¤ì • (ì²˜ìŒ í•œ ë²ˆë§Œ)
        if class_num and not current_class:
            current_class = class_num

        # 5ï¸âƒ£ í…ìŠ¤íŠ¸ ëˆ„ì 
        if current_text:
            current_text += " " + text
        else:
            current_text = text

        # 6ï¸âƒ£ ë³‘í•© ì¢…ë£Œ ì¡°ê±´ (; ë˜ëŠ” .)
        if current_text.rstrip().endswith(";") or current_text.rstrip().endswith("."):

            merged.append({
                "page": page,
                "text": current_text,  # â— ê·¸ëŒ€ë¡œ ìœ ì§€
                "class": current_class or class_num
            })

            # ëˆ„ì  ìƒíƒœ ì´ˆê¸°í™”
            current_text = ""
            current_class = None
            continue

    # 7ï¸âƒ£ ë£¨í”„ ì¢…ë£Œ í›„ ì”ì—¬ ë°ì´í„° ì²˜ë¦¬
    if current_text:

        merged.append({
            "page": current_page,
            "text": current_text.strip(),
            "class": current_class
        })

    return merged

def split_products(merged_results):
    """
    ë³‘í•©ëœ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜

    ë¶„ë¦¬ ê·œì¹™:
    1. ì„¸ë¯¸ì½œë¡ (;)ì´ ìˆìœ¼ë©´ ; ê¸°ì¤€ ë¶„ë¦¬
    2. ì„¸ë¯¸ì½œë¡ ì´ ì—†ê³  ì½¤ë§ˆ(,)ê°€ ìˆìœ¼ë©´ , ê¸°ì¤€ ë¶„ë¦¬
    3. êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ ì²˜ë¦¬
    """
    final_results = []

    # 1ï¸âƒ£ ë³‘í•©ëœ ê²°ê³¼ í•˜ë‚˜ì”© ì²˜ë¦¬
    for idx, item in enumerate(merged_results, 1):
        page = item["page"]
        text = item["text"]
        class_num = item.get("class")

        # 2ï¸âƒ£ [Class XX] ê°™ì€ ì ‘ë‘ì–´ ì œê±°
        text_without_class = remove_class_prefix(text)
        # 3ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë¶„ë¦¬
        if ";" in text_without_class:
            parts = [
                p.strip().replace(".", "")
                for p in text_without_class.split(";")
                if p.strip()
            ]

        # 4ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ì—†ìœ¼ë©´ ì½¤ë§ˆ ê¸°ì¤€ ë¶„ë¦¬
        elif "," in text_without_class:
            parts = [
                p.strip().replace(".", "")
                for p in text_without_class.split(",")
                if p.strip()
            ]

        # 5ï¸âƒ£ êµ¬ë¶„ì ìì²´ê°€ ì—†ëŠ” ê²½ìš°
        else:
            parts = [
                text_without_class.strip().replace(".", "")
            ]

        # 6ï¸âƒ£ ê²°ê³¼ ëˆ„ì 
        for part in parts:
            final_item = {
                "page": page,
                "text": part,
                "class": class_num
            }

            final_results.append(final_item)

    return final_results

def remove_class_prefix(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ ì•ì— ë¶™ì€ [Class XX] íŒ¨í„´ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ:
      "[Class 10] Shampoos" â†’ "Shampoos"
    """

    cleaned = re.sub(
        r'\[Class\s+\d+\]\s*',  # [Class 10] íŒ¨í„´
        '',
        text,
        flags=re.IGNORECASE
    ).strip()

    return cleaned

def merge_multiline_underlines(underlines, y_gap=20):
    """
    ì¤„ë°”ê¿ˆëœ underlineì„ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ ë³‘í•©
    """
    underlines = sorted(underlines, key=lambda x: (x["page"], x["y"]))
    merged = []

    buffer = None

    for u in underlines:
        if buffer is None:
            buffer = u.copy()
            continue

        same_page = buffer["page"] == u["page"]
        close_y = abs(u["y"] - buffer["y"]) < y_gap

        # ğŸ”¥ ì´ì „ underlineì´ ë¬¸ì¥ ì¢…ë£Œê°€ ì•„ë‹ˆë©´ ë³‘í•©
        no_end = not buffer["text"].strip().endswith((';', '.'))

        if same_page and close_y and no_end:
            buffer["text"] = buffer["text"].rstrip(';') + " " + u["text"].lstrip()

            buffer["tagged_text"] = (
                buffer["tagged_text"].replace("</u>", "") +
                " " +
                u["tagged_text"].replace("<u>", "")
            )

            buffer["y"] = u["y"]
        else:
            merged.append(buffer)
            buffer = u.copy()

    if buffer:
        merged.append(buffer)

    return merged

def extract_goods_from_tagged_text(tagged_text: str) -> list[str]:
    """
    ê·œì¹™:
    1. ; ë˜ëŠ” . ê¸°ì¤€ìœ¼ë¡œ 1ì°¨ ë¶„ë¦¬
    2. <u>ê°€ í¬í•¨ëœ ì¡°ê°ë§Œ ëŒ€ìƒ
    3. ì—°ì†ëœ <u> ì¡°ê°ì€ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ ë³‘í•©
    4. <u> íƒœê·¸ëŠ” ìœ ì§€
    """
    goods = []

    # 1ï¸âƒ£ 1ì°¨ ë¶„ë¦¬
    parts = re.split(r'[;.]', tagged_text)

    buffer = None  # ë³‘í•©ìš© ë²„í¼

    for part in parts:
        part = part.strip()
        if not part:
            continue

        if "<u>" in part:
            if buffer is None:
                buffer = part
            else:
                # ğŸ”¥ delimiter ì—†ì´ ì—°ì† underline â†’ ë³‘í•©
                buffer = buffer.replace("</u>", "") + " " + part.replace("<u>", "")
        else:
            # underline ì—†ëŠ” ì¡°ê°ì„ ë§Œë‚˜ë©´ ë²„í¼ í™•ì •
            if buffer:
                goods.append(buffer.strip())
                buffer = None

    # ë§ˆì§€ë§‰ ë²„í¼ ì²˜ë¦¬
    if buffer:
        goods.append(buffer.strip())

    return goods

def print_results(results):
    """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""

    print("\n" + "=" * 80)
    print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
    print("=" * 80 + "\n")

    for idx, r in enumerate(results, 1):
        print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")

        if r['filing_number']:
            print(f"    Filing Number: {r['filing_number']}")
        if r['international_registration']:
            print(f"    International Registration: {r['international_registration']}")

        print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")

        if r['underlined_goods']:
            print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
            for i, goods_item in enumerate(r['underlined_goods'], 1):
                class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
                print(f"      {i}. {class_info}{goods_item['goods']}")
        else:
            print(f"    (ë°‘ì¤„ ì—†ìŒ)")

        print()

def main(pdf_path):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")

    sections = extract_trademark_sections(pdf_path)
    print(sections)
    underlines = extract_underlined_with_positions(pdf_path)
    print(underlines)
    results = match_underlines_to_sections(sections, underlines)

    print_results(results)

    return results

if __name__ == "__main__":
    if len(sys.argv) > 1:
        path = sys.argv[1]
    else:
        path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/ë¬¸ì œ/552025075457917-01-ë³µì‚¬.pdf"

    if not Path(path).exists():
        print(f"íŒŒì¼ ì—†ìŒ: {path}")
        sys.exit(1)

    main(path)

for i in range(1):
    print("*"*100)

# """
# ìˆ˜ì •ë³¸
# 2026.01.19 ë°‘ì¤„ ë°ì´í„°ì™€ í•´ë‹¹ ë°‘ì¤„ì´ í¬í•¨ëœ í’€í…ìŠ¤íŠ¸ ë¹„êµ
# """
#
# import re
# import fitz
# import sys
# from pathlib import Path
#
# def extract_trademark_sections(pdf_path):
#     doc = fitz.open(pdf_path)
#     sections = []
#     all_blocks = []
#
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" not in block:
#                 continue
#
#             block_text = ""
#             for line in block["lines"]:
#                 for span in line["spans"]:
#                     block_text += span["text"] + " "
#
#             block_text = block_text.strip()
#
#             all_blocks.append({
#                 "page": page_num + 1,
#                 "y0": block["bbox"][1],
#                 "y1": block["bbox"][3],
#                 "text": block_text
#             })
#
#     section_starts = []
#
#     for idx, block in enumerate(all_blocks):
#         text_cleaned = block["text"].replace("â–¡", "").replace("â˜", "").strip()
#
#         match = re.search(
#             r"Information\s+concerning\s+the\s+earlier\s+mark\s*\((\d+)\)",
#             text_cleaned,
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         match = re.search(
#             r"Information\s+concerning\s+the\s+earlier\s+mark\s*$",
#             text_cleaned,
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     if not section_starts:
#         full_text = " ".join(b["text"] for b in all_blocks)
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
#         ir_match = re.search(
#             r"International\s+(?:Registration|registration)[/\s]+"
#             r"Subsequent\s+Designation\s+No[.\s]*:?\s*(\d+)",
#             full_text
#         )
#
#         doc.close()
#         return [{
#             "mark_number": 1,
#             "filing_number": filing_match.group(1) if filing_match else None,
#             "international_registration": ir_match.group(1) if ir_match else None,
#             "page_start": 1,
#             "page_end": all_blocks[-1]["page"] if all_blocks else 1,
#             "y_start": 0,
#             "y_end": float("inf")
#         }]
#
#     for i, start in enumerate(section_starts):
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         section_text = " ".join(
#             all_blocks[j]["text"] for j in range(start["index"], end_idx)
#         )
#
#         filing_match = re.search(r"Filing\s+number\s*:\s*(\d+)", section_text)
#         ir_match = re.search(
#             r"International\s+registration\s+number\s*:\s*(\d+)",
#             section_text,
#             re.IGNORECASE
#         )
#
#         sections.append({
#             "mark_number": start["mark_number"],
#             "filing_number": filing_match.group(1) if filing_match else None,
#             "international_registration": ir_match.group(1) if ir_match else None,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
# def extract_underlined_with_positions(pdf_path):
#     doc = fitz.open(pdf_path)
#     results = []
#
#     # ğŸ”¹ ì „ì²´ block ìˆ˜ì§‘ (í’€í…ìŠ¤íŠ¸ ë¹„êµìš©)
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" not in block:
#                 continue
#
#             text = ""
#             for line in block["lines"]:
#                 for span in line["spans"]:
#                     text += span["text"] + " "
#
#             all_blocks.append({
#                 "page": page_num + 1,
#                 "y0": block["bbox"][1],
#                 "y1": block["bbox"][3],
#                 "text": text.strip()
#             })
#
#     page_blocks = build_page_blocks(all_blocks)
#
#     # ğŸ”¹ underline ì¶”ì¶œ
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#
#             raw_text = page.get_text("text", clip=rect)
#             text = " ".join(raw_text.strip().split())
#
#             if not text or should_exclude_underlined_text(text):
#                 continue
#
#             normalized = normalize_underlined_text(text)
#
#             # ğŸ” í’€í…ìŠ¤íŠ¸(block) ë§¤ì¹­
#             candidate_blocks = [
#                 b["text"]
#                 for b in page_blocks.get(page_num + 1, [])
#                 if b["y0"] <= line["y"] <= b["y1"] + 5
#             ]
#
#             print("\n" + "-" * 80)
#             print(f"[UNDERLINE] page={page_num + 1}, y={line['y']:.2f}")
#             print(f"  â–¶ underline text : {normalized}")
#             print("  â–¶ matched fulltext blocks:")
#             for b in candidate_blocks:
#                 print(f"    - {b}")
#
#             results.append({
#                 "page": page_num + 1,
#                 "y": line["y"],
#                 "text": normalized,
#                 "class": None
#             })
#
#     doc.close()
#     return results
#
# def match_underlines_to_sections(sections, underlines):
#     """
#     ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­í•˜ëŠ” í•¨ìˆ˜
#
#     íë¦„:
#     1. ìƒí‘œ ì„¹ì…˜(page_start ~ page_end, y_start ~ y_end) ìˆœíšŒ
#     2. í•´ë‹¹ ì„¹ì…˜ì— í¬í•¨ë˜ëŠ” ë°‘ì¤„ ë°ì´í„°ë§Œ í•„í„°ë§
#     3. ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•©
#     4. ìµœì¢… ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
#     """
#
#     results = []
#
#     # 1ï¸âƒ£ ìƒí‘œ ì„¹ì…˜ ë‹¨ìœ„ ìˆœíšŒ
#     for s_idx, section in enumerate(sections, 1):
#
#         section_underlines = []
#
#         # 2ï¸âƒ£ ëª¨ë“  ë°‘ì¤„ ë°ì´í„° ìˆœíšŒ
#         for u_idx, u in enumerate(underlines, 1):
#
#             # 2-1ï¸âƒ£ í˜ì´ì§€ ë²”ìœ„ ì²´í¬
#             in_page_range = (
#                 section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if not in_page_range:
#                 continue
#
#             # 2-2ï¸âƒ£ ì‹œì‘ í˜ì´ì§€ y ë²”ìœ„ ì²´í¬
#             if u["page"] == section["page_start"] and u["y"] < section["y_start"]:
#                 continue
#
#             # 2-3ï¸âƒ£ ì¢…ë£Œ í˜ì´ì§€ y ë²”ìœ„ ì²´í¬
#             if u["page"] == section["page_end"] and u["y"] >= section["y_end"]:
#                 continue
#
#             # 2-4ï¸âƒ£ ì¡°ê±´ í†µê³¼ â†’ ì„¹ì…˜ì— í¬í•¨
#             section_underlines.append(u)
#
#         # 3ï¸âƒ£ ë³‘í•© + ë¶„ë¦¬
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#
#             final_goods = split_products(merged)
#
#             # 4ï¸âƒ£ ìµœì¢… goods ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
#             goods_list = []
#             for item in final_goods:
#                 goods_text = item["text"].strip()
#                 class_num = item.get("class")
#
#                 goods_list.append({
#                     "class": class_num,
#                     "goods": goods_text
#                 })
#
#         else:
#             goods_list = []
#
#         # 5ï¸âƒ£ ì„¹ì…˜ ê²°ê³¼ ì €ì¥
#         section_result = {
#             "mark_number": section.get("mark_number"),
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         }
#
#         results.append(section_result)
#
#     return results
#
# def normalize_underlined_text(text: str, remove_class: bool = False) -> str:
#     """
#     ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
#     - ë¶ˆí•„ìš”í•œ prefix ì œê±°
#     - goods/services í˜•íƒœ ë³´ì •
#     - Class ì œê±° ì˜µì…˜ ì²˜ë¦¬
#     """
#
#     # 1ï¸âƒ£ ì•ë’¤ ê³µë°± ì œê±°
#     text = text.strip()
#
#     # 2ï¸âƒ£ 'all' ë˜ëŠ” 'All' ë‹¨ë…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
#     if re.fullmatch(r"(all|All)", text):
#         return text
#
#     # 3ï¸âƒ£ '(underlined goods)' ì œê±°
#     before = text
#     text = re.sub(
#         r"^\(\s*underlined goods\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#
#     # 4ï¸âƒ£ '(underlined goods/services)' ì œê±°
#     before = text
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#
#     # 5ï¸âƒ£ Class ì œê±° ì˜µì…˜
#     if remove_class:
#         before = text
#         text = remove_class_prefix(text)
#
#     # 6ï¸âƒ£ goods/services ë¡œ ëë‚˜ëŠ” ê²½ìš° ; ë³´ì •
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#
#     # 7ï¸âƒ£ ìµœì¢… ì •ë¦¬
#     text = text.strip()
#
#     return text
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """
#     ë°‘ì¤„ í…ìŠ¤íŠ¸ê°€ 'ìƒí’ˆ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš°' ì œì™¸í•˜ê¸° ìœ„í•œ íŒë‹¨ í•¨ìˆ˜
#     """
#
#     stripped = text.strip()
#
#     # 1ï¸âƒ£ << ... >> í˜•íƒœ (ë©”íƒ€/ì£¼ì„)
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#
#     # 2ï¸âƒ£ ì—°ë½ì²˜ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
#     if re.search(r"\b(Fax|Tel\.?|Telephone|E-mail|Email)\b", stripped, re.IGNORECASE):
#         return True
#
#     # 3ï¸âƒ£ ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨
#     if "@" in stripped:
#         return True
#
#     # 4ï¸âƒ£ ì‹¬ì‚¬ê´€ ì§ì±… ë‹¨ë… í…ìŠ¤íŠ¸
#     if stripped in ["ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥", "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥"]:
#         return True
#
#     return False
#
# def merge_by_semicolon(results):
#     """
#     ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.) ê¸°ì¤€ìœ¼ë¡œ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜
#     - ê²°ê³¼ë¬¼ì—ëŠ” ; / . ì„ ì œê±°í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€
#     - í˜ì´ì§€ê°€ ë°”ë€Œë©´ ë¬´ì¡°ê±´ flush
#     """
#
#     merged = []            # ìµœì¢… ë³‘í•© ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
#     current_text = ""      # í˜„ì¬ ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸
#     current_page = None    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í˜ì´ì§€
#     current_class = None   # í˜„ì¬ ëˆ„ì  ì¤‘ì¸ class
#
#     # 1ï¸âƒ£ underline ê²°ê³¼ í•˜ë‚˜ì”© ìˆœíšŒ
#     for idx, item in enumerate(results, 1):
#         text = item["text"]
#         page = item["page"]
#         class_num = item.get("class")
#
#         # 2ï¸âƒ£ ì§í•¨/ì„œëª… ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
#         if text in ['ì‹¬ì‚¬ê´€', 'íŒŒíŠ¸ì¥', 'íŒ€ì¥', 'êµ­ì¥', 'íŒ€ì¥ êµ­ì¥']:
#             continue
#
#         # 3ï¸âƒ£ í˜ì´ì§€ ë³€ê²½ ê°ì§€ â†’ ì´ì „ ëˆ„ì  ë°ì´í„° flush
#         if current_page is not None and page != current_page:
#
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.strip(),  # â— ë ë¬¸ì ì œê±° ì•ˆ í•¨
#                     "class": current_class
#                 })
#
#                 current_text = ""
#                 current_class = None
#
#         # í˜„ì¬ í˜ì´ì§€ ê°±ì‹ 
#         current_page = page
#
#         # 4ï¸âƒ£ class ì„¤ì • (ì²˜ìŒ í•œ ë²ˆë§Œ)
#         if class_num and not current_class:
#             current_class = class_num
#
#         # 5ï¸âƒ£ í…ìŠ¤íŠ¸ ëˆ„ì 
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         # 6ï¸âƒ£ ë³‘í•© ì¢…ë£Œ ì¡°ê±´ (; ë˜ëŠ” .)
#         if current_text.rstrip().endswith(";") or current_text.rstrip().endswith("."):
#
#             merged.append({
#                 "page": page,
#                 "text": current_text,  # â— ê·¸ëŒ€ë¡œ ìœ ì§€
#                 "class": current_class or class_num
#             })
#
#             # ëˆ„ì  ìƒíƒœ ì´ˆê¸°í™”
#             current_text = ""
#             current_class = None
#             continue
#
#     # 7ï¸âƒ£ ë£¨í”„ ì¢…ë£Œ í›„ ì”ì—¬ ë°ì´í„° ì²˜ë¦¬
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.strip(),
#             "class": current_class
#         })
#
#     return merged
#
# def split_products(merged_results):
#     """
#     ë³‘í•©ëœ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
#
#     ë¶„ë¦¬ ê·œì¹™:
#     1. ì„¸ë¯¸ì½œë¡ (;)ì´ ìˆìœ¼ë©´ ; ê¸°ì¤€ ë¶„ë¦¬
#     2. ì„¸ë¯¸ì½œë¡ ì´ ì—†ê³  ì½¤ë§ˆ(,)ê°€ ìˆìœ¼ë©´ , ê¸°ì¤€ ë¶„ë¦¬
#     3. êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ ì²˜ë¦¬
#     """
#
#     final_results = []
#
#     # 1ï¸âƒ£ ë³‘í•©ëœ ê²°ê³¼ í•˜ë‚˜ì”© ì²˜ë¦¬
#     for idx, item in enumerate(merged_results, 1):
#         page = item["page"]
#         text = item["text"]
#         class_num = item.get("class")
#
#         # 2ï¸âƒ£ [Class XX] ê°™ì€ ì ‘ë‘ì–´ ì œê±°
#         text_without_class = remove_class_prefix(text)
#
#         # 3ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë¶„ë¦¬
#         if ";" in text_without_class:
#             parts = [
#                 p.strip().replace(".", "")
#                 for p in text_without_class.split(";")
#                 if p.strip()
#             ]
#
#         # 4ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ì—†ìœ¼ë©´ ì½¤ë§ˆ ê¸°ì¤€ ë¶„ë¦¬
#         elif "," in text_without_class:
#             parts = [
#                 p.strip().replace(".", "")
#                 for p in text_without_class.split(",")
#                 if p.strip()
#             ]
#
#         # 5ï¸âƒ£ êµ¬ë¶„ì ìì²´ê°€ ì—†ëŠ” ê²½ìš°
#         else:
#             parts = [
#                 text_without_class.strip().replace(".", "")
#             ]
#
#         # 6ï¸âƒ£ ê²°ê³¼ ëˆ„ì 
#         for part in parts:
#             final_item = {
#                 "page": page,
#                 "text": part,
#                 "class": class_num
#             }
#
#             final_results.append(final_item)
#
#     return final_results
#
# def remove_class_prefix(text: str) -> str:
#     """
#     í…ìŠ¤íŠ¸ ì•ì— ë¶™ì€ [Class XX] íŒ¨í„´ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
#     ì˜ˆ:
#       "[Class 10] Shampoos" â†’ "Shampoos"
#     """
#
#     cleaned = re.sub(
#         r'\[Class\s+\d+\]\s*',  # [Class 10] íŒ¨í„´
#         '',
#         text,
#         flags=re.IGNORECASE
#     ).strip()
#
#     return cleaned
#
# def build_page_blocks(all_blocks):
#     page_blocks = {}
#     for b in all_blocks:
#         page_blocks.setdefault(b["page"], []).append(b)
#     return page_blocks
#
# def underline_fulltext_blocks(merged_underlines, page_blocks):
#     """
#     ë³‘í•©ëœ ë°‘ì¤„ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
#     í’€í…ìŠ¤íŠ¸(block)ì— <u> íƒœê·¸ë¥¼ ì ìš© (printìš©)
#
#     merged_underlines: merge_by_semicolon ê²°ê³¼
#     page_blocks: build_page_blocks(all_blocks) ê²°ê³¼
#     """
#
#     print("\n" + "=" * 80)
#     print("UNDERLINE â†” FULLTEXT MATCH WITH <u> TAG")
#     print("=" * 80)
#
#     for u in merged_underlines:
#         page = u["page"]
#         merged_text = remove_class_prefix(u["text"])
#
#         # ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ìœ¼ë¡œ ì‹¤ì œ ë°‘ì¤„ fragment ë¶„ë¦¬
#         fragments = [
#             f.strip()
#             for f in re.split(r";|,", merged_text)
#             if f.strip()
#         ]
#
#         print(f"\n[PAGE {page}]")
#         print(f"â–¶ merged underline: {merged_text}")
#         print(f"â–¶ fragments: {fragments}")
#
#         for block in page_blocks.get(page, []):
#             original = block["text"]
#             highlighted = original
#
#             matched = False
#             for frag in fragments:
#                 # ê³µë°±/ëŒ€ì†Œë¬¸ì ì°¨ì´ ì™„í™”
#                 pattern = re.escape(frag)
#                 if re.search(pattern, highlighted, re.IGNORECASE):
#                     highlighted = re.sub(
#                         pattern,
#                         r"<u>\g<0></u>",
#                         highlighted,
#                         flags=re.IGNORECASE
#                     )
#                     matched = True
#
#             if matched:
#                 print("\n--- FULLTEXT BLOCK (MATCHED) ---")
#                 print("ORIGINAL:")
#                 print(original)
#                 print("WITH <u>:")
#                 print(highlighted)
#
# def print_results(results):
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods_item in enumerate(r['underlined_goods'], 1):
#                 class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
#                 print(f"      {i}. {class_info}{goods_item['goods']}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
# def main(pdf_path):
#     print("=" * 80)
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#
#     # ì„¹ì…˜
#     sections = extract_trademark_sections(pdf_path)
#
#     # underline ì›ë³¸
#     underlines = extract_underlined_with_positions(pdf_path)
#
#     # ğŸ”¹ ì „ì²´ block ë‹¤ì‹œ ìˆ˜ì§‘ (fulltext)
#     doc = fitz.open(pdf_path)
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         for block in page.get_text("dict")["blocks"]:
#             if "lines" not in block:
#                 continue
#             text = ""
#             for line in block["lines"]:
#                 for span in line["spans"]:
#                     text += span["text"] + " "
#             all_blocks.append({
#                 "page": page_num + 1,
#                 "y0": block["bbox"][1],
#                 "y1": block["bbox"][3],
#                 "text": text.strip()
#             })
#     doc.close()
#
#     page_blocks = build_page_blocks(all_blocks)
#
#     # ğŸ”¹ ì„¹ì…˜ ë§¤ì¹­
#     results = match_underlines_to_sections(sections, underlines)
#
#     # ğŸ”¹ <u> ë¹„êµìš© ì¶œë ¥
#     merged = merge_by_semicolon(underlines)
#     underline_fulltext_blocks(merged, page_blocks)
#
#     print_results(results)
#     return results
#
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/ë¬¸ì œ/552025075457917-01-ë³µì‚¬.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)
