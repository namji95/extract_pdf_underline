# # ì•„ë˜ ë¡œì§ì€ ë°‘ì¤„ ë°ì´í„°ë§Œ ì¶”ì¶œ
# # """
# # PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
# #
# # í•µì‹¬ ì•„ì´ë””ì–´:
# # - PDFëŠ” 'ë°‘ì¤„'ì„ ìŠ¤íƒ€ì¼ ì •ë³´ë¡œ ì €ì¥í•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë§ë‹¤
# # - ëŒ€ì‹  'ìˆ˜í‰ì„ (line drawing)' ê°ì²´ë¡œ ì €ì¥ëœ ê²½ìš°ê°€ ë§ë‹¤
# # - ì´ ìˆ˜í‰ì„  ë°”ë¡œ ìœ„ì— ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼í•œë‹¤
# #
# # í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:
# # pip install pymupdf
# # """
# #
# # import re
# # import fitz           # PyMuPDF: PDF ë‚´ë¶€ êµ¬ì¡°(í…ìŠ¤íŠ¸, ë„í˜•, ì„  ë“±)ë¥¼ ë‹¤ë£° ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
# # import sys            # ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬ìš©
# # from pathlib import Path  # íŒŒì¼ ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš©
# #
# #
# # def extract_underlined(pdf_path):
# #     """
# #     PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì„  ê¸°ë°˜)
# #
# #     pdf_path: ë¶„ì„í•  PDF íŒŒì¼ ê²½ë¡œ
# #     return: [
# #         { "page": í˜ì´ì§€ë²ˆí˜¸, "text": ë°‘ì¤„ì¹œ í…ìŠ¤íŠ¸ },
# #         ...
# #     ]
# #     """
# #
# #     # PDF íŒŒì¼ ì—´ê¸° (ë¬¸ì„œ ê°ì²´ ìƒì„±)
# #     doc = fitz.open(pdf_path)
# #
# #     # ìµœì¢… ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
# #     results = []
# #
# #     # í˜ì´ì§€ ë‹¨ìœ„ë¡œ ìˆœíšŒ
# #     # page_num: 0ë¶€í„° ì‹œì‘í•˜ëŠ” í˜ì´ì§€ ì¸ë±ìŠ¤
# #     # page: ì‹¤ì œ í˜ì´ì§€ ê°ì²´
# #     for page_num, page in enumerate(doc):
# #
# #         # --------------------------------------------------
# #         # 1ï¸âƒ£ ì´ í˜ì´ì§€ì— ê·¸ë ¤ì§„ ëª¨ë“  ë„í˜•(drawing) ê°€ì ¸ì˜¤ê¸°
# #         # --------------------------------------------------
# #         # get_drawings():
# #         # - ì„ (line)
# #         # - ì‚¬ê°í˜•(rect)
# #         # - ê³¡ì„ (curve)
# #         # - ê¸°íƒ€ ê·¸ë˜í”½ ìš”ì†Œ
# #         # ë¥¼ ëª¨ë‘ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
# #         drawings = page.get_drawings()
# #
# #         # ì´ í˜ì´ì§€ì—ì„œ ë°œê²¬ëœ "ìˆ˜í‰ì„ "ë§Œ ëª¨ì•„ë‘˜ ë¦¬ìŠ¤íŠ¸
# #         lines = []
# #
# #         # ê° drawing ê°ì²´ ìˆœíšŒ
# #         for d in drawings:
# #             # drawing ë‚´ë¶€ì—ëŠ” ì‹¤ì œ ê·¸ë˜í”½ ëª…ë ¹ë“¤ì´ itemsë¡œ ë“¤ì–´ ìˆìŒ
# #             for item in d.get("items", []):
# #
# #                 # item êµ¬ì¡° ì˜ˆ:
# #                 # ("l", Point(x1,y1), Point(x2,y2)) â†’ ì„ (line)
# #                 # ì²« ë²ˆì§¸ ê°’ item[0] == "l" ì´ë©´ ì„ 
# #                 if item[0] == "l":
# #                     p1, p2 = item[1], item[2]  # ì„ ì˜ ì‹œì‘ì , ëì 
# #
# #                     # --------------------------------------------------
# #                     # ìˆ˜í‰ì„  íŒë³„
# #                     # --------------------------------------------------
# #                     # y ì¢Œí‘œ ì°¨ì´ê°€ ê±°ì˜ ì—†ìœ¼ë©´ ìˆ˜í‰ì„ ìœ¼ë¡œ ê°„ì£¼
# #                     # (PDF ì¢Œí‘œê³„ì—ì„œëŠ” ì†Œìˆ˜ì  ì˜¤ì°¨ê°€ ìˆìœ¼ë¯€ë¡œ < 2 ì •ë„ í—ˆìš©)
# #                     if abs(p1.y - p2.y) < 2:
# #
# #                         # ì„ ì˜ ê¸¸ì´ ê³„ì‚° (xì¶• ë°©í–¥)
# #                         length = abs(p2.x - p1.x)
# #
# #                         # --------------------------------------------------
# #                         # ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸´ ì„ ì€ ì œì™¸
# #                         # - 10px ë¯¸ë§Œ: ê¸€ì ë°‘ì¤„ì´ ì•„ë‹ ê°€ëŠ¥ì„±
# #                         # - 500px ì´ˆê³¼: í‘œ, êµ¬ë¶„ì„ ì¼ ê°€ëŠ¥ì„±
# #                         # --------------------------------------------------
# #                         if 10 < length < 500:
# #                             lines.append({
# #                                 # ì„ ì˜ y ì¢Œí‘œ (ë°‘ì¤„ ìœ„ì¹˜)
# #                                 "y": p1.y,
# #
# #                                 # ì„ ì˜ ì‹œì‘ x
# #                                 "x0": min(p1.x, p2.x),
# #
# #                                 # ì„ ì˜ ë x
# #                                 "x1": max(p1.x, p2.x)
# #                             })
# #
# #         # --------------------------------------------------
# #         # 2ï¸âƒ£ ê° ìˆ˜í‰ì„  ë°”ë¡œ ìœ„ì— ìˆëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #         # --------------------------------------------------
# #         for line in lines:
# #             # í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ì˜ì—­(Rect) ì •ì˜
# #             #
# #             # ì™œ ì´ë ‡ê²Œ ì¡ë‚˜?
# #             # - ë°‘ì¤„ì€ ë³´í†µ í…ìŠ¤íŠ¸ ë°”ë¡œ "ì•„ë˜"ì— ìˆìŒ
# #             # - ê·¸ë˜ì„œ ì„  ê¸°ì¤€ìœ¼ë¡œ ìœ„ìª½(y-12) ì˜ì—­ì„ ì˜ë¼ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ìŒ
# #             rect = fitz.Rect(
# #                 line["x0"] - 1,     # ì¢Œì¸¡ ì—¬ìœ 
# #                 line["y"] - 12,     # ì„  ìœ„ìª½ ì˜ì—­
# #                 line["x1"] + 1,     # ìš°ì¸¡ ì—¬ìœ 
# #                 line["y"] + 1       # ì„  ë°”ë¡œ ìœ„ê¹Œì§€
# #             )
# #
# #             # í•´ë‹¹ ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #             # "text" ì˜µì…˜ â†’ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
# #             text = page.get_text("text", clip=rect).strip()
# #
# #             # ì—¬ëŸ¬ ì¤„/ê³µë°±ì„ í•œ ì¤„ë¡œ ì •ë¦¬
# #             text = " ".join(text.split())
# #
# #             # â­ ì„¤ëª…ìš© prefix ì œê±°
# #             text = normalize_underlined_text(text)
# #
# #             # ì˜ë¯¸ ì—†ëŠ” ê°’ ì œì™¸
# #             # - ë¹ˆ ë¬¸ìì—´
# #             # - í•œ ê¸€ì ì´í•˜
# #             if text and len(text) > 1 and not should_exclude_underlined_text(text):
# #                 results.append({
# #                     "page": page_num + 1, # ì‚¬ëŒ ê¸°ì¤€ í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„°)
# #                     "text": text
# #                 })
# #
# #     # PDF ë‹«ê¸° (ë¦¬ì†ŒìŠ¤ í•´ì œ)
# #     doc.close()
# #
# #     return results
# #
# #
# # def normalize_underlined_text(text: str) -> str:
# #     """
# #     ë°‘ì¤„ í…ìŠ¤íŠ¸ì—ì„œ
# #     - ìƒí’ˆê³¼ ë¬´ê´€í•œ ì„¤ëª…ìš© prefix ì œê±°
# #     - goods/services ë¡œ ëë‚˜ëŠ” ìƒí’ˆì€ ì„¸ë¯¸ì½œë¡  ë³´ì •
# #     """
# #
# #     original = text
# #     text = text.strip()
# #
# #     # --------------------------------------------------
# #     # 1ï¸âƒ£ (underlined goods/services) prefix ì œê±°
# #     # --------------------------------------------------
# #     text = re.sub(
# #         r"^\(\s*underlined goods/services\s*\)\s*",
# #         "",
# #         text,
# #         flags=re.IGNORECASE
# #     )
# #
# #     # --------------------------------------------------
# #     # 2ï¸âƒ£ goods/services ë¡œ ëë‚˜ëŠ” ê²½ìš° ì„¸ë¯¸ì½œë¡  ë³´ì •
# #     # --------------------------------------------------
# #     # ì¡°ê±´:
# #     # - prefix ì œê±° í›„ ê²°ê³¼ì— ì ìš©
# #     # - ì´ë¯¸ ; ë˜ëŠ” . ìœ¼ë¡œ ëë‚˜ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
# #     # - ì •í™•íˆ goods/services ë¡œ "ëë‚˜ëŠ”" ê²½ìš°ë§Œ
# #     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
# #         if not text.rstrip().endswith((';', '.')):
# #             text = text.rstrip() + ";"
# #
# #     return text.strip()
# #
# #
# #
# # def should_exclude_underlined_text(text: str) -> bool:
# #     """
# #     ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¤‘ 'ë¬´ì¡°ê±´ ì œê±°í•´ì•¼ í•˜ëŠ” ê²ƒ'ë§Œ ê±¸ëŸ¬ë‚¸ë‹¤.
# #     ìƒí’ˆ ì—¬ë¶€ íŒë‹¨ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤.
# #     """
# #
# #     stripped = text.strip()
# #
# #     # 1ï¸âƒ£ << ... >> í˜•íƒœì˜ ì„¹ì…˜/UI í—¤ë” ì œê±°
# #     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
# #         return True
# #
# #     # 2ï¸âƒ£ ì´ë©”ì¼ / ì—°ë½ì²˜ ë¼ì¸ ì œê±° (ë¼ì¸ ì‹œì‘ ê¸°ì¤€)
# #     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
# #         return True
# #
# #     # 3ï¸âƒ£ ì´ë©”ì¼ ì£¼ì†Œê°€ í¬í•¨ëœ ë‹¨ë… ë¼ì¸ ì œê±°
# #     if "@" in stripped:
# #         return True
# #
# #     # 4ï¸âƒ£ ì‹¬ì‚¬ê´€ ì§í•¨ ë¼ì¸ ì œê±° (ëª…ì‹œì  ë¬¸ìì—´ ë§¤ì¹­)
# #     # ğŸ‘‰ ì—¬ê¸°ì„œëŠ” 'íŒë‹¨'ì´ ì•„ë‹ˆë¼ 'ì§€ì • ì œê±°'
# #     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
# #         return True
# #
# #     return False
# #
# #
# # def merge_by_semicolon(results):
# #     """
# #     ë°‘ì¤„ ì¶”ì¶œ ê²°ê³¼(results)ë¥¼ ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.) ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•œë‹¤.
# #
# #     results ì…ë ¥ í˜•íƒœ:
# #     [
# #         {"page": 2, "text": "provision of"},
# #         {"page": 2, "text": "space on web sites for advertising goods and services;"},
# #         {"page": 3, "text": "jewellery;"},
# #         ...
# #     ]
# #
# #     ë°˜í™˜ í˜•íƒœ:
# #     [
# #         {"page": 2, "text": "provision of space on web sites for advertising goods and services"},
# #         {"page": 3, "text": "jewellery"},
# #         ...
# #     ]
# #
# #     í•µì‹¬ ê°œë…:
# #     - PDFì—ì„œëŠ” í•œ ìƒí’ˆëª…ì´ ì—¬ëŸ¬ ì¤„ë¡œ ëŠì–´ì ¸ ìˆì„ ìˆ˜ ìˆë‹¤
# #     - ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.)ëŠ” 'ìƒí’ˆ í•˜ë‚˜ì˜ ì¢…ë£Œ'ë¥¼ ì˜ë¯¸í•œë‹¤
# #     - ë”°ë¼ì„œ í•´ë‹¹ ê¸°í˜¸ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ í…ìŠ¤íŠ¸ë¥¼ ëˆ„ì í•œë‹¤
# #     """
# #
# #     # ìµœì¢… ë³‘í•© ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
# #     merged = []
# #
# #     # í˜„ì¬ ìƒí’ˆì„ êµ¬ì„± ì¤‘ì¸ ì„ì‹œ ë²„í¼
# #     # ì—¬ëŸ¬ ì¤„ì„ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ í•©ì¹  ë•Œ ì‚¬ìš©
# #     current_text = ""
# #
# #     # í˜„ì¬ ë²„í¼ì— ë‹´ê¸´ í…ìŠ¤íŠ¸ê°€ ì†í•œ í˜ì´ì§€ ë²ˆí˜¸
# #     # í˜ì´ì§€ ë³€ê²½ ì‹œ ë²„í¼ë¥¼ ê°•ì œë¡œ í™•ì •í•˜ê¸° ìœ„í•´ í•„ìš”
# #     current_page = None
# #
# #     # ì¶”ì¶œëœ ë°‘ì¤„ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆœíšŒ
# #     # resultsëŠ” PDF ìƒì—ì„œ ì½ì€ ìˆœì„œë¥¼ ìœ ì§€í•´ì•¼ í•¨
# #     for item in results:
# #
# #         # í˜„ì¬ ì¤„ì˜ í…ìŠ¤íŠ¸ (ë°‘ì¤„ë¡œ ì¶”ì¶œëœ ë‹¨ìœ„)
# #         text = item["text"]
# #
# #         # í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ ìœ„ì¹˜í•œ í˜ì´ì§€ ë²ˆí˜¸
# #         page = item["page"]
# #
# #         # --------------------------------------------------
# #         # 1ï¸âƒ£ í˜ì´ì§€ ë³€ê²½ ê°ì§€
# #         # --------------------------------------------------
# #         # ì´ì „ ì¤„ê³¼ í˜„ì¬ ì¤„ì˜ í˜ì´ì§€ê°€ ë‹¤ë¥´ë©´
# #         # â†’ ì´ì „ í˜ì´ì§€ì—ì„œ ëˆ„ì  ì¤‘ì´ë˜ ìƒí’ˆì„ ê°•ì œë¡œ í™•ì •
# #         if current_page is not None and page != current_page:
# #
# #             # ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ê²°ê³¼ë¡œ ì¶”ê°€
# #             if current_text:
# #                 merged.append({
# #                     "page": current_page,
# #                     # â­ ë§ˆì§€ë§‰ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
# #                     "text": current_text.rstrip(";.").strip()
# #                 })
# #
# #                 # ë²„í¼ ì´ˆê¸°í™”
# #                 current_text = ""
# #
# #         # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í˜ì´ì§€ ë²ˆí˜¸ ê°±ì‹ 
# #         current_page = page
# #
# #         # --------------------------------------------------
# #         # 2ï¸âƒ£ í…ìŠ¤íŠ¸ ëˆ„ì 
# #         # --------------------------------------------------
# #         # ì´ë¯¸ ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´
# #         # â†’ ê³µë°±ì„ í•˜ë‚˜ ë„£ê³  ì´ì–´ ë¶™ì„
# #         if current_text:
# #             current_text += " " + text
# #         else:
# #             # ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸ê°€ ì—†ë‹¤ë©´ ìƒˆë¡œ ì‹œì‘
# #             current_text = text
# #
# #         # --------------------------------------------------
# #         # 3ï¸âƒ£ ìƒí’ˆ ì¢…ë£Œ ì¡°ê±´ íŒë‹¨
# #         # --------------------------------------------------
# #         # ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.)ë¡œ ëë‚˜ë©´
# #         # â†’ í•˜ë‚˜ì˜ ìƒí’ˆì´ ì™„ì„±ë˜ì—ˆë‹¤ê³  íŒë‹¨
# #         if current_text.endswith(";") or current_text.endswith("."):
# #
# #             # ì™„ì„±ëœ ìƒí’ˆì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
# #             merged.append({
# #                 "page": current_page,
# #                 # â­ ë§ˆì§€ë§‰ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
# #                 "text": current_text.rstrip(";.").strip()
# #             })
# #
# #             # ë‹¤ìŒ ìƒí’ˆì„ ìœ„í•´ ë²„í¼ ì´ˆê¸°í™”
# #             current_text = ""
# #
# #     # --------------------------------------------------
# #     # 4ï¸âƒ£ ë£¨í”„ ì¢…ë£Œ í›„ ë‚¨ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
# #     # --------------------------------------------------
# #     # íŒŒì¼ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œëŠ”
# #     # ì„¸ë¯¸ì½œë¡  ì—†ì´ ëë‚˜ëŠ” ìƒí’ˆì´ ìˆì„ ìˆ˜ ìˆìŒ
# #     if current_text:
# #         merged.append({
# #             "page": current_page,
# #             # â­ ë§ˆì§€ë§‰ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
# #             "text": current_text.rstrip(";.").strip()
# #         })
# #
# #     # ë³‘í•©ëœ ìµœì¢… ê²°ê³¼ ë°˜í™˜
# #     return merged
# #
# #
# # def split_products(merged_results):
# #     """
# #     ë³‘í•©ëœ ìƒí’ˆ í…ìŠ¤íŠ¸ì—ì„œ ì„¸ë¯¸ì½œë¡ (;) ê¸°ì¤€ìœ¼ë¡œ
# #     ê°œë³„ ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ëŠ” í•¨ìˆ˜.
# #
# #     merged_results ì…ë ¥ í˜•íƒœ:
# #     [
# #         {"page": 11, "text": "Office furniture; desks; tea tables"},
# #         {"page": 11, "text": "book shelves rocking chairs"},
# #         ...
# #     ]
# #
# #     ë°˜í™˜ í˜•íƒœ:
# #     [
# #         {"page": 11, "text": "Office furniture"},
# #         {"page": 11, "text": "desks"},
# #         {"page": 11, "text": "tea tables"},
# #         {"page": 11, "text": "book shelves rocking chairs"},
# #         ...
# #     ]
# #
# #     í•µì‹¬ ê°œë…:
# #     - merge_by_semicolon ë‹¨ê³„ì—ì„œëŠ”
# #       "ì¤„ ê¹¨ì§(line break)"ë§Œ í•´ê²°í•œë‹¤.
# #     - í•˜ì§€ë§Œ í•œ ì¤„ ì•ˆì— ì—¬ëŸ¬ ìƒí’ˆì´ ë“¤ì–´ ìˆëŠ” ê²½ìš°ê°€ ë§ë‹¤.
# #     - ì´ í•¨ìˆ˜ëŠ” ì„¸ë¯¸ì½œë¡ (;)ì„
# #       "ìƒí’ˆê³¼ ìƒí’ˆì„ ë‚˜ëˆ„ëŠ” êµ¬ë¶„ì"ë¡œ ì‚¬ìš©í•˜ì—¬
# #       ìµœì¢… ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„í•´í•œë‹¤.
# #     """
# #
# #     # ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
# #     # ê° ìš”ì†ŒëŠ” {page, text} í˜•íƒœì˜ ë‹¨ì¼ ìƒí’ˆ
# #     final_results = []
# #
# #     # ë³‘í•©ëœ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆœíšŒ
# #     # ì´ ìˆœì„œëŠ” PDF ì›ë¬¸ì— ë‚˜íƒ€ë‚œ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•¨
# #     for item in merged_results:
# #
# #         # í•´ë‹¹ ìƒí’ˆì´ ë“±ì¥í•œ í˜ì´ì§€ ë²ˆí˜¸
# #         # (merge ë‹¨ê³„ì—ì„œ ì´ë¯¸ í™•ì •ëœ ê°’)
# #         page = item["page"]
# #
# #         # ë³‘í•©ëœ ìƒí’ˆ í…ìŠ¤íŠ¸
# #         # ì˜ˆ: "Office furniture; desks; tea tables"
# #         text = item["text"]
# #
# #         # --------------------------------------------------
# #         # 1ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë¶„í•´
# #         # --------------------------------------------------
# #         # split(";"):
# #         #   "Office furniture; desks; tea tables"
# #         # â†’ ["Office furniture", " desks", " tea tables"]
# #         #
# #         # strip():
# #         #   ê° ì¡°ê°ì˜ ì•ë’¤ ê³µë°± ì œê±°
# #         #
# #         # if p.strip():
# #         #   ë¹ˆ ë¬¸ìì—´ ì œê±°
# #         parts = [
# #             p.strip()
# #             for p in text.split(";")
# #             if p.strip()
# #         ]
# #
# #         # --------------------------------------------------
# #         # 2ï¸âƒ£ ê°œë³„ ìƒí’ˆ ë‹¨ìœ„ë¡œ ê²°ê³¼ ìƒì„±
# #         # --------------------------------------------------
# #         # í•˜ë‚˜ì˜ merged itemì—ì„œ
# #         # ì—¬ëŸ¬ ê°œì˜ ìµœì¢… ìƒí’ˆì´ ë§Œë“¤ì–´ì§ˆ ìˆ˜ ìˆìŒ
# #         for part in parts:
# #             final_results.append({
# #                 "page": page,  # ì›ë³¸ í˜ì´ì§€ ë²ˆí˜¸ ìœ ì§€
# #                 "text": part   # ìµœì¢… ìƒí’ˆëª… (ì„¸ë¯¸ì½œë¡  ì œê±°ë¨)
# #             })
# #
# #     # ì„¸ë¯¸ì½œë¡  ë¶„í•´ê°€ ì™„ë£Œëœ ìµœì¢… ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
# #     return final_results
# #
# #
# # def main(pdf_path):
# #     """
# #     ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ìš© ë©”ì¸ í•¨ìˆ˜
# #     """
# #
# #     print(f"íŒŒì¼: {pdf_path}")
# #     print("-" * 50)
# #
# #     # ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰
# #     results = extract_underlined(pdf_path)
# #     # 1ï¸âƒ£ ì¤„ ê¹¨ì§ ë³‘í•©
# #     merged_results = merge_by_semicolon(results)
# #     # 2ï¸âƒ£ í•œ ì¤„ ë‚´ ë‹¤ì¤‘ ìƒí’ˆ ë¶„í•´
# #     final_results = split_products(merged_results)
# #
# #
# #     # ê²°ê³¼ ì¶œë ¥
# #     if final_results:
# #         for r in final_results:
# #             print(f"[p{r['page']}] {r['text']}")
# #         print(f"\nì´ {len(results)}ê°œ ë°‘ì¤„ ë°œê²¬")
# #     else:
# #         print("ë°‘ì¤„ ì—†ìŒ")
# #
# #     return final_results
# #
# #
# # if __name__ == "__main__":
# #     # --------------------------------------------------
# #     # ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬
# #     # --------------------------------------------------
# #     # python extract.py sample.pdf
# #     if len(sys.argv) > 1:
# #         path = sys.argv[1]
# #     else:
# #         # ì¸ìê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
# #         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ë™ì¼ìœ ì‚¬_1ìƒí‘œ1ì¶œì›1.pdf"
# #
# #     # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
# #     if not Path(path).exists():
# #         print(f"íŒŒì¼ ì—†ìŒ: {path}")
# #         sys.exit(1)
# #
# #     # ì‹¤í–‰
# #     main(path)
#
#
#
# # ì•„ë˜ ë¡œì§ì€ ë°‘ì¤„ì´ í¬í•¨ëœ ë°ì´í„° ì¶”ì¶œ
# # """
# # PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# # í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# # """
# #
# # import re
# # import fitz
# # import sys
# # from pathlib import Path
# # from typing import List, Dict, Optional
# #
# #
# # def extract_trademark_sections(pdf_path):
# #     """
# #     PDFì—ì„œ ìƒí‘œ ì •ë³´ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ì—¬ ê° ì„¹ì…˜ì˜ ë²”ìœ„ë¥¼ íŒŒì•…
# #
# #     return: [
# #         {
# #             "mark_number": 1,
# #             "filing_number": "4120080005100",
# #             "international_registration": None,
# #             "page_start": 2,
# #             "page_end": 2,
# #             "y_start": 200.5,
# #             "y_end": 450.3,
# #             "owner": "Han Nam Hee"
# #         },
# #         ...
# #     ]
# #     """
# #     doc = fitz.open(pdf_path)
# #     sections = []
# #
# #     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
# #     all_blocks = []
# #     for page_num, page in enumerate(doc):
# #         blocks = page.get_text("dict")["blocks"]
# #         for block in blocks:
# #             if "lines" in block:
# #                 block_text = ""
# #                 for line in block["lines"]:
# #                     for span in line["spans"]:
# #                         block_text += span["text"] + " "
# #
# #                 all_blocks.append({
# #                     "page": page_num + 1,
# #                     "y0": block["bbox"][1],
# #                     "y1": block["bbox"][3],
# #                     "text": block_text.strip()
# #                 })
# #
# #     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
# #     section_starts = []
# #     for idx, block in enumerate(all_blocks):
# #         match = re.search(
# #             r"Information concerning the earlier mark \((\d+)\)",
# #             block["text"],
# #             re.IGNORECASE
# #         )
# #         if match:
# #             section_starts.append({
# #                 "index": idx,
# #                 "mark_number": int(match.group(1)),
# #                 "page": block["page"],
# #                 "y": block["y0"]
# #             })
# #
# #     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
# #     for i, start in enumerate(section_starts):
# #         # ì„¹ì…˜ ë ì§€ì  ê²°ì •
# #         if i + 1 < len(section_starts):
# #             end_idx = section_starts[i + 1]["index"]
# #             end_page = section_starts[i + 1]["page"]
# #             end_y = section_starts[i + 1]["y"]
# #         else:
# #             end_idx = len(all_blocks)
# #             end_page = all_blocks[-1]["page"]
# #             end_y = all_blocks[-1]["y1"]
# #
# #         # í•´ë‹¹ ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
# #         section_text = " ".join([
# #             all_blocks[j]["text"]
# #             for j in range(start["index"], end_idx)
# #         ])
# #
# #         # Filing number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
# #         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
# #         filing_number = filing_match.group(1) if filing_match else None
# #
# #         # International registration number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
# #         ir_match = re.search(
# #             r"International registration number\s*:\s*(\d+)",
# #             section_text
# #         )
# #         international_registration = ir_match.group(1) if ir_match else None
# #
# #         # Owner ì •ë³´ ì¶”ì¶œ
# #         owner_match = re.search(
# #             r"Name and address of the owner\s*:\s*([^\n]+)",
# #             section_text
# #         )
# #         owner = owner_match.group(1).strip() if owner_match else "Unknown"
# #
# #         sections.append({
# #             "mark_number": start["mark_number"],
# #             "filing_number": filing_number,
# #             "international_registration": international_registration,
# #             "page_start": start["page"],
# #             "page_end": end_page,
# #             "y_start": start["y"],
# #             "y_end": end_y,
# #             "owner": owner
# #         })
# #
# #     doc.close()
# #     return sections
# #
# #
# # def extract_underlined_with_positions(pdf_path):
# #     """
# #     PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ
# #
# #     return: [
# #         {"page": 2, "y": 350.5, "text": "Advertising"},
# #         {"page": 2, "y": 365.2, "text": "presentation of goods..."},
# #         ...
# #     ]
# #     """
# #     doc = fitz.open(pdf_path)
# #     results = []
# #
# #     for page_num, page in enumerate(doc):
# #         drawings = page.get_drawings()
# #         lines = []
# #
# #         # ìˆ˜í‰ì„  ì°¾ê¸°
# #         for d in drawings:
# #             for item in d.get("items", []):
# #                 if item[0] == "l":
# #                     p1, p2 = item[1], item[2]
# #                     if abs(p1.y - p2.y) < 2:
# #                         length = abs(p2.x - p1.x)
# #                         if 10 < length < 500:
# #                             lines.append({
# #                                 "y": p1.y,
# #                                 "x0": min(p1.x, p2.x),
# #                                 "x1": max(p1.x, p2.x)
# #                             })
# #
# #         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #         for line in lines:
# #             rect = fitz.Rect(
# #                 line["x0"] - 1,
# #                 line["y"] - 12,
# #                 line["x1"] + 1,
# #                 line["y"] + 1
# #             )
# #             text = page.get_text("text", clip=rect).strip()
# #             text = " ".join(text.split())
# #             text = normalize_underlined_text(text)
# #
# #             if text and len(text) > 1 and not should_exclude_underlined_text(text):
# #                 results.append({
# #                     "page": page_num + 1,
# #                     "y": line["y"],
# #                     "text": text
# #                 })
# #
# #     doc.close()
# #     return results
# #
# #
# # def normalize_underlined_text(text: str) -> str:
# #     """ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
# #     text = text.strip()
# #     text = re.sub(
# #         r"^\(\s*underlined goods/services\s*\)\s*",
# #         "",
# #         text,
# #         flags=re.IGNORECASE
# #     )
# #     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
# #         if not text.rstrip().endswith((';', '.')):
# #             text = text.rstrip() + ";"
# #     return text.strip()
# #
# #
# # def should_exclude_underlined_text(text: str) -> bool:
# #     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
# #     stripped = text.strip()
# #     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
# #         return True
# #     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
# #         return True
# #     if "@" in stripped:
# #         return True
# #     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
# #         return True
# #     return False
# #
# #
# # def match_underlines_to_sections(sections, underlines):
# #     """
# #     ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­
# #
# #     sections: extract_trademark_sections() ê²°ê³¼
# #     underlines: extract_underlined_with_positions() ê²°ê³¼
# #
# #     return: [
# #         {
# #             "mark_number": 1,
# #             "filing_number": "4120080005100",
# #             "international_registration": None,
# #             "owner": "Han Nam Hee",
# #             "underlined_goods": ["Advertising", "presentation of goods...", ...]
# #         },
# #         ...
# #     ]
# #     """
# #     results = []
# #
# #     for section in sections:
# #         # ì´ ì„¹ì…˜ì— ì†í•˜ëŠ” ë°‘ì¤„ ì°¾ê¸°
# #         section_underlines = []
# #
# #         for u in underlines:
# #             # í˜ì´ì§€ì™€ yì¢Œí‘œë¡œ ë²”ìœ„ íŒë‹¨
# #             in_page_range = (
# #                     section["page_start"] <= u["page"] <= section["page_end"]
# #             )
# #
# #             if in_page_range:
# #                 # ê°™ì€ í˜ì´ì§€ì¼ ê²½ìš° yì¢Œí‘œë„ í™•ì¸
# #                 if u["page"] == section["page_start"]:
# #                     if u["y"] < section["y_start"]:
# #                         continue
# #                 if u["page"] == section["page_end"]:
# #                     if u["y"] > section["y_end"]:
# #                         continue
# #
# #                 section_underlines.append(u)
# #
# #         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
# #         if section_underlines:
# #             merged = merge_by_semicolon(section_underlines)
# #             final_goods = split_products(merged)
# #             goods_list = [item["text"] for item in final_goods]
# #         else:
# #             goods_list = []
# #
# #         results.append({
# #             "mark_number": section["mark_number"],
# #             "filing_number": section["filing_number"],
# #             "international_registration": section["international_registration"],
# #             "owner": section["owner"],
# #             "page_range": f"{section['page_start']}-{section['page_end']}",
# #             "underlined_goods": goods_list
# #         })
# #
# #     return results
# #
# #
# # def merge_by_semicolon(results):
# #     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•©"""
# #     merged = []
# #     current_text = ""
# #     current_page = None
# #
# #     for item in results:
# #         text = item["text"]
# #         page = item["page"]
# #
# #         if current_page is not None and page != current_page:
# #             if current_text:
# #                 merged.append({
# #                     "page": current_page,
# #                     "text": current_text.rstrip(";.").strip()
# #                 })
# #                 current_text = ""
# #
# #         current_page = page
# #
# #         if current_text:
# #             current_text += " " + text
# #         else:
# #             current_text = text
# #
# #         if current_text.endswith(";") or current_text.endswith("."):
# #             merged.append({
# #                 "page": current_page,
# #                 "text": current_text.rstrip(";.").strip()
# #             })
# #             current_text = ""
# #
# #     if current_text:
# #         merged.append({
# #             "page": current_page,
# #             "text": current_text.rstrip(";.").strip()
# #         })
# #
# #     return merged
# #
# #
# # def split_products(merged_results):
# #     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´"""
# #     final_results = []
# #     for item in merged_results:
# #         page = item["page"]
# #         text = item["text"]
# #         parts = [p.strip() for p in text.split(";") if p.strip()]
# #         for part in parts:
# #             final_results.append({
# #                 "page": page,
# #                 "text": part
# #             })
# #     return final_results
# #
# #
# # def print_results(results):
# #     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
# #     print("\n" + "=" * 80)
# #     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
# #     print("=" * 80 + "\n")
# #
# #     for idx, r in enumerate(results, 1):
# #         print(f"[{idx}] ìƒí‘œ ì •ë³´")
# #         print(f"    Mark Number: {r['mark_number']}")
# #
# #         if r['filing_number']:
# #             print(f"    Filing Number: {r['filing_number']}")
# #         if r['international_registration']:
# #             print(f"    International Registration: {r['international_registration']}")
# #
# #         print(f"    Owner: {r['owner']}")
# #         print(f"    Page Range: {r['page_range']}")
# #         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
# #
# #         if r['underlined_goods']:
# #             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
# #             for i, goods in enumerate(r['underlined_goods'], 1):
# #                 print(f"      {i}. {goods}")
# #         else:
# #             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
# #
# #         print()
# #
# #
# # def main(pdf_path):
# #     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
# #     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
# #     print("=" * 80)
# #
# #     # 1ë‹¨ê³„: ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ
# #     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
# #     sections = extract_trademark_sections(pdf_path)
# #     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
# #
# #     # 2ë‹¨ê³„: ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
# #     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
# #     underlines = extract_underlined_with_positions(pdf_path)
# #     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
# #
# #     # 3ë‹¨ê³„: ë§¤ì¹­
# #     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
# #     results = match_underlines_to_sections(sections, underlines)
# #     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
# #
# #     # ê²°ê³¼ ì¶œë ¥
# #     print_results(results)
# #
# #     return results
# #
# #
# # if __name__ == "__main__":
# #     if len(sys.argv) > 1:
# #         path = sys.argv[1]
# #     else:
# #         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ë™ì¼ìœ ì‚¬_1ìƒí‘œ1ì¶œì›1.pdf"
# #
# #     if not Path(path).exists():
# #         print(f"íŒŒì¼ ì—†ìŒ: {path}")
# #         sys.exit(1)
# #
# #     main(path)
#
# """
# PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# """
#
# import re
# import fitz
# import sys
# from pathlib import Path
# from typing import List, Dict, Optional
#
#
# def extract_trademark_sections(pdf_path):
#     """
#     PDFì—ì„œ ìƒí‘œ ì •ë³´ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ì—¬ ê° ì„¹ì…˜ì˜ ë²”ìœ„ë¥¼ íŒŒì•…
#
#     return: [
#         {
#             "filing_number": "4120080005100",
#             "international_registration": None,
#             "page_start": 2,
#             "page_end": 2,
#             "y_start": 200.5,
#             "y_end": 450.3
#         },
#         ...
#     ]
#     """
#     doc = fitz.open(pdf_path)
#     sections = []
#
#     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" in block:
#                 block_text = ""
#                 for line in block["lines"]:
#                     for span in line["spans"]:
#                         block_text += span["text"] + " "
#
#                 all_blocks.append({
#                     "page": page_num + 1,
#                     "y0": block["bbox"][1],
#                     "y1": block["bbox"][3],
#                     "text": block_text.strip()
#                 })
#
#     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
#     # ë‘ ê°€ì§€ íŒ¨í„´ ëª¨ë‘ ì§€ì›: ë²ˆí˜¸ ìˆìŒ/ì—†ìŒ
#     section_starts = []
#     for idx, block in enumerate(all_blocks):
#         # íŒ¨í„´ 1: ë²ˆí˜¸ ìˆìŒ (1), (2), (3)...
#         match = re.search(
#             r"Information concerning the earlier mark \((\d+)\)",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ìŒ
#         match = re.search(
#             r"Information concerning the earlier mark\s*$",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,  # ë²ˆí˜¸ ì—†ìœ¼ë©´ 1ë¡œ ì„¤ì •
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
#     for i, start in enumerate(section_starts):
#         # ì„¹ì…˜ ë ì§€ì  ê²°ì •
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         # í•´ë‹¹ ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
#         section_text = " ".join([
#             all_blocks[j]["text"]
#             for j in range(start["index"], end_idx)
#         ])
#
#         # Filing number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         # International registration number ì¶”ì¶œ (ê³ ì • í˜•ì‹)
#         ir_match = re.search(
#             r"International registration number\s*:\s*(\d+)",
#             section_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         # Owner ì •ë³´ ì¶”ì¶œ
#         owner_match = re.search(
#             r"Name and address of the owner\s*:\s*([^\n]+)",
#             section_text
#         )
#         owner = owner_match.group(1).strip() if owner_match else "Unknown"
#
#         sections.append({
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
# def extract_underlined_with_positions(pdf_path):
#     """
#     PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ
#
#     return: [
#         {"page": 2, "y": 350.5, "text": "Advertising"},
#         {"page": 2, "y": 365.2, "text": "presentation of goods..."},
#         ...
#     ]
#     """
#     doc = fitz.open(pdf_path)
#     results = []
#
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         # ìˆ˜í‰ì„  ì°¾ê¸°
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#             text = page.get_text("text", clip=rect).strip()
#             text = " ".join(text.split())
#             text = normalize_underlined_text(text)
#
#             if text and len(text) > 1 and not should_exclude_underlined_text(text):
#                 results.append({
#                     "page": page_num + 1,
#                     "y": line["y"],
#                     "text": text
#                 })
#
#     doc.close()
#     return results
#
# def normalize_underlined_text(text: str) -> str:
#     """ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
#     text = text.strip()
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#     return text.strip()
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
#     stripped = text.strip()
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
#         return True
#     if "@" in stripped:
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
#         return True
#     return False
#
# def match_underlines_to_sections(sections, underlines):
#     """
#     ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­
#
#     sections: extract_trademark_sections() ê²°ê³¼
#     underlines: extract_underlined_with_positions() ê²°ê³¼
#
#     return: [
#         {
#             "filing_number": "4120080005100",
#             "international_registration": None,
#             "underlined_goods": ["Advertising", "presentation of goods...", ...]
#         },
#         ...
#     ]
#     """
#     results = []
#
#     for section in sections:
#         # ì´ ì„¹ì…˜ì— ì†í•˜ëŠ” ë°‘ì¤„ ì°¾ê¸°
#         section_underlines = []
#
#         for u in underlines:
#             # í˜ì´ì§€ì™€ yì¢Œí‘œë¡œ ë²”ìœ„ íŒë‹¨
#             in_page_range = (
#                 section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if in_page_range:
#                 # ê°™ì€ í˜ì´ì§€ì¼ ê²½ìš° yì¢Œí‘œë„ í™•ì¸
#                 if u["page"] == section["page_start"]:
#                     if u["y"] < section["y_start"]:
#                         continue
#                 if u["page"] == section["page_end"]:
#                     if u["y"] > section["y_end"]:
#                         continue
#
#                 section_underlines.append(u)
#
#         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#             final_goods = split_products(merged)
#             goods_list = [item["text"] for item in final_goods]
#         else:
#             goods_list = []
#
#         results.append({
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         })
#
#     return results
#
# def merge_by_semicolon(results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•©"""
#     merged = []
#     current_text = ""
#     current_page = None
#
#     for item in results:
#         text = item["text"]
#         page = item["page"]
#
#         if current_page is not None and page != current_page:
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.rstrip(";.").strip()
#                 })
#                 current_text = ""
#
#         current_page = page
#
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         if current_text.endswith(";") or current_text.endswith("."):
#             merged.append({
#                 "page": current_page,
#                 "text": current_text.rstrip(";.").strip()
#             })
#             current_text = ""
#
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.rstrip(";.").strip()
#         })
#
#     return merged
#
# def split_products(merged_results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´"""
#     final_results = []
#     for item in merged_results:
#         page = item["page"]
#         text = item["text"]
#         parts = [p.strip() for p in text.split(";") if p.strip()]
#         for part in parts:
#             final_results.append({
#                 "page": page,
#                 "text": part
#             })
#     return final_results
#
# def print_results(results):
#     print(results)
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods in enumerate(r['underlined_goods'], 1):
#                 print(f"      {i}. {goods}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
# def main(pdf_path):
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#     print("=" * 80)
#
#     # 1ë‹¨ê³„: ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ
#     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
#     sections = extract_trademark_sections(pdf_path)
#     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
#
#     # 2ë‹¨ê³„: ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
#     underlines = extract_underlined_with_positions(pdf_path)
#     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
#
#     # 3ë‹¨ê³„: ë§¤ì¹­
#     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
#     results = match_underlines_to_sections(sections, underlines)
#     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
#
#     # ê²°ê³¼ ì¶œë ¥
#     print_results(results)
#
#     return results
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ì‹ë³„ë ¥_1ìƒí‘œ1ì¶œì›.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)


# """
# PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# """
#
# import re
# import fitz
# import sys
# import asyncio
# from pathlib import Path
# from typing import List, Dict, Optional
# from concurrent.futures import ThreadPoolExecutor
#
#
# def extract_class_from_text(text: str) -> Optional[str]:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] íŒ¨í„´ ì¶”ì¶œ"""
#     match = re.search(r'\[Class\s+(\d+)\]', text, re.IGNORECASE)
#     return match.group(1) if match else None
#
# def remove_class_prefix(text: str) -> str:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] ë¶€ë¶„ ì œê±°"""
#     return re.sub(r'\[Class\s+\d+\]\s*', '', text, flags=re.IGNORECASE).strip()
#
# def normalize_underlined_text(text: str) -> str:
#     """ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
#     text = text.strip()
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#     return text.strip()
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
#     stripped = text.strip()
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
#         return True
#     if "@" in stripped:
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
#         return True
#     return False
#
# def extract_trademark_sections(pdf_path):
#     doc = fitz.open(pdf_path)
#     sections = []
#
#     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" in block:
#                 block_text = ""
#                 for line in block["lines"]:
#                     for span in line["spans"]:
#                         block_text += span["text"] + " "
#
#                 all_blocks.append({
#                     "page": page_num + 1,
#                     "y0": block["bbox"][1],
#                     "y1": block["bbox"][3],
#                     "text": block_text.strip()
#                 })
#
#     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
#     section_starts = []
#     for idx, block in enumerate(all_blocks):
#         # íŒ¨í„´ 1: ë²ˆí˜¸ ìˆìŒ
#         match = re.search(
#             r"Information concerning the earlier mark \((\d+)\)",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ìŒ
#         match = re.search(
#             r"Information concerning the earlier mark\s*$",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     # ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš°: ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬
#     if not section_starts:
#         full_text = " ".join([block["text"] for block in all_blocks])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International Registration/Subsequent Designation No[.\s]*.*?:\s*(\d+)",
#             full_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         doc.close()
#         return [{
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": 1,
#             "page_end": all_blocks[-1]["page"] if all_blocks else 1,
#             "y_start": 0,
#             "y_end": float('inf')
#         }]
#
#     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
#     for i, start in enumerate(section_starts):
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         section_text = " ".join([
#             all_blocks[j]["text"]
#             for j in range(start["index"], end_idx)
#         ])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International registration number\s*:\s*(\d+)",
#             section_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         sections.append({
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
# def extract_underlined_with_positions(pdf_path):
#     """PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ"""
#     doc = fitz.open(pdf_path)
#     results = []
#
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         # ìˆ˜í‰ì„  ì°¾ê¸°
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#             text = page.get_text("text", clip=rect).strip()
#             text = " ".join(text.split())
#
#             # Class ì •ë³´ ì¶”ì¶œ (ì •ê·œí™” ì „ì—)
#             class_num = extract_class_from_text(text)
#
#             # í…ìŠ¤íŠ¸ ì •ê·œí™”
#             text = normalize_underlined_text(text)
#
#             if text and len(text) > 1 and not should_exclude_underlined_text(text):
#                 results.append({
#                     "page": page_num + 1,
#                     "y": line["y"],
#                     "text": text,
#                     "class": class_num
#                 })
#
#     doc.close()
#     return results
#
# def match_underlines_to_sections(sections, underlines):
#     """ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­"""
#     results = []
#
#     for section in sections:
#         section_underlines = []
#
#         for u in underlines:
#             in_page_range = (
#                     section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if in_page_range:
#                 if u["page"] == section["page_start"]:
#                     if u["y"] < section["y_start"]:
#                         continue
#                 if u["page"] == section["page_end"]:
#                     if u["y"] > section["y_end"]:
#                         continue
#
#                 section_underlines.append(u)
#
#         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#             final_goods = split_products(merged)
#
#             # Class ì •ë³´ì™€ í•¨ê»˜ êµ¬ì¡°í™”
#             goods_list = []
#             for item in final_goods:
#                 goods_list.append({
#                     "class": item.get("class"),
#                     "goods": item["text"]
#                 })
#         else:
#             goods_list = []
#
#         results.append({
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         })
#
#     return results
#
# def merge_by_semicolon(results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•© (Class ì •ë³´ ìœ ì§€)"""
#     merged = []
#     current_text = ""
#     current_page = None
#     current_class = None
#
#     for item in results:
#         text = item["text"]
#         page = item["page"]
#         class_num = item.get("class")
#
#         if current_page is not None and page != current_page:
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.rstrip(";.").strip(),
#                     "class": current_class
#                 })
#                 current_text = ""
#                 current_class = None
#
#         current_page = page
#
#         if class_num and not current_class:
#             current_class = class_num
#
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         if current_text.endswith(";") or current_text.endswith("."):
#             merged.append({
#                 "page": current_page,
#                 "text": current_text.rstrip(";.").strip(),
#                 "class": current_class
#             })
#             current_text = ""
#             current_class = None
#
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.rstrip(";.").strip(),
#             "class": current_class
#         })
#
#     return merged
#
# def split_products(merged_results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´ (Class ì •ë³´ ìœ ì§€)"""
#     final_results = []
#     for item in merged_results:
#         page = item["page"]
#         text = item["text"]
#         class_num = item.get("class")
#
#         text_without_class = remove_class_prefix(text)
#         parts = [p.strip() for p in text_without_class.split(";") if p.strip()]
#
#         for part in parts:
#             final_results.append({
#                 "page": page,
#                 "text": part,
#                 "class": class_num
#             })
#     return final_results
#
# def extract_underlined_goods_sync(pdf_path):
#     """ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     sections = extract_trademark_sections(pdf_path)
#     underlines = extract_underlined_with_positions(pdf_path)
#     results = match_underlines_to_sections(sections, underlines)
#     return results
#
# async def extract_underlined_goods_async(pdf_path):
#     """ë¹„ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     loop = asyncio.get_event_loop()
#
#     with ThreadPoolExecutor() as executor:
#         results = await loop.run_in_executor(
#             executor,
#             extract_underlined_goods_sync,
#             pdf_path
#         )
#
#     return results
#
# async def extract_underline(file_path: str):
#     import logging
#     logger = logging.getLogger(__name__)
#
#     logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘.")
#
#     try:
#         if not Path(file_path).exists():
#             logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
#             return []
#
#         results = await extract_underlined_goods_async(file_path)
#
#         logger.info(f"PDF UNDERLINE ì¶”ì¶œ ì™„ë£Œ: {len(results)}ê°œ ìƒí‘œ ì²˜ë¦¬")
#         logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")
#
#         return results
#
#     except Exception as e:
#         logger.error(f"PDF UNDERLINE ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
#         return []
#
# def print_results(results):
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#     print("\nê²°ê³¼ ë°ì´í„°:")
#     print(results)
#
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods_item in enumerate(r['underlined_goods'], 1):
#                 class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
#                 print(f"      {i}. {class_info}{goods_item['goods']}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
# def main(pdf_path):
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#     print("=" * 80)
#
#     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
#     sections = extract_trademark_sections(pdf_path)
#     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
#
#     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
#     underlines = extract_underlined_with_positions(pdf_path)
#     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
#
#     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
#     results = match_underlines_to_sections(sections, underlines)
#     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
#
#     print_results(results)
#
#     return results
#
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/í…ŒìŠ¤íŠ¸/ë™ì¼ìœ ì‚¬3.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)

# ìµœì¢…ìœ¼ë¡œ ì‚¬ìš©í•˜ë ¤ê³  í–ˆì§€ë§Œ ì¸ìš© ìƒí‘œ ì „ì²´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ëŠ” ìƒí™© ë°œìƒìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
# """
# PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
# í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
# """
#
# import re
# import fitz
# import sys
# import asyncio
# from pathlib import Path
# from typing import List, Dict, Optional
# from concurrent.futures import ThreadPoolExecutor
#
#
# def extract_class_from_text(text: str) -> Optional[str]:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] íŒ¨í„´ ì¶”ì¶œ"""
#     match = re.search(r'\[Class\s+(\d+)\]', text, re.IGNORECASE)
#     return match.group(1) if match else None
#
#
# def remove_class_prefix(text: str) -> str:
#     """í…ìŠ¤íŠ¸ì—ì„œ [Class XX] ë¶€ë¶„ ì œê±°"""
#     return re.sub(r'\[Class\s+\d+\]\s*', '', text, flags=re.IGNORECASE).strip()
#
#
# def normalize_underlined_text(text: str, remove_class: bool = False) -> str:
#     """
#     ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”
#
#     Args:
#         text: ì •ê·œí™”í•  í…ìŠ¤íŠ¸
#         remove_class: [Class XX] ë¶€ë¶„ë„ ì œê±°í• ì§€ ì—¬ë¶€
#     """
#     text = text.strip()
#
#     # (underlined goods/services) prefix ì œê±°
#     text = re.sub(
#         r"^\(\s*underlined goods/services\s*\)\s*",
#         "",
#         text,
#         flags=re.IGNORECASE
#     )
#
#     # [Class XX] ì œê±° (ì˜µì…˜)
#     if remove_class:
#         text = remove_class_prefix(text)
#
#     # goods/servicesë¡œ ëë‚˜ëŠ” ê²½ìš° ì„¸ë¯¸ì½œë¡  ë³´ì •
#     if re.search(r"goods/services\s*$", text, re.IGNORECASE):
#         if not text.rstrip().endswith((';', '.')):
#             text = text.rstrip() + ";"
#
#     return text.strip()
#
#
# def should_exclude_underlined_text(text: str) -> bool:
#     """ì œì™¸í•  ë°‘ì¤„ í…ìŠ¤íŠ¸ íŒë‹¨"""
#     stripped = text.strip()
#     if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
#         return True
#     if re.match(r"^(E-mail|Email|Telephone|Tel\.?|Fax)\s*:", stripped, re.IGNORECASE):
#         return True
#     if "@" in stripped:
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥":
#         return True
#     if stripped == "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥":
#         return True
#     return False
#
#
# def extract_trademark_sections(pdf_path):
#     """PDFì—ì„œ ìƒí‘œ ì •ë³´ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ì—¬ ê° ì„¹ì…˜ì˜ ë²”ìœ„ë¥¼ íŒŒì•…"""
#     doc = fitz.open(pdf_path)
#     sections = []
#
#     # ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
#     all_blocks = []
#     for page_num, page in enumerate(doc):
#         blocks = page.get_text("dict")["blocks"]
#         for block in blocks:
#             if "lines" in block:
#                 block_text = ""
#                 for line in block["lines"]:
#                     for span in line["spans"]:
#                         block_text += span["text"] + " "
#
#                 all_blocks.append({
#                     "page": page_num + 1,
#                     "y0": block["bbox"][1],
#                     "y1": block["bbox"][3],
#                     "text": block_text.strip()
#                 })
#
#     # "Information concerning the earlier mark" íŒ¨í„´ ì°¾ê¸°
#     section_starts = []
#     for idx, block in enumerate(all_blocks):
#         # íŒ¨í„´ 1: ë²ˆí˜¸ ìˆìŒ
#         match = re.search(
#             r"Information concerning the earlier mark \((\d+)\)",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": int(match.group(1)),
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#             continue
#
#         # íŒ¨í„´ 2: ë²ˆí˜¸ ì—†ìŒ
#         match = re.search(
#             r"Information concerning the earlier mark\s*$",
#             block["text"],
#             re.IGNORECASE
#         )
#         if match:
#             section_starts.append({
#                 "index": idx,
#                 "mark_number": 1,
#                 "page": block["page"],
#                 "y": block["y0"]
#             })
#
#     # ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš°: ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬
#     if not section_starts:
#         full_text = " ".join([block["text"] for block in all_blocks])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International Registration/Subsequent Designation No[.\s]*.*?:\s*(\d+)",
#             full_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         doc.close()
#         return [{
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": 1,
#             "page_end": all_blocks[-1]["page"] if all_blocks else 1,
#             "y_start": 0,
#             "y_end": float('inf')
#         }]
#
#     # ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê²°ì • ë° ì •ë³´ ì¶”ì¶œ
#     for i, start in enumerate(section_starts):
#         if i + 1 < len(section_starts):
#             end_idx = section_starts[i + 1]["index"]
#             end_page = section_starts[i + 1]["page"]
#             end_y = section_starts[i + 1]["y"]
#         else:
#             end_idx = len(all_blocks)
#             end_page = all_blocks[-1]["page"]
#             end_y = all_blocks[-1]["y1"]
#
#         section_text = " ".join([
#             all_blocks[j]["text"]
#             for j in range(start["index"], end_idx)
#         ])
#
#         filing_match = re.search(r"Filing number\s*:\s*(\d+)", section_text)
#         filing_number = filing_match.group(1) if filing_match else None
#
#         ir_match = re.search(
#             r"International registration number\s*:\s*(\d+)",
#             section_text
#         )
#         international_registration = ir_match.group(1) if ir_match else None
#
#         sections.append({
#             "filing_number": filing_number,
#             "international_registration": international_registration,
#             "page_start": start["page"],
#             "page_end": end_page,
#             "y_start": start["y"],
#             "y_end": end_y
#         })
#
#     doc.close()
#     return sections
#
#
# def extract_underlined_with_positions(pdf_path):
#     """PDFì—ì„œ ë°‘ì¤„ í…ìŠ¤íŠ¸ì™€ ì •í™•í•œ ìœ„ì¹˜(í˜ì´ì§€, yì¢Œí‘œ) ì¶”ì¶œ"""
#     doc = fitz.open(pdf_path)
#     results = []
#
#     for page_num, page in enumerate(doc):
#         drawings = page.get_drawings()
#         lines = []
#
#         # ìˆ˜í‰ì„  ì°¾ê¸°
#         for d in drawings:
#             for item in d.get("items", []):
#                 if item[0] == "l":
#                     p1, p2 = item[1], item[2]
#                     if abs(p1.y - p2.y) < 2:
#                         length = abs(p2.x - p1.x)
#                         if 10 < length < 500:
#                             lines.append({
#                                 "y": p1.y,
#                                 "x0": min(p1.x, p2.x),
#                                 "x1": max(p1.x, p2.x)
#                             })
#
#         # ê° ìˆ˜í‰ì„  ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
#         for line in lines:
#             rect = fitz.Rect(
#                 line["x0"] - 1,
#                 line["y"] - 12,
#                 line["x1"] + 1,
#                 line["y"] + 1
#             )
#             text = page.get_text("text", clip=rect).strip()
#             text = " ".join(text.split())
#
#             # â­ ì¤‘ìš”: Class ì •ë³´ë¥¼ ë¨¼ì € ì¶”ì¶œ (ì •ê·œí™” ì „ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ)
#             original_text = text
#             class_num = extract_class_from_text(original_text)
#
#             # í…ìŠ¤íŠ¸ ì •ê·œí™” (ClassëŠ” ì•„ì§ ì œê±°í•˜ì§€ ì•ŠìŒ)
#             text = normalize_underlined_text(text, remove_class=False)
#
#             if text and len(text) > 1 and not should_exclude_underlined_text(text):
#                 results.append({
#                     "page": page_num + 1,
#                     "y": line["y"],
#                     "text": text,
#                     "class": class_num
#                 })
#
#     doc.close()
#     return results
#
#
# def match_underlines_to_sections(sections, underlines):
#     """ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­"""
#     results = []
#
#     for section in sections:
#         section_underlines = []
#
#         for u in underlines:
#             in_page_range = (
#                     section["page_start"] <= u["page"] <= section["page_end"]
#             )
#
#             if in_page_range:
#                 if u["page"] == section["page_start"]:
#                     if u["y"] < section["y_start"]:
#                         continue
#                 if u["page"] == section["page_end"]:
#                     if u["y"] > section["y_end"]:
#                         continue
#
#                 section_underlines.append(u)
#
#         # ë°‘ì¤„ í…ìŠ¤íŠ¸ ë³‘í•© ë° ë¶„í•´
#         if section_underlines:
#             merged = merge_by_semicolon(section_underlines)
#             final_goods = split_products(merged)
#
#             # Class ì •ë³´ì™€ í•¨ê»˜ êµ¬ì¡°í™”
#             goods_list = []
#             for item in final_goods:
#                 goods_list.append({
#                     "class": item.get("class"),
#                     "goods": item["text"]
#                 })
#         else:
#             goods_list = []
#
#         results.append({
#             "filing_number": section["filing_number"],
#             "international_registration": section["international_registration"],
#             "underlined_goods": goods_list
#         })
#
#     return results
#
#
# def merge_by_semicolon(results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•© (Class ì •ë³´ ìœ ì§€)"""
#     merged = []
#     current_text = ""
#     current_page = None
#     current_class = None
#
#     for item in results:
#         text = item["text"]
#         page = item["page"]
#         class_num = item.get("class")
#
#         if current_page is not None and page != current_page:
#             if current_text:
#                 merged.append({
#                     "page": current_page,
#                     "text": current_text.rstrip(";.").strip(),
#                     "class": current_class
#                 })
#                 current_text = ""
#                 current_class = None
#
#         current_page = page
#
#         if class_num and not current_class:
#             current_class = class_num
#
#         if current_text:
#             current_text += " " + text
#         else:
#             current_text = text
#
#         if current_text.endswith(";") or current_text.endswith("."):
#             merged.append({
#                 "page": current_page,
#                 "text": current_text.rstrip(";.").strip(),
#                 "class": current_class
#             })
#             current_text = ""
#             current_class = None
#
#     if current_text:
#         merged.append({
#             "page": current_page,
#             "text": current_text.rstrip(";.").strip(),
#             "class": current_class
#         })
#
#     return merged
#
#
# def split_products(merged_results):
#     """ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ê°œë³„ ìƒí’ˆ ë¶„í•´ (Class ì •ë³´ ìœ ì§€)"""
#     final_results = []
#     for item in merged_results:
#         page = item["page"]
#         text = item["text"]
#         class_num = item.get("class")
#
#         # [Class XX] ì œê±° í›„ ë¶„í•´
#         text_without_class = remove_class_prefix(text)
#
#         # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„í•´
#         parts = [p.strip() for p in text_without_class.split(";") if p.strip()]
#
#         for part in parts:
#             final_results.append({
#                 "page": page,
#                 "text": part,
#                 "class": class_num
#             })
#
#     return final_results
#
#
# def extract_underlined_goods_sync(pdf_path):
#     """ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     sections = extract_trademark_sections(pdf_path)
#     underlines = extract_underlined_with_positions(pdf_path)
#     results = match_underlines_to_sections(sections, underlines)
#     return results
#
#
# async def extract_underlined_goods_async(pdf_path):
#     """ë¹„ë™ê¸° í•¨ìˆ˜: PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ì¶”ì¶œ"""
#     loop = asyncio.get_event_loop()
#
#     with ThreadPoolExecutor() as executor:
#         results = await loop.run_in_executor(
#             executor,
#             extract_underlined_goods_sync,
#             pdf_path
#         )
#
#     return results
#
#
# async def extract_underline(file_path: str):
#     """
#     PDFì—ì„œ ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆì„ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
#
#     Returns:
#         list: [
#             {
#                 'filing_number': '4120080005100',
#                 'international_registration': None,
#                 'underlined_goods': [
#                     {"class": "35", "goods": "Advertising"},
#                     ...
#                 ]
#             },
#             ...
#         ]
#     """
#     import logging
#     logger = logging.getLogger(__name__)
#
#     logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘.")
#
#     try:
#         if not Path(file_path).exists():
#             logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
#             return []
#
#         results = await extract_underlined_goods_async(file_path)
#
#         logger.info(f"PDF UNDERLINE ì¶”ì¶œ ì™„ë£Œ: {len(results)}ê°œ ìƒí‘œ ì²˜ë¦¬")
#         logger.info("PDF UNDERLINE ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")
#
#         return results
#
#     except Exception as e:
#         logger.error(f"PDF UNDERLINE ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
#         return []
#
#
# def print_results(results):
#     """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
#     print("\nê²°ê³¼ ë°ì´í„°:")
#     print(results)
#
#     print("\n" + "=" * 80)
#     print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
#     print("=" * 80 + "\n")
#
#     for idx, r in enumerate(results, 1):
#         print(f"[{idx}] ìƒí‘œ ì •ë³´")
#
#         if r['filing_number']:
#             print(f"    Filing Number: {r['filing_number']}")
#         if r['international_registration']:
#             print(f"    International Registration: {r['international_registration']}")
#
#         print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")
#
#         if r['underlined_goods']:
#             print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
#             for i, goods_item in enumerate(r['underlined_goods'], 1):
#                 class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
#                 print(f"      {i}. {class_info}{goods_item['goods']}")
#         else:
#             print(f"    (ë°‘ì¤„ ì—†ìŒ)")
#
#         print()
#
#
# def main(pdf_path):
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")
#     print("=" * 80)
#
#     print("\n[1ë‹¨ê³„] ìƒí‘œ ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
#     sections = extract_trademark_sections(pdf_path)
#     print(f"âœ“ {len(sections)}ê°œ ìƒí‘œ ì„¹ì…˜ ë°œê²¬")
#
#     print("\n[2ë‹¨ê³„] ë°‘ì¤„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
#     underlines = extract_underlined_with_positions(pdf_path)
#     print(f"âœ“ {len(underlines)}ê°œ ë°‘ì¤„ ë°œê²¬")
#
#     # ë””ë²„ê¹…: ì¶”ì¶œëœ ë°‘ì¤„ í™•ì¸
#     print("\nì¶”ì¶œëœ ë°‘ì¤„ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
#     for i, u in enumerate(underlines[:3]):
#         print(f"  {i + 1}. Page={u['page']}, Class={u['class']}, Text={u['text'][:50]}...")
#
#     print("\n[3ë‹¨ê³„] ìƒí‘œ-ë°‘ì¤„ ë§¤ì¹­ ì¤‘...")
#     results = match_underlines_to_sections(sections, underlines)
#     print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ")
#
#     print_results(results)
#
#     return results
#
#
# if __name__ == "__main__":
#     if len(sys.argv) > 1:
#         path = sys.argv[1]
#     else:
#         path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/552025075457917-01-ë³µì‚¬.pdf"
#
#     if not Path(path).exists():
#         print(f"íŒŒì¼ ì—†ìŒ: {path}")
#         sys.exit(1)
#
#     main(path)

for i in range(5):
    print(i-i)

"""
í˜„ì¬ ê°€ì¥ ì í•©í•œ ë¡œì§
2026.01.16 ; íŠ¹ìˆ˜ê¸°í˜¸ê°€ ì¡´ì¬í•  ê²½ìš° ; ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ | ,ê°€ ìˆëŠ” ê²½ìš° , ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ => ;ê°€ ìš°ì„  
merge_by_semicolon, split_products
PDFì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ 
í•´ë‹¹ ë°‘ì¤„ì´ ì†í•œ ìƒí‘œ(Filing number/International registration number)ì™€ ì—°ê²°
"""

import re
import fitz
import sys
import asyncio
from pathlib import Path
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor

def extract_trademark_sections(pdf_path):
    """
    PDFì—ì„œ 'Information concerning the earlier mark' ì„¹ì…˜ì„ ê¸°ì¤€ìœ¼ë¡œ
    ê° ìƒí‘œ(Earlier Mark)ì˜ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """

    print("\n[START] extract_trademark_sections")
    print(f"PDF PATH: {pdf_path}")

    # PDF ì—´ê¸°
    doc = fitz.open(pdf_path)

    # ìµœì¢… ì„¹ì…˜ ê²°ê³¼
    sections = []

    # ==================================================
    # 1ï¸âƒ£ ëª¨ë“  í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜ì§‘
    # ==================================================
    all_blocks = []

    for page_num, page in enumerate(doc):
        print(f"\n--- Page {page_num + 1} ì²˜ë¦¬ ì‹œì‘ ---")

        # PyMuPDF dict í˜•íƒœë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        blocks = page.get_text("dict")["blocks"]

        for block_idx, block in enumerate(blocks):
            # í…ìŠ¤íŠ¸ ë¼ì¸ì´ ìˆëŠ” ë¸”ë¡ë§Œ ì‚¬ìš©
            if "lines" not in block:
                continue

            block_text = ""

            # í•œ ë¸”ë¡ ì•ˆì˜ ëª¨ë“  span í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
            for line in block["lines"]:
                for span in line["spans"]:
                    block_text += span["text"] + " "

            block_text = block_text.strip()

            block_info = {
                "page": page_num + 1,               # í˜ì´ì§€ ë²ˆí˜¸
                "y0": block["bbox"][1],             # ë¸”ë¡ ì‹œì‘ yì¢Œí‘œ
                "y1": block["bbox"][3],             # ë¸”ë¡ ë yì¢Œí‘œ
                "text": block_text                  # ë¸”ë¡ ì „ì²´ í…ìŠ¤íŠ¸
            }

            print(f"[BLOCK] page={block_info['page']} y0={block_info['y0']:.2f} "
                  f"text='{block_text[:80]}'")

            all_blocks.append(block_info)

    print(f"\n[INFO] ì „ì²´ ë¸”ë¡ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_blocks)}ê°œ")

    # ==================================================
    # 2ï¸âƒ£ 'Information concerning the earlier mark' ì‹œì‘ì  ì°¾ê¸°
    # ==================================================
    section_starts = []

    for idx, block in enumerate(all_blocks):
        text = block["text"]

        # PDF ì²´í¬ë°•ìŠ¤ ê¸°í˜¸ ì œê±°
        text_cleaned = text.replace("â–¡", "").replace("â˜", "").strip()

        # íŒ¨í„´ 1ï¸âƒ£ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°: (1), (2) ...
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*\((\d+)\)",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            mark_number = int(match.group(1))
            print(f"[SECTION START] idx={idx}, mark_number={mark_number}, "
                  f"page={block['page']}, y={block['y0']:.2f}")

            section_starts.append({
                "index": idx,
                "mark_number": mark_number,
                "page": block["page"],
                "y": block["y0"]
            })
            continue

        # íŒ¨í„´ 2ï¸âƒ£ ë²ˆí˜¸ ì—†ëŠ” ê²½ìš° (ë‹¨ì¼ ìƒí‘œ ë¬¸ì„œ)
        match = re.search(
            r"Information\s+concerning\s+the\s+earlier\s+mark\s*$",
            text_cleaned,
            re.IGNORECASE
        )

        if match:
            print(f"[SECTION START - NO NUMBER] idx={idx}, page={block['page']}")

            section_starts.append({
                "index": idx,
                "mark_number": 1,
                "page": block["page"],
                "y": block["y0"]
            })

    print(f"\n[INFO] ì„¹ì…˜ ì‹œì‘ì  ê°œìˆ˜: {len(section_starts)}")

    # ==================================================
    # 3ï¸âƒ£ ì„¹ì…˜ ì‹œì‘ì ì´ ì•„ì˜ˆ ì—†ëŠ” PDF ì²˜ë¦¬
    # ==================================================
    if not section_starts:
        print("[WARN] ì„¹ì…˜ í—¤ë” ë¯¸ë°œê²¬ â†’ ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ìƒí‘œë¡œ ì²˜ë¦¬")

        full_text = " ".join([block["text"] for block in all_blocks])

        filing_match = re.search(r"Filing number\s*:\s*(\d+)", full_text)
        filing_number = filing_match.group(1) if filing_match else None

        ir_match = re.search(
            r"International\s+(?:Registration|registration)[/\s]+"
            r"Subsequent\s+Designation\s+No[.\s]*:?\s*(\d+)",
            full_text
        )
        international_registration = ir_match.group(1) if ir_match else None

        print(f"[INFO] Filing Number: {filing_number}")
        print(f"[INFO] International Reg.: {international_registration}")

        doc.close()

        return [{
            "mark_number": 1,
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": 1,
            "page_end": all_blocks[-1]["page"] if all_blocks else 1,
            "y_start": 0,
            "y_end": float('inf')
        }]

    # ==================================================
    # 4ï¸âƒ£ ê° ì„¹ì…˜ì˜ ë²”ìœ„ ê³„ì‚° + ì •ë³´ ì¶”ì¶œ
    # ==================================================
    for i, start in enumerate(section_starts):
        print(f"\n[PROCESS SECTION] mark_number={start['mark_number']}")

        # ë‹¤ìŒ ì„¹ì…˜ì´ ìˆìœ¼ë©´ ê±°ê¸° ì „ê¹Œì§€
        if i + 1 < len(section_starts):
            end_idx = section_starts[i + 1]["index"]
            end_page = section_starts[i + 1]["page"]
            end_y = section_starts[i + 1]["y"]
        else:
            end_idx = len(all_blocks)
            end_page = all_blocks[-1]["page"]
            end_y = all_blocks[-1]["y1"]

        print(f"  page_start={start['page']} y_start={start['y']:.2f}")
        print(f"  page_end={end_page} y_end={end_y:.2f}")

        # í•´ë‹¹ ì„¹ì…˜ í…ìŠ¤íŠ¸ ì „ì²´ í•©ì¹˜ê¸°
        section_text = " ".join(
            all_blocks[j]["text"] for j in range(start["index"], end_idx)
        )

        # Filing number ì¶”ì¶œ
        filing_match = re.search(r"Filing\s+number\s*:\s*(\d+)", section_text)
        filing_number = filing_match.group(1) if filing_match else None

        # International registration number ì¶”ì¶œ
        ir_match = re.search(
            r"International\s+registration\s+number\s*:\s*(\d+)",
            section_text,
            re.IGNORECASE
        )
        international_registration = ir_match.group(1) if ir_match else None

        print(f"  Filing Number: {filing_number}")
        print(f"  International Reg.: {international_registration}")

        sections.append({
            "mark_number": start["mark_number"],
            "filing_number": filing_number,
            "international_registration": international_registration,
            "page_start": start["page"],
            "page_end": end_page,
            "y_start": start["y"],
            "y_end": end_y
        })

    doc.close()

    print("\n[END] extract_trademark_sections")
    print(f"[RESULT] sections={sections}")

    return sections

def extract_underlined_with_positions(pdf_path):
    """
    PDFì—ì„œ 'ë°‘ì¤„(underline)'ì— í•´ë‹¹í•˜ëŠ” ìˆ˜í‰ì„ ì„ ì§ì ‘ íƒì§€í•˜ê³ ,
    í•´ë‹¹ ìˆ˜í‰ì„  ë°”ë¡œ ìœ„ì— ìœ„ì¹˜í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜

    âœ” í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼(underline ì†ì„±)ì„ ì“°ì§€ ì•Šê³ 
    âœ” PDF ë‚´ë¶€ì— ì‹¤ì œë¡œ ê·¸ë ¤ì§„ 'ìˆ˜í‰ì„ (line)'ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•¨
    """

    print("\n[START] extract_underlined_with_positions")
    print(f"[INFO] PDF PATH = {pdf_path}")

    # ==================================================
    # 0ï¸âƒ£ PDF íŒŒì¼ ì˜¤í”ˆ
    # ==================================================
    # fitz.open() : PyMuPDFì—ì„œ PDF ë¬¸ì„œë¥¼ ì—¬ëŠ” ê³µì‹ API
    doc = fitz.open(pdf_path)

    # ìµœì¢… ê²°ê³¼ë¥¼ ëˆ„ì í•  ë¦¬ìŠ¤íŠ¸
    # ê° ì›ì†ŒëŠ” {page, y, text, class} í˜•íƒœì˜ dict
    results = []

    # ==================================================
    # 1ï¸âƒ£ í˜ì´ì§€ ë‹¨ìœ„ë¡œ PDF ìˆœíšŒ
    # ==================================================
    # enumerate â†’ (í˜ì´ì§€ ì¸ë±ìŠ¤, í˜ì´ì§€ ê°ì²´)
    for page_num, page in enumerate(doc):
        print(f"\n==============================")
        print(f"[PAGE START] Page {page_num + 1}")
        print(f"==============================")

        # --------------------------------------------------
        # page.get_drawings()
        # --------------------------------------------------
        # PyMuPDF(fitz) ë‚´ì¥ ë©”ì„œë“œ
        # í•´ë‹¹ í˜ì´ì§€ì— 'ê·¸ë ¤ì§„ ëª¨ë“  ê·¸ë˜í”½ ê°ì²´'ë¥¼ ë°˜í™˜
        #
        # í¬í•¨ ì˜ˆ:
        # - ì„ (line)
        # - ì‚¬ê°í˜•(rect)
        # - í…Œë‘ë¦¬
        # - ë°‘ì¤„ (underline)
        #
        # âŒ í…ìŠ¤íŠ¸ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒ
        drawings = page.get_drawings()
        print(f"[INFO] total drawings = {len(drawings)}")

        # ë°‘ì¤„ë¡œ ì˜ì‹¬ë˜ëŠ” 'ìˆ˜í‰ì„  í›„ë³´'ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸
        lines = []

        # ==================================================
        # 2ï¸âƒ£ ê·¸ë˜í”½ ê°ì²´ ì¤‘ ìˆ˜í‰ì„ (underline) íƒìƒ‰
        # ==================================================
        for d_idx, d in enumerate(drawings):
            print(f"\n  [DRAWING {d_idx + 1}] items = {len(d.get('items', []))}")

            # drawings ì•ˆì˜ ì‹¤ì œ ê°ì²´ë“¤ì€ d["items"]ì— ë“¤ì–´ìˆìŒ
            for item in d.get("items", []):

                # item[0] == "l"  â†’ line (ì„ )
                # item êµ¬ì¡° ì˜ˆ:
                # ("l", Point(x1,y1), Point(x2,y2))
                if item[0] == "l":
                    p1, p2 = item[1], item[2]

                    # ------------------------------------------
                    # ìˆ˜í‰ì„  íŒë³„ ì¡°ê±´
                    # ------------------------------------------
                    # y ì¢Œí‘œ ì°¨ì´ê°€ ê±°ì˜ ì—†ìœ¼ë©´ ìˆ˜í‰ì„ 
                    if abs(p1.y - p2.y) < 2:
                        length = abs(p2.x - p1.x)

                        # ------------------------------------------
                        # ë°‘ì¤„ë¡œ ë³¼ ìˆ˜ ìˆëŠ” ê¸¸ì´ë§Œ í—ˆìš©
                        # ë„ˆë¬´ ì§§ìœ¼ë©´ ë…¸ì´ì¦ˆ
                        # ë„ˆë¬´ ê¸¸ë©´ í˜ì´ì§€ êµ¬ë¶„ì„ /í‘œ í…Œë‘ë¦¬ ê°€ëŠ¥ì„±
                        # ------------------------------------------
                        if 10 < length < 500:
                            line_info = {
                                "y": p1.y,
                                "x0": min(p1.x, p2.x),
                                "x1": max(p1.x, p2.x)
                            }

                            print(
                                f"  [UNDERLINE FOUND] "
                                f"y={p1.y:.2f}, "
                                f"x0={line_info['x0']:.2f}, "
                                f"x1={line_info['x1']:.2f}, "
                                f"length={length:.2f}"
                            )

                            # ë°‘ì¤„ í›„ë³´ë¡œ ì €ì¥
                            lines.append(line_info)

        print(f"\n[INFO] underline candidates found = {len(lines)}")

        # ==================================================
        # 3ï¸âƒ£ ê° ë°‘ì¤„ ìœ„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        # ==================================================
        for idx, line in enumerate(lines):
            print(f"\n------------------------------")
            print(f"[PROCESS LINE {idx + 1}] y={line['y']:.2f}")
            print(f"------------------------------")

            # ------------------------------------------
            # ë°‘ì¤„ ë°”ë¡œ 'ìœ„' ì˜ì—­ì„ clip ì˜ì—­ìœ¼ë¡œ ì„¤ì •
            # ------------------------------------------
            # PDF ì¢Œí‘œê³„:
            # - y ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ì•„ë˜ìª½
            #
            # ë”°ë¼ì„œ:
            # y - 12 ~ y + 1 ì˜ì—­ì´
            # 'ë°‘ì¤„ ë°”ë¡œ ìœ„ì˜ í…ìŠ¤íŠ¸ ì˜ì—­'
            rect = fitz.Rect(
                line["x0"] - 1,
                line["y"] - 12,   # â¬…ï¸ ë°‘ì¤„ ìœ„ìª½ í…ìŠ¤íŠ¸ ì˜ì—­
                line["x1"] + 1,
                line["y"] + 1
            )

            # ------------------------------------------
            # clip ì˜ì—­ ë‚´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            # ------------------------------------------
            raw_text = page.get_text("text", clip=rect)
            if raw_text == 'ì‹¬ì‚¬ê´€\níŒŒíŠ¸ì¥\níŒ€ì¥\nêµ­ì¥\n':
                continue

            # repr ì‚¬ìš© â†’ \n, \t ê°™ì€ ì œì–´ë¬¸ì í™•ì¸ ëª©ì 
            print(f"[RAW TEXT] {repr(raw_text)}")

            # ------------------------------------------
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            # - ì•ë’¤ ê³µë°± ì œê±°
            # - ì¤„ë°”ê¿ˆ, ì—°ì† ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
            # ------------------------------------------
            text = raw_text.strip()
            text = " ".join(text.split())

            print(f"[CLEAN TEXT] '{text}'")

            # ==================================================
            # 4ï¸âƒ£ Class ì •ë³´ ì¶”ì¶œ ([Class XX])
            # ==================================================
            original_text = text

            match = re.search(
                r'\[Class\s+(\d+)\]',
                original_text,
                re.IGNORECASE
            )

            class_num = match.group(1) if match else None
            print(f"[CLASS] extracted = {class_num}")

            # ==================================================
            # 5ï¸âƒ£ ë°‘ì¤„ í…ìŠ¤íŠ¸ ì •ê·œí™”
            # ==================================================
            # - (underlined goods) ì œê±°
            # - goods/services ì²˜ë¦¬
            # - class prefix ìœ ì§€ ì—¬ë¶€ ì¡°ì •
            normalized_text = normalize_underlined_text(
                text,
                remove_class=False
            )

            print(f"[NORMALIZED TEXT] '{normalized_text}'")

            # ==================================================
            # 6ï¸âƒ£ ì œì™¸ ëŒ€ìƒ í…ìŠ¤íŠ¸ ê²€ì‚¬
            # ==================================================
            # Fax, Tel, Email, ì‹¬ì‚¬ê´€/íŒ€ì¥/êµ­ì¥ ë“±
            excluded = should_exclude_underlined_text(normalized_text)
            print(f"[EXCLUDE CHECK] excluded={excluded}")

            # ==================================================
            # 7ï¸âƒ£ ê²°ê³¼ ì €ì¥
            # ==================================================
            if normalized_text and len(normalized_text) > 1 and not excluded:
                result_item = {
                    "page": page_num + 1,
                    "y": line["y"],
                    "text": normalized_text,
                    "class": class_num
                }

                print(f"[ADD RESULT] {result_item}")
                results.append(result_item)
            else:
                print("[SKIP] empty / excluded / too short")

    # ==================================================
    # 8ï¸âƒ£ PDF ë‹«ê¸°
    # ==================================================
    doc.close()

    print("\n[END] extract_underlined_with_positions")
    print(f"[RESULT COUNT] {len(results)}")
    print(f"[RESULT DATA]\n{results}")

    return results

def match_underlines_to_sections(sections, underlines):
    """
    ë°‘ì¤„ ë°ì´í„°ë¥¼ ìƒí‘œ ì„¹ì…˜ì— ë§¤ì¹­í•˜ëŠ” í•¨ìˆ˜

    íë¦„:
    1. ìƒí‘œ ì„¹ì…˜(page_start ~ page_end, y_start ~ y_end) ìˆœíšŒ
    2. í•´ë‹¹ ì„¹ì…˜ì— í¬í•¨ë˜ëŠ” ë°‘ì¤„ ë°ì´í„°ë§Œ í•„í„°ë§
    3. ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë³‘í•©
    4. ìµœì¢… ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    """

    print("\n================ MATCH UNDERLINES TO SECTIONS ================\n")

    results = []

    # 1ï¸âƒ£ ìƒí‘œ ì„¹ì…˜ ë‹¨ìœ„ ìˆœíšŒ
    for s_idx, section in enumerate(sections, 1):
        print(f"\n[SECTION {s_idx}]")
        print(f"  page range : {section['page_start']} ~ {section['page_end']}")
        print(f"  y range    : {section['y_start']} ~ {section['y_end']}")

        section_underlines = []

        # 2ï¸âƒ£ ëª¨ë“  ë°‘ì¤„ ë°ì´í„° ìˆœíšŒ
        for u_idx, u in enumerate(underlines, 1):
            print(f"\n  â””â”€ [UNDERLINE {u_idx}] page={u['page']} y={u['y']} text='{u['text']}'")

            # 2-1ï¸âƒ£ í˜ì´ì§€ ë²”ìœ„ ì²´í¬
            in_page_range = (
                section["page_start"] <= u["page"] <= section["page_end"]
            )

            if not in_page_range:
                print("     âŒ page range ë¶ˆì¼ì¹˜ â†’ skip")
                continue

            # 2-2ï¸âƒ£ ì‹œì‘ í˜ì´ì§€ y ë²”ìœ„ ì²´í¬
            if u["page"] == section["page_start"] and u["y"] < section["y_start"]:
                print("     âŒ start page y ë²”ìœ„ ìœ„ â†’ skip")
                continue

            # 2-3ï¸âƒ£ ì¢…ë£Œ í˜ì´ì§€ y ë²”ìœ„ ì²´í¬
            if u["page"] == section["page_end"] and u["y"] >= section["y_end"]:
                print("     âŒ end page y ë²”ìœ„ ì•„ë˜ â†’ skip")
                continue

            # 2-4ï¸âƒ£ ì¡°ê±´ í†µê³¼ â†’ ì„¹ì…˜ì— í¬í•¨
            print("     âœ… sectionì— í¬í•¨")
            section_underlines.append(u)

        print(f"\n  â–¶ section_underlines ({len(section_underlines)}ê°œ):")
        for item in section_underlines:
            print(f"     - {item}")

        # 3ï¸âƒ£ ë³‘í•© + ë¶„ë¦¬
        if section_underlines:
            print("\n  â–¶ merge_by_semicolon ì‹¤í–‰")
            merged = merge_by_semicolon(section_underlines)

            print("  â–¶ merge ê²°ê³¼:")
            for m in merged:
                print(f"     - {m}")

            print("\n  â–¶ split_products ì‹¤í–‰")
            final_goods = split_products(merged)

            print("  â–¶ split ê²°ê³¼:")
            for fg in final_goods:
                print(f"     - {fg}")

            # 4ï¸âƒ£ ìµœì¢… goods ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
            goods_list = []
            for item in final_goods:
                goods_text = item["text"].strip()
                class_num = item.get("class")

                goods_list.append({
                    "class": class_num,
                    "goods": goods_text
                })

        else:
            print("\n  â–¶ section_underlines ì—†ìŒ")
            goods_list = []

        # 5ï¸âƒ£ ì„¹ì…˜ ê²°ê³¼ ì €ì¥
        section_result = {
            "mark_number": section.get("mark_number"),
            "filing_number": section["filing_number"],
            "international_registration": section["international_registration"],
            "underlined_goods": goods_list
        }

        print("\n  â–¶ SECTION RESULT:")
        print(section_result)

        results.append(section_result)

    print("\n================ MATCH END ================\n")
    return results

def normalize_underlined_text(text: str, remove_class: bool = False) -> str:
    """
    ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    - ë¶ˆí•„ìš”í•œ prefix ì œê±°
    - goods/services í˜•íƒœ ë³´ì •
    - Class ì œê±° ì˜µì…˜ ì²˜ë¦¬
    """

    print("\n[NORMALIZE START]")
    print(f"INPUT TEXT: '{text}'")
    print(f"remove_class = {remove_class}")

    # 1ï¸âƒ£ ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    print(f"[STEP 1] strip -> '{text}'")

    # 2ï¸âƒ£ 'all' ë˜ëŠ” 'All' ë‹¨ë…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if re.fullmatch(r"(all|All)", text):
        print("[STEP 2] matched 'all' only â†’ return ê·¸ëŒ€ë¡œ")
        return text

    # 3ï¸âƒ£ '(underlined goods)' ì œê±°
    before = text
    text = re.sub(
        r"^\(\s*underlined goods\s*\)\s*",
        "",
        text,
        flags=re.IGNORECASE
    )
    if before != text:
        print(f"[STEP 3] remove '(underlined goods)' -> '{text}'")

    # 4ï¸âƒ£ '(underlined goods/services)' ì œê±°
    before = text
    text = re.sub(
        r"^\(\s*underlined goods/services\s*\)\s*",
        "",
        text,
        flags=re.IGNORECASE
    )
    if before != text:
        print(f"[STEP 4] remove '(underlined goods/services)' -> '{text}'")

    # 5ï¸âƒ£ Class ì œê±° ì˜µì…˜
    if remove_class:
        before = text
        text = remove_class_prefix(text)
        if before != text:
            print(f"[STEP 5] remove class prefix -> '{text}'")

    # 6ï¸âƒ£ goods/services ë¡œ ëë‚˜ëŠ” ê²½ìš° ; ë³´ì •
    if re.search(r"goods/services\s*$", text, re.IGNORECASE):
        print("[STEP 6] ends with 'goods/services'")
        if not text.rstrip().endswith((';', '.')):
            text = text.rstrip() + ";"
            print(f"         append ';' -> '{text}'")

    # 7ï¸âƒ£ ìµœì¢… ì •ë¦¬
    text = text.strip()
    print(f"[NORMALIZE END] RESULT = '{text}'")

    return text

def should_exclude_underlined_text(text: str) -> bool:
    """
    ë°‘ì¤„ í…ìŠ¤íŠ¸ê°€ 'ìƒí’ˆ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš°' ì œì™¸í•˜ê¸° ìœ„í•œ íŒë‹¨ í•¨ìˆ˜
    """

    print("\n[EXCLUDE CHECK START]")
    print(f"INPUT TEXT: '{text}'")

    stripped = text.strip()
    print(f"[STEP 1] stripped -> '{stripped}'")

    # 1ï¸âƒ£ << ... >> í˜•íƒœ (ë©”íƒ€/ì£¼ì„)
    if re.fullmatch(r"<<\s*[^<>]+\s*>>", stripped):
        print("[EXCLUDE] matched << >> pattern")
        return True

    # 2ï¸âƒ£ ì—°ë½ì²˜ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    if re.search(r"\b(Fax|Tel\.?|Telephone|E-mail|Email)\b", stripped, re.IGNORECASE):
        print("[EXCLUDE] contact keyword detected (Fax/Tel/Email)")
        return True

    # 3ï¸âƒ£ ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨
    if "@" in stripped:
        print("[EXCLUDE] '@' detected (email)")
        return True

    # 4ï¸âƒ£ ì‹¬ì‚¬ê´€ ì§ì±… ë‹¨ë… í…ìŠ¤íŠ¸
    if stripped in ["ì‹¬ì‚¬ê´€ íŒŒíŠ¸ì¥ íŒ€ì¥ êµ­ì¥", "ì‹¬ì‚¬ê´€ íŒ€ì¥ êµ­ì¥"]:
        print("[EXCLUDE] examiner title only")
        return True

    print("[KEEP] valid underlined text")
    return False

def merge_by_semicolon(results):
    """
    ì„¸ë¯¸ì½œë¡ (;) ë˜ëŠ” ë§ˆì¹¨í‘œ(.) ê¸°ì¤€ìœ¼ë¡œ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜
    - ê²°ê³¼ë¬¼ì—ëŠ” ; / . ì„ ì œê±°í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€
    - í˜ì´ì§€ê°€ ë°”ë€Œë©´ ë¬´ì¡°ê±´ flush
    """

    print("\n================ MERGE BY SEMICOLON START ================\n")

    merged = []            # ìµœì¢… ë³‘í•© ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    current_text = ""      # í˜„ì¬ ëˆ„ì  ì¤‘ì¸ í…ìŠ¤íŠ¸
    current_page = None    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í˜ì´ì§€
    current_class = None   # í˜„ì¬ ëˆ„ì  ì¤‘ì¸ class

    # 1ï¸âƒ£ underline ê²°ê³¼ í•˜ë‚˜ì”© ìˆœíšŒ
    for idx, item in enumerate(results, 1):
        text = item["text"]
        page = item["page"]
        class_num = item.get("class")

        print(f"[{idx}] INPUT ITEM")
        print(f"    page  : {page}")
        print(f"    text  : '{text}'")
        print(f"    class : {class_num}")

        # 2ï¸âƒ£ ì§í•¨/ì„œëª… ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
        if text in ['ì‹¬ì‚¬ê´€', 'íŒŒíŠ¸ì¥', 'íŒ€ì¥', 'êµ­ì¥', 'íŒ€ì¥ êµ­ì¥']:
            print("    âŒ ì§í•¨ í…ìŠ¤íŠ¸ â†’ skip")
            continue

        # 3ï¸âƒ£ í˜ì´ì§€ ë³€ê²½ ê°ì§€ â†’ ì´ì „ ëˆ„ì  ë°ì´í„° flush
        if current_page is not None and page != current_page:
            print("    ğŸ”„ í˜ì´ì§€ ë³€ê²½ ê°ì§€")

            if current_text:
                print(f"    â–¶ flush (page={current_page}) : '{current_text}'")
                merged.append({
                    "page": current_page,
                    "text": current_text.strip(),  # â— ë ë¬¸ì ì œê±° ì•ˆ í•¨
                    "class": current_class
                })

                current_text = ""
                current_class = None

        # í˜„ì¬ í˜ì´ì§€ ê°±ì‹ 
        current_page = page

        # 4ï¸âƒ£ class ì„¤ì • (ì²˜ìŒ í•œ ë²ˆë§Œ)
        if class_num and not current_class:
            current_class = class_num
            print(f"    ğŸ“Œ class ì„¤ì •: {current_class}")

        # 5ï¸âƒ£ í…ìŠ¤íŠ¸ ëˆ„ì 
        if current_text:
            current_text += " " + text
        else:
            current_text = text

        print(f"    â• ëˆ„ì  í…ìŠ¤íŠ¸: '{current_text}'")

        # 6ï¸âƒ£ ë³‘í•© ì¢…ë£Œ ì¡°ê±´ (; ë˜ëŠ” .)
        if current_text.rstrip().endswith(";") or current_text.rstrip().endswith("."):
            print("    âœ… ë³‘í•© ì¢…ë£Œ ì¡°ê±´ ì¶©ì¡± (; or .)")

            merged.append({
                "page": page,
                "text": current_text,  # â— ê·¸ëŒ€ë¡œ ìœ ì§€
                "class": current_class or class_num
            })

            print(f"    â–¶ append: '{current_text}'")

            # ëˆ„ì  ìƒíƒœ ì´ˆê¸°í™”
            current_text = ""
            current_class = None
            continue

    # 7ï¸âƒ£ ë£¨í”„ ì¢…ë£Œ í›„ ì”ì—¬ ë°ì´í„° ì²˜ë¦¬
    if current_text:
        print("\nğŸ§¹ ë§ˆì§€ë§‰ ì”ì—¬ ë°ì´í„° flush")
        print(f"    page={current_page}, text='{current_text}'")

        merged.append({
            "page": current_page,
            "text": current_text.strip(),
            "class": current_class
        })

    print("\n================ MERGE RESULT ================\n")
    for m in merged:
        print(m)

    print("\n================ MERGE END ================\n")
    return merged

def split_products(merged_results):
    """
    ë³‘í•©ëœ ë°‘ì¤„ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ìƒí’ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜

    ë¶„ë¦¬ ê·œì¹™:
    1. ì„¸ë¯¸ì½œë¡ (;)ì´ ìˆìœ¼ë©´ ; ê¸°ì¤€ ë¶„ë¦¬
    2. ì„¸ë¯¸ì½œë¡ ì´ ì—†ê³  ì½¤ë§ˆ(,)ê°€ ìˆìœ¼ë©´ , ê¸°ì¤€ ë¶„ë¦¬
    3. êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ í•˜ë‚˜ì˜ ìƒí’ˆìœ¼ë¡œ ì²˜ë¦¬
    """

    print("\n================ SPLIT PRODUCTS START ================\n")

    final_results = []

    # 1ï¸âƒ£ ë³‘í•©ëœ ê²°ê³¼ í•˜ë‚˜ì”© ì²˜ë¦¬
    for idx, item in enumerate(merged_results, 1):
        page = item["page"]
        text = item["text"]
        class_num = item.get("class")

        print(f"[{idx}] INPUT MERGED ITEM")
        print(f"    page  : {page}")
        print(f"    text  : '{text}'")
        print(f"    class : {class_num}")

        # 2ï¸âƒ£ [Class XX] ê°™ì€ ì ‘ë‘ì–´ ì œê±°
        text_without_class = remove_class_prefix(text)
        print(f"    after remove_class_prefix: '{text_without_class}'")

        # 3ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ê¸°ì¤€ ë¶„ë¦¬
        if ";" in text_without_class:
            print("    ğŸ”¹ split by ';'")
            parts = [
                p.strip().replace(".", "")
                for p in text_without_class.split(";")
                if p.strip()
            ]

        # 4ï¸âƒ£ ì„¸ë¯¸ì½œë¡  ì—†ìœ¼ë©´ ì½¤ë§ˆ ê¸°ì¤€ ë¶„ë¦¬
        elif "," in text_without_class:
            print("    ğŸ”¹ split by ','")
            parts = [
                p.strip().replace(".", "")
                for p in text_without_class.split(",")
                if p.strip()
            ]

        # 5ï¸âƒ£ êµ¬ë¶„ì ìì²´ê°€ ì—†ëŠ” ê²½ìš°
        else:
            print("    ğŸ”¹ no delimiter â†’ single item")
            parts = [
                text_without_class.strip().replace(".", "")
            ]

        print(f"    â–¶ split result parts: {parts}")

        # 6ï¸âƒ£ ê²°ê³¼ ëˆ„ì 
        for part in parts:
            final_item = {
                "page": page,
                "text": part,
                "class": class_num
            }
            print(f"    â• append final item: {final_item}")

            final_results.append(final_item)

    print("\n================ SPLIT PRODUCTS RESULT ================\n")
    for r in final_results:
        print(r)

    print("\n================ SPLIT PRODUCTS END ================\n")
    return final_results

def remove_class_prefix(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ ì•ì— ë¶™ì€ [Class XX] íŒ¨í„´ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    ì˜ˆ:
      "[Class 10] Shampoos" â†’ "Shampoos"
    """

    print(f"    ğŸ”§ remove_class_prefix input: '{text}'")

    cleaned = re.sub(
        r'\[Class\s+\d+\]\s*',  # [Class 10] íŒ¨í„´
        '',
        text,
        flags=re.IGNORECASE
    ).strip()

    print(f"    ğŸ”§ remove_class_prefix output: '{cleaned}'")

    return cleaned

def print_results(results):
    """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""

    print("\n" + "=" * 80)
    print("ìƒí‘œë³„ ë°‘ì¤„ ìƒí’ˆ ë¶„ì„ ê²°ê³¼")
    print("=" * 80 + "\n")

    for idx, r in enumerate(results, 1):
        print(f"[{idx}] ìƒí‘œ ì •ë³´ (Earlier Mark {r.get('mark_number', '?')})")

        if r['filing_number']:
            print(f"    Filing Number: {r['filing_number']}")
        if r['international_registration']:
            print(f"    International Registration: {r['international_registration']}")

        print(f"    Underlined Goods: {len(r['underlined_goods'])}ê°œ")

        if r['underlined_goods']:
            print(f"\n    ë°‘ì¤„ ì¹œ ìƒí’ˆ ëª©ë¡:")
            for i, goods_item in enumerate(r['underlined_goods'], 1):
                class_info = f"[Class {goods_item['class']}] " if goods_item['class'] else ""
                print(f"      {i}. {class_info}{goods_item['goods']}")
        else:
            print(f"    (ë°‘ì¤„ ì—†ìŒ)")

        print()

def main(pdf_path):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print(f"\níŒŒì¼ ë¶„ì„ ì¤‘: {pdf_path}")

    sections = extract_trademark_sections(pdf_path)
    underlines = extract_underlined_with_positions(pdf_path)
    results = match_underlines_to_sections(sections, underlines)
    print(f"\n{results}\n")

    print_results(results)

    return results

if __name__ == "__main__":
    if len(sys.argv) > 1:
        path = sys.argv[1]
    else:
        path = r"/home/mark15/project/markpass/markpass-file/example_opinion/ê°€ê±°ì ˆ í†µì§€ì„œ/ë¬¸ì œ/552025075457917-01-ë³µì‚¬.pdf"

    if not Path(path).exists():
        print(f"íŒŒì¼ ì—†ìŒ: {path}")
        sys.exit(1)

    main(path)
